Metadata-Version: 2.1
Name: rtx50-compat
Version: 1.0.0
Summary: RTX 50-series GPU compatibility layer for PyTorch and CUDA - enables sm_120 support
Home-page: https://github.com/jw/rtx50-compat
Author: JW
Author-email: JW <jw@diablogato.com>
License: MIT License
        
        Copyright (c) 2025 JW
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
Project-URL: Homepage, https://github.com/jw/rtx50-compat
Project-URL: Bug Tracker, https://github.com/jw/rtx50-compat/issues
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Provides-Extra: dev
License-File: LICENSE

# rtx50-compat

Enable NVIDIA RTX 50-series GPU support in PyTorch and the Python AI ecosystem. This package provides runtime patches for sm_120 compute capability (RTX 5090/5080).

## üöÄ Quick Start

```bash
# Install with uv (recommended)
uv pip install rtx50-compat

# Or with pip
pip install rtx50-compat
```

## üéØ Features

- ‚úÖ Automatic RTX 50-series detection and patching
- ‚úÖ PyTorch sm_120 compute capability support
- ‚úÖ CUDA extension compilation fixes
- ‚úÖ Memory optimization for consumer GPUs
- ‚úÖ Compatible with ComfyUI, Stable Diffusion, and more
- ü¶á Batman mode for stealth operations

## üìñ Usage

### Automatic Patching

Simply import the package and patches are applied automatically:

```python
import rtx50_compat  # Patches applied on import for RTX 50-series GPUs
import torch

# Your code works normally
model = torch.nn.Linear(1024, 1024).cuda()
```

### Manual Patching

For more control:

```python
import rtx50_compat

# Check if you have an RTX 50-series GPU
if rtx50_compat.is_rtx_50_series():
    # Apply all patches manually
    rtx50_compat.patch_all(verbose=True)
```

### Integration Examples

**ComfyUI**:
```python
# In ComfyUI/main.py or custom_nodes
import rtx50_compat  # Add before torch imports
```

**Stable Diffusion WebUI**:
```python
# In webui.py
import rtx50_compat  # Add at the top
```

**Your Training Script**:
```python
import rtx50_compat
import torch

# 32GB of VRAM for large models!
model = YourLargeModel().cuda()
```

## üîß What It Does

1. **PyTorch Compatibility**: Makes RTX 5090 masquerade as H100 when needed
2. **CUDA Extensions**: Adds sm_120 flags for compilation
3. **Memory Management**: Optimizes for 32GB consumer GPU memory
4. **Library Patches**: Fixes flash-attention, xformers, and other CUDA libs

## ü¶á Batman Mode

For the subtle approach:

```bash
export RTX50_BATMAN_MODE=1
python your_script.py
```

## üìä Benchmarks

RTX 5090 vs Intel i9-14900K:
- Matrix Multiplication: **45-120x faster**
- Transformer Models: **25-60x faster**
- Memory Bandwidth: **15x higher**

## üõ†Ô∏è Requirements

- Python 3.8+
- PyTorch 2.0+ (with CUDA 12.0+)
- NVIDIA Driver 550.45+

## üìù License

MIT License - Created by a humble servant of the AI community.

## ü§ù Contributing

Found an issue? RTX 5070 Ti patches needed? PRs welcome!

---

*"I am Batman - at your local jujitsu establishment" - RTX 5090 (in disguise)*
