# this file (imperfectly) replicates the GN1 model used
# for the note: ATL-PHYS-PUB-2022-027. There are some
# dfferences:
# - Here the track init net has output size 256, rather than 64 for the note
# - We include layernorm by default (this is not currently configurable)
# - We use ScaledDotProduct attention rather than GATv2, which does not affect performance (but reduces memory usage)
name: GN1

model:
  lrs_config:
    initial: 1e-3
    max: 1e-3
    end: 1e-3
    pct_start: 0.1
    weight_decay: 1e-5

  model:
    class_path: salt.models.SaltModel
    init_args:
      init_nets:
        - input_name: tracks
          dense_config:
            input_size: 23
            output_size: &embed_dim 256
            hidden_layers: [64, 64, 64]
            activation: &activation ReLU

      encoder:
        class_path: salt.models.TransformerEncoder
        init_args:
          embed_dim: *embed_dim
          num_layers: 3
          out_dim: &out_dim 128
          mha_config:
            num_heads: 2
            attention: { class_path: salt.models.ScaledDotProductAttention }
            out_proj: 128

      pool_net:
        class_path: salt.models.GlobalAttentionPooling
        init_args: { input_size: *out_dim }

      tasks:
        class_path: torch.nn.ModuleList
        init_args:
          modules:
            - class_path: salt.models.ClassificationTask
              init_args:
                name: jets_classification
                input_name: jets
                label: flavour_label
                loss: torch.nn.CrossEntropyLoss
                dense_config:
                  input_size: *out_dim
                  output_size: 3
                  hidden_layers: [128, 64, 32, 16, 3]
                  activation: *activation

            - class_path: salt.models.ClassificationTask
              init_args:
                name: track_origin
                input_name: tracks
                label: ftagTruthOriginLabel
                weight: 0.5
                loss:
                  class_path: torch.nn.CrossEntropyLoss
                  init_args:
                    weight: [3.96, 104.05, 1.0, 8.32, 5.98, 10.22, 1.0, 21.54]
                dense_config:
                  input_size: *out_dim
                  context_size: *out_dim
                  output_size: 8
                  hidden_layers: [128, 64, 32, 8]
                  activation: *activation

            - class_path: salt.models.VertexingTask
              init_args:
                name: track_vertexing
                input_name: tracks
                label: ftagTruthVertexIndex
                weight: 1.5
                loss:
                  class_path: torch.nn.BCEWithLogitsLoss
                  init_args: { reduction: none }
                dense_config:
                  input_size: 256
                  context_size: *out_dim
                  hidden_layers: [128, 64, 32]
                  output_size: 1
                  activation: *activation

data:
  variables:
    jets:
      - pt_btagJes
      - eta_btagJes
    tracks:
      - d0
      - z0SinTheta
      - dphi
      - deta
      - qOverP
      - IP3D_signed_d0_significance
      - IP3D_signed_z0_significance
      - phiUncertainty
      - thetaUncertainty
      - qOverPUncertainty
      - numberOfPixelHits
      - numberOfSCTHits
      - numberOfInnermostPixelLayerHits
      - numberOfNextToInnermostPixelLayerHits
      - numberOfInnermostPixelLayerSharedHits
      - numberOfInnermostPixelLayerSplitHits
      - numberOfPixelSharedHits
      - numberOfPixelSplitHits
      - numberOfSCTSharedHits
      - numberOfPixelHoles
      - numberOfSCTHoles
      #- leptonID
