# Site information
site_name: doteval

site_author: dottxt
site_description: >-
   Large Language Model evaluations library


# Repository
repo_name: dottxt-ai/doteval
repo_url: https://github.com/dottxt-ai/doteval

# Copyright
copyright: Copyright &copy; 2024- The Outlines Developers

# Configuration
theme:
  name: material
  palette:
    - scheme: default
      primary: white
  logo: assets/images/doteval.svg
  favicon: assets/images/doteval.svg
  icon:
    repo: fontawesome/brands/github
  features:
    - content.code.copy
    - navigation.expand
    - navigation.tabs
    - navigation.sections
    - header.autohide
    - announce.dismiss
  font:
    text: Inter
    code: Source Code Pro

# Additional configuration
extra:
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/dottxt-ai/doteval
    - icon: fontawesome/brands/twitter
      link: https://x.com/dottxtai
  generator: false

extra_css:
    - stylesheets/extra.css

# Extensions
markdown_extensions:
  - admonition
  - def_list
  - attr_list
  - md_in_html
  - pymdownx.highlight:
      anchor_linenums: true
      line_spans: __span
      pygments_lang_class: true
      noclasses: True
      pygments_style: nord
      use_pygments: true
      pygments_style: nord
  - pymdownx.superfences
  - pymdownx.tabbed:
      alternate_style: true
  - pymdownx.inlinehilite
  - pymdownx.details
  - pymdownx.emoji:
      emoji_index: !!python/name:material.extensions.emoji.twemoji
      emoji_generator: !!python/name:material.extensions.emoji.to_svg

plugins:
  - mkdocstrings:
      default_handler: python
      handlers:
        python:
          paths: [src]
          options:
            show_submodules: true
  - search
  - section-index

nav:
  - Home: index.md
  - Getting Started:
      - Welcome to doteval: welcome.md
      - Why LLM Evaluation?: why-llm-evaluation.md
      - Installation: installation.md
      - Quickstart: quickstart.md
  - Tutorials:
      - Get Started in 10 Minutes: tutorials/01-your-first-evaluation.md
      - Use APIs and Local Models: tutorials/02-using-real-models.md
      - Evaluate on HF Datasets: tutorials/03-working-with-real-datasets.md
      - Create an LLM Judge Evaluator: tutorials/04-building-custom-evaluators.md
      - Run Evaluations in Parallel: tutorials/05-scale-with-async-evaluation.md
      - Share Expensive Resources: tutorials/06-pytest-fixtures-and-resource-pooling.md
      - Comparing Models: tutorials/07-comparing-multiple-models.md
      - Manage API Rate Limits: tutorials/08-optimize-concurrency-for-production.md
      - Set Up Continuous Evaluation: tutorials/09-build-production-evaluation-pipeline.md
  - How-To Guides:
      - how-to/index.md
      - Evaluate Structured Generation: how-to/evaluate-structured-generation.md
      - Debug Slow Evaluations: how-to/debug-slow-evaluations.md
      - Handle Rate Limits and API Errors: how-to/handle-rate-limits-and-api-errors.md
      - Work with Custom Data Formats: how-to/work-with-custom-data-formats.md
      - Resume Failed Evaluations: how-to/resume-failed-evaluations.md
      - Create a Dataset Plugin: how-to/create-dataset-plugin.md
      - Create a Model Provider Plugin: how-to/create-model-provider-plugin.md
      - Create an Evaluator Plugin: how-to/create-evaluator-plugin.md
  - Explanation:
      - explanation/index.md
      - Design Principles: explanation/design-principles.md
      - Control Plane Architecture: explanation/control-plane-architecture.md
      - Plugin Architecture: explanation/plugin-architecture.md
      - Core Concepts:
          - explanation/core-concepts/index.md
          - The @foreach Decorator: explanation/core-concepts/foreach-decorator.md
          - Result Models and Scoring: explanation/core-concepts/result-models-scoring.md
          - Session Management: explanation/core-concepts/session-management.md
          - Registry Architecture: explanation/core-concepts/registry-architecture.md
  - Reference:
      - reference/index.md
      - Running Evaluations: reference/running-evaluations.md
      - "@foreach Decorator": reference/foreach.md
      - CLI: reference/cli.md
      - Evaluators: reference/evaluators.md
      - Metrics: reference/metrics.md
      - Experiments: reference/experiments.md
      - Storage Backends: reference/storage.md
      - Pytest Integration: reference/pytest.md
      - Async Evaluations: reference/async.md
      - Data Handling: reference/datasets.md
  - API Reference:
      - api/index.md
      - Core: api/core.md
      - Models: api/models.md
      - Evaluators: api/evaluators.md
      - Metrics: api/metrics.md
      - Datasets: api/datasets.md
      - Sessions: api/sessions.md
      - CLI: api/cli.md
      - Plugin: api/plugin.md
