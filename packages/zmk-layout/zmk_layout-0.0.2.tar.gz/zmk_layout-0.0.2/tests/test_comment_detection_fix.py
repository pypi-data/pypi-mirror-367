"""Comprehensive tests for multi-line comment detection fix in dt_parser.py.

This module tests three different approaches for comment detection that replaced
the original bogus startswith("/*") detection:

1. **Regex-based detection**: Using regex patterns to identify comment types
2. **Lark-based detection**: Using SINGLE_LINE_COMMENT and MULTI_LINE_COMMENT tokens from Lark grammar
3. **Tokenizer-based detection**: Using specific comment token types in the custom tokenizer (current)

The tests ensure all approaches correctly distinguish between single-line (//) and
multi-line (/* */) comments, with the tokenizer-based approach being the primary
solution and Lark parser remaining independent.
"""

import re

import pytest

from zmk_layout.parsers.dt_parser import parse_dt_lark_safe, parse_dt_safe
from zmk_layout.parsers.tokenizer import TokenType, tokenize_dt


class TestTokenizerCommentDetection:
    """Tests for the tokenizer-based comment detection using specific token types."""

    @pytest.mark.parametrize(
        "comment_text, expected_token_type",
        [
            # Single-line comments should produce SINGLE_LINE_COMMENT tokens
            ("// This is a single line comment", TokenType.SINGLE_LINE_COMMENT),
            ("//", TokenType.SINGLE_LINE_COMMENT),
            ("// with some // internal slashes", TokenType.SINGLE_LINE_COMMENT),
            ("// /* this is not a block */", TokenType.SINGLE_LINE_COMMENT),
            # Multi-line comments should produce MULTI_LINE_COMMENT tokens
            ("/* This is a block comment */", TokenType.MULTI_LINE_COMMENT),
            ("/* Multi\nline\ncomment */", TokenType.MULTI_LINE_COMMENT),
            ("/**/", TokenType.MULTI_LINE_COMMENT),  # Empty block
            ("/*   */", TokenType.MULTI_LINE_COMMENT),  # Block with spaces
            ("/*\t*/", TokenType.MULTI_LINE_COMMENT),  # Block with tabs
            ("/*\n*/", TokenType.MULTI_LINE_COMMENT),  # Block with only newlines
            ("/*\r\n*/", TokenType.MULTI_LINE_COMMENT),  # Block with CRLF newlines
            ("/* !@#$%^&*()_+-={}[]|:;\"'<>,.?/`~ */", TokenType.MULTI_LINE_COMMENT),
            ("/* outer /* inner */", TokenType.MULTI_LINE_COMMENT),  # Non-greedy match
            ("/* leading space */", TokenType.MULTI_LINE_COMMENT),
            ("/*trailing space */", TokenType.MULTI_LINE_COMMENT),
            ("/*\n\n\n*/", TokenType.MULTI_LINE_COMMENT),  # Multiple newlines
            ("/* line 1\n * line 2\n * line 3\n */", TokenType.MULTI_LINE_COMMENT),
            # Preprocessor directives should produce PREPROCESSOR tokens
            ("#define FOO", TokenType.PREPROCESSOR),
            ("#ifdef BAR", TokenType.PREPROCESSOR),
            ("#else", TokenType.PREPROCESSOR),
            ("#endif", TokenType.PREPROCESSOR),
            ("#include <file.h>", TokenType.PREPROCESSOR),
        ],
    )
    def test_tokenizer_produces_correct_token_types(
        self, comment_text: str, expected_token_type: TokenType
    ) -> None:
        """Test that the tokenizer produces the correct specific comment token types."""
        tokens = tokenize_dt(comment_text)
        assert len(tokens) > 0, f"No tokens produced for: {comment_text}"

        # Find the comment token (should be first non-whitespace token)
        comment_token = None
        for token in tokens:
            if token.type in (
                TokenType.SINGLE_LINE_COMMENT,
                TokenType.MULTI_LINE_COMMENT,
                TokenType.PREPROCESSOR,
            ):
                comment_token = token
                break

        assert comment_token is not None, f"No comment token found for: {comment_text}"
        assert comment_token.type == expected_token_type, (
            f"Expected {expected_token_type.value}, got {comment_token.type.value} for: {comment_text}"
        )

    def test_tokenizer_comment_content_preservation(self) -> None:
        """Test that tokenizer preserves the full comment content."""
        test_cases = [
            "// Single line with special chars: !@#$%",
            "/* Multi-line\n * with asterisks\n * and formatting */",
            "#include <dt-bindings/zmk/keys.h>",
        ]

        for comment_text in test_cases:
            tokens = tokenize_dt(comment_text)
            comment_tokens = [
                t
                for t in tokens
                if t.type
                in (
                    TokenType.SINGLE_LINE_COMMENT,
                    TokenType.MULTI_LINE_COMMENT,
                    TokenType.PREPROCESSOR,
                )
            ]
            assert len(comment_tokens) == 1, (
                f"Expected 1 comment token, got {len(comment_tokens)}"
            )
            assert comment_tokens[0].value == comment_text, (
                f"Content mismatch: expected '{comment_text}', got '{comment_tokens[0].value}'"
            )


class TestLarkCommentDetection:
    """Tests for the Lark-based comment detection using grammar tokens."""

    def test_lark_parser_comment_independence(self) -> None:
        """Test that Lark parser handles comments independently from custom parser."""
        dts_with_comments = """
        // Single line comment
        /* Multi-line
           comment */
        / {
            compatible = "test,device";
            test_node {
                prop = <0x123>;
            };
        };
        """

        # Test that Lark parser works (though comment handling may differ)
        roots, errors = parse_dt_lark_safe(dts_with_comments)
        assert len(errors) == 0, f"Lark parser should not have errors: {errors}"
        assert len(roots) > 0, "Lark parser should produce at least one root node"

        root = roots[0]
        assert root.get_property("compatible") is not None, (
            "Should parse compatible property"
        )
        assert root.get_child("test_node") is not None, "Should parse child node"

    def test_lark_parser_vs_custom_parser_compatibility(self) -> None:
        """Test that both parsers can handle the same basic DTS content."""
        basic_dts = """
        / {
            compatible = "test,device";
            reg = <0x1000 0x100>;
            status = "okay";
        };
        """

        # Test custom parser
        custom_root, custom_errors = parse_dt_safe(basic_dts)
        assert len(custom_errors) == 0, "Custom parser should not have errors"
        assert custom_root is not None, "Custom parser should produce root"

        # Test Lark parser
        lark_roots, lark_errors = parse_dt_lark_safe(basic_dts)
        assert len(lark_errors) == 0, "Lark parser should not have errors"
        assert len(lark_roots) > 0, "Lark parser should produce roots"

        lark_root = lark_roots[0]

        # Both should parse the same properties
        assert custom_root.get_property("compatible") is not None
        assert custom_root.get_property("reg") is not None
        assert custom_root.get_property("status") is not None

        assert lark_root.get_property("compatible") is not None
        assert lark_root.get_property("reg") is not None
        assert lark_root.get_property("status") is not None


class TestRegexCommentDetection:
    """Direct tests for the regex-based multi-line comment detection logic."""

    @pytest.mark.parametrize(
        "comment_text, expected_is_block",
        [
            # Single-line comments should be False
            ("// This is a single line comment", False),
            ("//", False),
            ("// with some // internal slashes", False),
            ("// /* this is not a block */", False),
            ("//Multi-line\ntext in single line comment", False),
            # Multi-line comments should be True
            ("/* This is a block comment */", True),
            ("/* Multi\nline\ncomment */", True),
            ("/**/", True),  # Empty block
            ("/*   */", True),  # Block with spaces
            ("/*\t*/", True),  # Block with tabs
            ("/*\n*/", True),  # Block with only newlines
            ("/*\r\n*/", True),  # Block with CRLF newlines
            ("/* !@#$%^&*()_+-={}[]|:;\"'<>,.?/`~ */", True),  # Special chars
            # Edge cases for multi-line comments
            ("/* outer /* inner */", True),  # Non-greedy match should stop at first */
            ("/* leading space */", True),
            ("/*trailing space */", True),
            ("/*\n\n\n*/", True),  # Multiple newlines
            ("/*\n  line 2\n*/", True),
            ("/* line 1\n * line 2\n * line 3\n */", True),  # Standard format
            # Preprocessor directives should be False
            ("#define FOO", False),
            ("#ifdef BAR", False),
            ("#else", False),
            ("#endif", False),
            ("#include <file.h>", False),
            # Malformed/edge inputs
            ("/*", False),  # Just opening (incomplete)
            ("*/", False),  # Just closing
            ("", False),  # Empty string
            ("not a comment", False),
            ("/* unclosed comment", False),  # Unclosed block
            ("regular text /* with block */ inside", False),  # Mixed content
        ],
    )
    def test_regex_detection_accuracy(
        self, comment_text: str, expected_is_block: bool
    ) -> None:
        """Test the exact regex logic used at line 606 in dt_parser.py."""
        # This is the exact regex from the fix
        is_block = bool(re.match(r"/\*(.|\n)*?\*/", comment_text, re.DOTALL))
        assert is_block == expected_is_block, (
            f"Comment '{comment_text}' expected is_block={expected_is_block}, got {is_block}"
        )

    def test_regex_dotall_flag_importance(self) -> None:
        """Verify DOTALL flag is essential for multi-line comment detection."""
        multiline_comment = "/*\nLine 1\nLine 2\n*/"

        # With DOTALL flag (correct behavior)
        with_dotall = bool(re.match(r"/\*(.|\n)*?\*/", multiline_comment, re.DOTALL))

        # Without DOTALL flag - note: (.|\n) pattern still works because it explicitly includes \n
        # So let's test with a pattern that would truly fail without DOTALL
        without_dotall = bool(
            re.match(r"/\*.*?\*/", multiline_comment)
        )  # . doesn't match newlines without DOTALL

        assert with_dotall is True, "DOTALL flag should enable multi-line matching"
        assert without_dotall is False, (
            "Without DOTALL, . doesn't match newlines in multi-line comments"
        )

    def test_regex_non_greedy_matching(self) -> None:
        """Verify non-greedy matching stops at first */ occurrence."""
        nested_style = "/* outer /* inner */ more */"

        match = re.match(r"/\*(.|\n)*?\*/", nested_style, re.DOTALL)
        assert match is not None
        # Should match only until first */
        assert match.group() == "/* outer /* inner */"


class TestParserCommentDetection:
    """Integration tests for comment detection within the full parser workflow."""

    def test_single_line_comment_detection(self) -> None:
        """Test single-line comment detection in parser context."""
        dts_content = """
        // Single line comment
        / {
            test = "value";
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None
        assert len(root.comments) == 1

        comment = root.comments[0]
        assert comment.text == "// Single line comment"
        assert comment.is_block is False

    def test_multi_line_comment_detection(self) -> None:
        """Test multi-line comment detection in parser context."""
        dts_content = """
        /*
         * Multi-line comment
         * with proper formatting
         */
        / {
            test = "value";
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None
        assert len(root.comments) == 1

        comment = root.comments[0]
        assert "Multi-line comment" in comment.text
        assert comment.is_block is True

    def test_mixed_comment_types(self) -> None:
        """Test mixed single-line and multi-line comments."""
        dts_content = """
        // Single line 1
        /* Block comment 1 */
        // Single line 2
        /*
         * Multi-line block
         * comment 2
         */
        / {
            test = "value";
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None
        assert len(root.comments) == 4

        # Verify comment types
        assert root.comments[0].is_block is False  # Single line 1
        assert root.comments[1].is_block is True  # Block comment 1
        assert root.comments[2].is_block is False  # Single line 2
        assert root.comments[3].is_block is True  # Multi-line block

    def test_empty_and_minimal_block_comments(self) -> None:
        """Test edge cases with empty and minimal block comments."""
        dts_content = """
        /**/
        /*  */
        /* x */
        / {
            test = "value";
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None
        assert len(root.comments) == 3

        # All should be detected as block comments
        assert all(comment.is_block for comment in root.comments)

    def test_preprocessor_directives_as_non_block_comments(self) -> None:
        """Test that preprocessor directives are not detected as block comments."""
        dts_content = """
        #include <dt-bindings/zmk/keys.h>
        #define TEST_MACRO 1
        #ifdef CONFIG_TEST
        #else
        #endif
        / {
            test = "value";
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None
        assert len(root.comments) == 5

        # All preprocessor directives should be non-block comments
        assert all(not comment.is_block for comment in root.comments)


class TestZMKKeymapIntegration:
    """Test comment detection in realistic ZMK keymap scenarios."""

    def test_zmk_keymap_with_mixed_comments(self) -> None:
        """Test comment detection in a realistic ZMK keymap structure."""
        zmk_keymap = """
        #include <behaviors.dtsi>
        #include <dt-bindings/zmk/keys.h>

        /*
         * ZMK Keymap Configuration
         * 36-key layout with home row mods
         */

        / {
            keymap {
                compatible = "zmk,keymap";

                // Default layer
                default_layer {
                    bindings = <
                        // First row
                        &kp Q &kp W &kp E &kp R &kp T   &kp Y &kp U  &kp I     &kp O   &kp P
                        // Home row with mods
                        &kp A &kp S &kp D &kp F &kp G   &kp H &kp J  &kp K     &kp L   &kp SEMI
                        /*
                         * Bottom row
                         * Z-X-C-V-B on left
                         */
                        &kp Z &kp X &kp C &kp V &kp B   &kp N &kp M  &kp COMMA &kp DOT &kp FSLH
                                     &kp LGUI  &kp SPC   &kp RET  &kp RALT
                    >;
                };
            };
        };
        """

        root, errors = parse_dt_safe(zmk_keymap)
        assert len(errors) == 0
        assert root is not None

        # Count comments by type
        single_line_count = sum(1 for comment in root.comments if not comment.is_block)
        multi_line_count = sum(1 for comment in root.comments if comment.is_block)

        # Should have comments (exact counts may vary based on comment association logic)
        total_comments = len(root.comments)
        assert total_comments > 0, "Should have collected some comments"

        # Should have both single-line and multi-line comments if any comments found
        if total_comments > 0:
            assert single_line_count > 0 or multi_line_count > 0, (
                "Should have at least one type of comment"
            )

        # Verify at least some expected comment content exists
        comment_texts = [comment.text for comment in root.comments]
        has_expected_comments = any(
            phrase in text
            for text in comment_texts
            for phrase in ["ZMK", "keymap", "layer", "row"]
        )
        if total_comments > 0:
            assert has_expected_comments, (
                f"Expected ZMK-related comments, got: {comment_texts[:3]}"
            )

    def test_zmk_behavior_definitions_with_comments(self) -> None:
        """Test comment detection in ZMK behavior definitions."""
        zmk_behaviors = """
        #include <dt-bindings/zmk/keys.h>

        / {
            behaviors {
                // Home row mod-tap behavior
                hm: homerow_mods {
                    compatible = "zmk,behavior-hold-tap";
                    /*
                     * Timing configuration
                     * - tapping-term-ms: how long to wait
                     * - quick-tap-ms: quick tap threshold
                     */
                    tapping-term-ms = <200>;
                    quick-tap-ms = <0>;
                    flavor = "tap-preferred";
                    bindings = <&kp>, <&kp>;
                };
            };
        };
        """

        root, errors = parse_dt_safe(zmk_behaviors)
        assert len(errors) == 0
        assert root is not None

        # Find behavior-specific comments
        behavior_comments = []
        for comment in root.comments:
            if any(
                phrase in comment.text.lower()
                for phrase in ["home", "timing", "behavior", "configuration"]
            ):
                behavior_comments.append(comment)

        # Should have at least one behavior-related comment (but comment association may vary)
        # The main goal is to verify the parser handles complex ZMK structures correctly
        total_comments = len(root.comments)
        assert total_comments > 0, (
            f"Should have some comments in ZMK behavior definition, got: {[c.text for c in root.comments[:3]]}"
        )


class TestCommentAssociation:
    """Test how comments with correct is_block detection are associated with nodes/properties."""

    def test_node_comment_association_respects_comment_type(self) -> None:
        """Test that node comment association works regardless of comment type."""
        dts_content = """
        // Single line node comment
        test_node {
            prop = "value";
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None

        node = root.get_child("test_node")
        assert node is not None
        assert len(node.comments) >= 1

        # Find the associated comment
        associated_comment = next(
            (c for c in node.comments if "Single line node comment" in c.text), None
        )
        assert associated_comment is not None
        assert associated_comment.is_block is False

    def test_property_comment_association_with_block_comment(self) -> None:
        """Test property comment association with multi-line comments."""
        dts_content = """
        / {
            node {
                /*
                 * Property comment
                 * with multiple lines
                 */
                my_prop = "value";
            };
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None

        node = root.get_child("node")
        assert node is not None

        prop = node.get_property("my_prop")
        assert prop is not None

        # Property comment association may vary based on proximity rules
        # The key thing is that the comment was correctly detected as a block comment
        # Check if it's associated with property or parent node
        has_property_comment = len(prop.comments) > 0
        has_node_comment = any("Property comment" in c.text for c in node.comments)

        assert has_property_comment or has_node_comment, (
            "Block comment should be associated with property or parent node"
        )


class TestEdgeCasesAndErrorHandling:
    """Test edge cases and error handling scenarios."""

    def test_malformed_comment_handling(self) -> None:
        """Test handling of malformed comments."""
        dts_content = """
        /* Unclosed comment
        / {
            test = "value";
        };
        """

        # Should not crash, but may have errors
        root, errors = parse_dt_safe(dts_content)

        # Parser should be resilient to malformed comments
        assert root is not None
        # May have parsing errors, but should not crash

    def test_very_large_comment_blocks(self) -> None:
        """Test handling of very large comment blocks."""
        large_comment_content = "Very long comment content. " * 1000
        dts_content = f"""
        /*
         {large_comment_content}
         */
        / {{
            test = "value";
        }};
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None
        assert len(root.comments) >= 1

        # Verify large comment is detected as block comment
        large_comment = next(
            (c for c in root.comments if "Very long comment" in c.text), None
        )
        assert large_comment is not None
        assert large_comment.is_block is True

    def test_comments_with_special_characters_and_unicode(self) -> None:
        """Test comment detection with special characters and unicode."""
        dts_content = """
        // Comment with special chars: !@#$%^&*()_+-={}[]|:;"'<>,.?/`~
        /* Block comment with unicode: αβγδε 中文 🚀 */
        / {
            test = "value";
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None
        assert len(root.comments) == 2

        # Verify both comments are correctly detected
        assert root.comments[0].is_block is False
        assert root.comments[1].is_block is True

    def test_nested_comment_style_handling(self) -> None:
        """Test handling of nested-style comments (not true nesting)."""
        dts_content = """
        /* Outer /* inner comment style */ remaining */
        / {
            test = "value";
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert root is not None

        # Should have at least one comment
        if root.comments:
            # First comment should be detected as block comment
            first_comment = root.comments[0]
            assert first_comment.is_block is True
            # Should only match until first */ (non-greedy)
            assert first_comment.text == "/* Outer /* inner comment style */"


class TestRegressionAndBackwardCompatibility:
    """Regression tests to ensure the fix doesn't break existing functionality."""

    def test_existing_parser_functionality_unchanged(self) -> None:
        """Ensure basic parser functionality is unchanged."""
        dts_content = """
        / {
            compatible = "test,device";
            reg = <0x1000 0x100>;
            status = "okay";

            child_node {
                property = "value";
            };
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None

        # Verify basic parsing still works
        assert root.get_property("compatible") is not None
        assert root.get_property("reg") is not None
        assert root.get_property("status") is not None
        assert root.get_child("child_node") is not None

    def test_comment_parsing_with_complex_nodes(self) -> None:
        """Test comment parsing doesn't interfere with complex node structures."""
        dts_content = """
        // Root comment
        / {
            // Node comment
            complex_node@1000 {
                compatible = "test,complex";
                reg = <0x1000 0x100>;

                /* Property block comment */
                array_prop = <1 2 3 4>;
                string_array = "item1", "item2";

                // Nested node comment
                nested@2000 {
                    /* Nested property comment */
                    nested_prop = &some_reference;
                };
            };
        };
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None

        # Verify complex structure is parsed correctly
        complex_node = None
        for child_name, child_node in root.children.items():
            if "complex_node" in child_name:
                complex_node = child_node
                break

        assert complex_node is not None, (
            f"Should find complex_node, got children: {list(root.children.keys())}"
        )
        assert complex_node.unit_address == "1000"

        nested_node = None
        for child_name, child_node in complex_node.children.items():
            if "nested" in child_name:
                nested_node = child_node
                break

        assert nested_node is not None, (
            f"Should find nested node, got children: {list(complex_node.children.keys())}"
        )
        assert nested_node.unit_address == "2000"

        # Verify comments are present and correctly typed
        total_comments = len(root.comments)
        for child in root.children.values():
            total_comments += len(child.comments)
            for nested in child.children.values():
                total_comments += len(nested.comments)

        assert total_comments > 0, "Should have collected comments from various levels"

    @pytest.mark.parametrize(
        "comment_style",
        [
            "// Single line",
            "/* Single line block */",
            "/*\n * Multi-line\n * block comment\n */",
            "#define PREPROCESSOR_DIRECTIVE",
        ],
    )
    def test_comment_detection_consistency_across_styles(
        self, comment_style: str
    ) -> None:
        """Test that comment detection is consistent across different comment styles."""
        dts_content = f"""
        {comment_style}
        / {{
            test = "value";
        }};
        """

        root, errors = parse_dt_safe(dts_content)
        assert len(errors) == 0
        assert root is not None
        assert len(root.comments) >= 1

        comment = root.comments[0]
        assert comment.text == comment_style

        # Verify is_block detection based on comment style
        if comment_style.startswith("//") or comment_style.startswith("#"):
            assert comment.is_block is False
        elif comment_style.startswith("/*"):
            assert comment.is_block is True


class TestAllApproachesComparison:
    """Integration tests comparing all three comment detection approaches."""

    @pytest.mark.parametrize(
        "comment_text, expected_is_block",
        [
            # Test cases that should work consistently across all approaches
            ("// Single line comment", False),
            ("/* Block comment */", True),
            ("/*\n * Multi-line\n * comment\n */", True),
            ("/**/", True),
            ("/* with spaces */", True),
        ],
    )
    def test_all_approaches_agree_on_comment_type(
        self, comment_text: str, expected_is_block: bool
    ) -> None:
        """Test that regex, tokenizer, and parser all agree on comment classification."""

        # 1. Test regex approach (direct)
        regex_result = bool(re.match(r"/\*(.|\n)*?\*/", comment_text, re.DOTALL))

        # 2. Test tokenizer approach
        tokens = tokenize_dt(comment_text)
        tokenizer_result = None
        for token in tokens:
            if token.type == TokenType.SINGLE_LINE_COMMENT:
                tokenizer_result = False
                break
            elif token.type == TokenType.MULTI_LINE_COMMENT:
                tokenizer_result = True
                break

        # 3. Test parser approach (via DTParser)
        dts = f'{comment_text}\n/ {{ test = "value"; }};'
        root, errors = parse_dt_safe(dts)
        parser_result = None
        if not errors and root and root.comments:
            parser_result = root.comments[0].is_block

        # All approaches should agree on the result
        if comment_text.startswith("//"):
            # Single line comments
            assert not regex_result, "Regex should identify // as single-line"
            assert not tokenizer_result, "Tokenizer should identify // as single-line"
            assert not parser_result, "Parser should identify // as single-line"
        elif comment_text.startswith("/*") and comment_text.endswith("*/"):
            # Block comments
            assert regex_result, "Regex should identify /* */ as block"
            assert tokenizer_result, "Tokenizer should identify /* */ as block"
            assert parser_result, "Parser should identify /* */ as block"

        # Final consistency check
        if tokenizer_result is not None and parser_result is not None:
            assert tokenizer_result == parser_result == expected_is_block, (
                f"Approaches disagree: tokenizer={tokenizer_result}, parser={parser_result}, expected={expected_is_block}"
            )

    def test_architectural_separation(self) -> None:
        """Test that different parsers work independently without interference."""
        test_dts = """
        // Single line comment
        /* Multi-line comment */
        / {
            compatible = "test,device";
            test_node {
                prop = <0x123>;
            };
        };
        """

        # Custom parser (primary)
        custom_root, custom_errors = parse_dt_safe(test_dts)
        assert len(custom_errors) == 0, "Custom parser should work"
        assert custom_root is not None, "Custom parser should produce root"

        # Lark parser (independent)
        lark_roots, lark_errors = parse_dt_lark_safe(test_dts)
        assert len(lark_errors) == 0, "Lark parser should work independently"
        assert len(lark_roots) > 0, "Lark parser should produce results"

        # Both should parse the structure correctly
        custom_node = custom_root.get_child("test_node")
        lark_node = lark_roots[0].get_child("test_node")

        assert custom_node is not None, "Custom parser should find test_node"
        assert lark_node is not None, "Lark parser should find test_node"

        assert custom_node.get_property("prop") is not None, (
            "Custom parser should find prop"
        )
        assert lark_node.get_property("prop") is not None, (
            "Lark parser should find prop"
        )

    @pytest.mark.performance
    def test_performance_and_fallback_behavior(self) -> None:
        """Test that fallback mechanisms work correctly."""

        # Test with a well-formed challenging comment (non-greedy matching)
        challenging_comment = "/* Complex /* inner */ comment */"
        dts_with_challenging = f'{challenging_comment}\n/ {{ test = "value"; }};'

        # The parser may have parsing challenges with this specific pattern,
        # but should not crash - let's test that both approaches handle it
        root, errors = parse_dt_safe(dts_with_challenging)
        # Note: This may produce errors due to the nested comment syntax, which is expected
        assert root is not None or len(errors) > 0, (
            "Should either parse successfully or report errors gracefully"
        )

        # Test tokenizer directly
        tokens = tokenize_dt(challenging_comment)
        comment_tokens = [
            t
            for t in tokens
            if t.type in (TokenType.SINGLE_LINE_COMMENT, TokenType.MULTI_LINE_COMMENT)
        ]
        assert len(comment_tokens) >= 1, "Should tokenize challenging comment"

        # Test Lark parser independence
        lark_roots, lark_errors = parse_dt_lark_safe(dts_with_challenging)
        # Lark may or may not handle this specific case, but shouldn't crash
        assert isinstance(lark_roots, list), "Lark should return list"
        assert isinstance(lark_errors, list), "Lark should return error list"


if __name__ == "__main__":
    pytest.main([__file__])
