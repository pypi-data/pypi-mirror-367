workdir = "aiforge_work"
max_tokens = 4096
max_rounds = 2
max_optimization_attempts = 3
default_llm_provider = "openrouter"

[llm.openrouter]
type = "openai"
model = "deepseek/deepseek-chat-v3-0324:free"
api_key = ""
base_url = "https://openrouter.ai/api/v1"
timeout = 30
max_tokens = 8192

[llm.grok]
type = "grok"
model = "xai/grok-3"
api_key = ""
base_url = "https://api.x.ai/v1/"
timeout = 30
max_tokens = 8192

[llm.qwen]
type = "openai"
model = "openai/qwen-plus"
api_key = ""
base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
timeout = 30
max_tokens = 8192

[llm.gemini]
type = "gemini"
model = "gemini/gemini-2.0-flash"
api_key = ""
base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"
timeout = 30
max_tokens = 8192

[llm.ollama]
type = "ollama"
model = "llama3"
api_key = ""
base_url = "http://localhost:11434"
timeout = 30
max_tokens = 8192

[llm.deepseek]
type = "deepseek"
model = "deepseek-chat"
api_key = ""
base_url = "https://api.deepseek.com"
timeout = 30
max_tokens = 8192

[cache.code]
enabled = true
max_modules = 20
failure_threshold = 0.8
max_age_days = 30
cleanup_interval = 10
semantic_threshold = 0.6
enable_semantic_matching = true
use_lightweight_semantic = false
enable_action_clustering = true
action_cluster_threshold = 0.75

[optimization]
enabled = false
aggressive_minify = true
max_feedback_length = 200
obfuscate_variables = true


# 在配置文件中添加扩展部分  
[extensions]
enabled = true
auto_load = true
extension_dir = "extensions"

[[extensions.registered]]
name = "custom_executor"
type = "executor"
config = {}


# 示例
[[extensions.registered]]
name = "custom_data_processor"
type = "executor"
module_path = "my_plugins.data_processor"
class_name = "CustomDataProcessor"
priority = 1

[[extensions.registered]]
name = "domain_specific_executor"
type = "executor"
config_file = "plugins/domain_executor.toml"
