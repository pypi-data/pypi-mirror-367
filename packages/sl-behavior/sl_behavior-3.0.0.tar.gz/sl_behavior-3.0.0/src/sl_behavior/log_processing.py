"""This module contains the functions used to parse the log data generated by the current Sun lab data acquisition
systems. Specifically, the tools provided by this module read the compressed .npz log files and extract the necessary
data as .feather files, used during later data processing stages.
"""

from typing import Any
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed

from tqdm import tqdm
from numba import njit  # type: ignore
import numpy as np
import polars as pl
from numpy.typing import NDArray
from numpy.lib.npyio import NpzFile
from sl_shared_assets import (
    SessionData,
    SessionTypes,
    ExperimentTrial,
    TrackerFileNames,
    AcquisitionSystems,
    MesoscopeHardwareState,
    MesoscopeExperimentConfiguration,
    get_processing_tracker,
    generate_project_manifest,
)
from ataraxis_video_system import extract_logged_video_system_data
from ataraxis_base_utilities import LogLevel, console
from ataraxis_communication_interface import ExtractedModuleData, extract_logged_hardware_module_data

# Stores acquisition systems supported by this library as a set.
_supported_acquisition_systems = {AcquisitionSystems.MESOSCOPE_VR}
_supported_session_types = {SessionTypes.MESOSCOPE_EXPERIMENT, SessionTypes.RUN_TRAINING, SessionTypes.LICK_TRAINING}


def _prepare_motif_data(
    trial_motifs: list[NDArray[np.uint8]], trial_distances: list[float]
) -> tuple[NDArray[np.uint8], NDArray[np.int32], NDArray[np.int32], NDArray[np.int32], NDArray[np.float32]]:
    """Prepares the flattened trial motif data for faster cue sequence-to-trial decomposition (conversion).

    Args:
        trial_motifs: A list of trial motifs (wall cue sequences) used by the processed session, in the format of
            numpy arrays.
        trial_distances: A list of trial distances in centimeters. Should match the order of items inside the
            trial_motifs list.

    Returns:
        A tuple containing five elements. The first element is a flattened array of all motifs. The second
        element is an array that stores the starting indices of each motif in the flat array. The third element is
        an array that stores the length of each motif. The fourth element is an array that stores the original
        indices of motifs before sorting. The fifth element is an array of trial distances in centimeters.
    """
    # Sorts motifs by length (longest first)
    motif_data: list[tuple[int, NDArray[np.uint8], int]] = [
        (i, motif, len(motif)) for i, motif in enumerate(trial_motifs)
    ]
    motif_data.sort(key=lambda x: x[2], reverse=True)

    # Calculates total size needed to represent all motifs in an array.
    total_size: int = sum(len(motif) for motif in trial_motifs)
    num_motifs: int = len(trial_motifs)

    # Creates arrays with specified dtypes.
    motifs_flat: NDArray[np.uint8] = np.zeros(total_size, dtype=np.uint8)
    motif_starts: NDArray[np.int32] = np.zeros(num_motifs, dtype=np.int32)
    motif_lengths: NDArray[np.int32] = np.zeros(num_motifs, dtype=np.int32)
    motif_indices: NDArray[np.int32] = np.zeros(num_motifs, dtype=np.int32)

    # Fills the arrays
    current_pos: int = 0
    for i, (orig_idx, motif, length) in enumerate(motif_data):
        # Ensures motifs are stored as uint8
        motif_uint8 = motif.astype(np.uint8) if motif.dtype != np.uint8 else motif
        motifs_flat[current_pos : current_pos + length] = motif_uint8
        motif_starts[i] = current_pos
        motif_lengths[i] = length
        motif_indices[i] = orig_idx
        current_pos += length

    # Converts distances to float32 type
    distances_array: NDArray[np.float32] = np.array(trial_distances, dtype=np.float32)

    return motifs_flat, motif_starts, motif_lengths, motif_indices, distances_array


@njit(cache=True)  # type: ignore
def _decompose_sequence_numba_flat(
    cue_sequence: NDArray[np.uint8],
    motifs_flat: NDArray[np.uint8],
    motif_starts: NDArray[np.int32],
    motif_lengths: NDArray[np.int32],
    motif_indices: NDArray[np.int32],
    max_trials: int,
) -> tuple[NDArray[np.int32], int]:
    """Decomposes a long sequence of Virtual Reality (VR) wall cues into individual trial motifs.

    This is a worker function used to speed up decomposition via numba-acceleration.

    Args:
        cue_sequence: The full cue sequence to decompose.
        motifs_flat: All motifs concatenated into a single 1D array.
        motif_starts: Starting index of each motif in motifs_flat.
        motif_lengths: The length of each motif.
        motif_indices: Original indices of motifs (before sorting).
        max_trials: The maximum number of trials that can make up the cue sequence.

    Returns:
        A tuple of two elements. The first element stores the array of trial type-indices (the sequence of trial
        type indices). The second element stores the total number of trials extracted from the cue sequence.
    """
    # Prepares runtime trackers
    trial_indices = np.zeros(max_trials, dtype=np.int32)
    trial_count = 0
    sequence_pos = 0
    sequence_length = len(cue_sequence)
    num_motifs = len(motif_lengths)

    # Decomposes the sequence into trial motifs using greedy matching. Longer motifs are matched over shorter ones.
    # Pre-specifying the maximum number of trials serves as a safety feature to avoid processing errors.
    while sequence_pos < sequence_length and trial_count < max_trials:
        motif_found = False

        for i in range(num_motifs):
            motif_length = motif_lengths[i]

            # If the current sequence position is within the bounds of the motif, checks if it matches the motif.
            if sequence_pos + motif_length <= sequence_length:
                # Gets motif start position from the flat array
                motif_start = motif_starts[i]

                # Checks if the motif matches the evaluated sequence.
                match = True
                for j in range(motif_length):
                    if cue_sequence[sequence_pos + j] != motifs_flat[motif_start + j]:
                        match = False
                        break
                # If the motif matches, records the trial type index and moves to the next sequence position.
                if match:
                    trial_indices[trial_count] = motif_indices[i]
                    trial_count += 1
                    sequence_pos += motif_length
                    motif_found = True
                    break
        # If the function is not able to pair a part of the sequence with a motif, aborts with an error.
        if not motif_found:
            return trial_indices, -1

    return trial_indices[:trial_count], trial_count


def _decompose_multiple_cue_sequences_into_trials(
    experiment_configuration: MesoscopeExperimentConfiguration,
    cue_sequences: list[NDArray[np.uint8]],
    distance_breakpoints: list[np.float64],
) -> tuple[NDArray[np.int32], NDArray[np.float64]]:
    """Decomposes multiple Virtual Reality (VR) task wall cue sequences into a unified sequence of trials.

    Handles cases where the original sequence was interrupted and a new sequence was generated. Uses distance
    breakpoints to stitch sequences together correctly.

    Args:
        experiment_configuration: The initialized ExperimentConfiguration instance for which to parse the trial data.
        cue_sequences: A list of cue sequences in the order they were used during runtime.
        distance_breakpoints: A list of cumulative distances (in centimeters) at which each sequence ends. Should have
            the same number of elements as the number of cue sequences - 1.

    Returns:
        A tuple of two elements. The first element is an array of trial type indices in the order encountered at
        runtime. The second element is an array of cumulative distances at the end of each trial.

    Raises:
        ValueError: If the number of breakpoints doesn't match the number of sequences - 1.
        RuntimeError: If the function is not able to fully decompose any of the cue sequences.
    """

    # Validates inputs
    if len(cue_sequences) == 0:
        message = (
            f"Unable to decompose input cue sequence(s) into trials. Expected at least one cue sequence as input, but "
            f"received none."
        )
        console.error(message=message, error=ValueError)

    if len(cue_sequences) > 1 and len(distance_breakpoints) != len(cue_sequences) - 1:
        message = (
            f"Unable to decompose input cue sequence(s) into trials. Expected the number of distance breakpoints "
            f"to be ({len(cue_sequences) - 1} (number of sequences - 1), but encountered ({len(distance_breakpoints)})."
        )
        console.error(message=message, error=ValueError)

    # Extracts the list of trial structures supported by the processed experiment runtime
    trials: list[ExperimentTrial] = [trial for trial in experiment_configuration.trial_structures.values()]

    # Extracts trial motif (cue sequences for each trial type) and their corresponding distances in cm
    trial_motifs: list[NDArray[np.uint8]] = [np.array(trial.cue_sequence, dtype=np.uint8) for trial in trials]
    trial_distances: list[float] = [float(trial.trial_length_cm) for trial in trials]

    # Prepares the flattened motif data
    motifs_flat, motif_starts, motif_lengths, motif_indices, distances_array = _prepare_motif_data(
        trial_motifs, trial_distances
    )

    # Estimates the maximum number of trials across all sequences
    min_motif_length = min(len(motif) for motif in trial_motifs)
    total_cue_length = sum(len(seq) for seq in cue_sequences)
    max_trials = total_cue_length // min_motif_length + 1

    # Processes each sequence and collects results
    all_trial_indices: list[int] = []
    all_trial_distances: list[float] = []
    cumulative_distance = 0.0

    for seq_idx, cue_sequence in enumerate(cue_sequences):
        # Decomposes the current sequence
        trial_indices_array, trial_count = _decompose_sequence_numba_flat(
            cue_sequence, motifs_flat, motif_starts, motif_lengths, motif_indices, max_trials
        )

        # Checks for decomposition errors
        if trial_count == -1:
            # Finds the position where decomposition failed
            sequence_pos = 0
            trial_indices_list = trial_indices_array[:max_trials].tolist()

            for idx in trial_indices_list:
                if idx == 0 and sequence_pos > 0:
                    break
                sequence_pos += len(trial_motifs[idx])

            remaining_sequence = cue_sequence[sequence_pos : sequence_pos + 20]
            message = (
                f"Unable to decompose VR wall cue sequence {seq_idx + 1} of {len(cue_sequences)} into a sequence of "
                f"trial distances. No trial motif matched at position {sequence_pos}. The next 20 cues: "
                f"{remaining_sequence.tolist()}"
            )
            console.error(message=message, error=RuntimeError)
            raise RuntimeError(message)

        # Extracts trial indices for this sequence
        sequence_trial_indices = trial_indices_array[:trial_count].tolist()

        for trial_idx in sequence_trial_indices:
            trial_distance = distances_array[trial_idx]
            new_cumulative_distance = cumulative_distance + trial_distance

            # If this is not the last sequence, checks if the loop has reached the breakpoint distance to
            # truncate the sequence
            if seq_idx < len(cue_sequences) - 1:
                breakpoint_distance = distance_breakpoints[seq_idx]

                # If the processed trial includes the breakpoint distance, truncates the sequence at the breakpoint
                if new_cumulative_distance > breakpoint_distance:
                    # This trial extends beyond the breakpoint. Adds a truncated version of this trial to the
                    # tracking list. The trial type is preserved, but later processing code is expected to catch the
                    # abrupt trial transition
                    truncated_distance = breakpoint_distance - cumulative_distance

                    # Once the truncated trial is found, modifies the trials' data to reflect the fact that the trial
                    # did not reach the final associated distance.
                    if truncated_distance > 0:
                        all_trial_indices.append(trial_idx)
                        all_trial_distances.append(breakpoint_distance)

                        # Notifies the user about the detected breakpoint
                        message = (
                            f"Sequence {seq_idx + 1}, Trial {trial_idx}: truncated. Full trial should have ended at "
                            f"{new_cumulative_distance:.1f} cm, but the sequence was interrupted at "
                            f"{breakpoint_distance:.1f} cm"
                        )
                        console.echo(message=message, level=LogLevel.WARNING)

                    # Stops processing trials (truncates the sequence) after breakpoint
                    cumulative_distance = breakpoint_distance
                    break
                else:
                    # If the trial was traversed fully, adds its data to the stitched sequence
                    all_trial_indices.append(trial_idx)
                    all_trial_distances.append(new_cumulative_distance)
                    cumulative_distance = new_cumulative_distance
            else:
                # For the last sequence, adds all available trials to the stitched sequence.
                all_trial_indices.append(trial_idx)
                all_trial_distances.append(new_cumulative_distance)
                cumulative_distance = new_cumulative_distance

    # Converts results to numpy arrays before returning them to the caller
    trial_type_sequence = np.array(all_trial_indices, dtype=np.int32)
    trial_distance_sequence = np.array(all_trial_distances, dtype=np.float64)

    return trial_type_sequence, trial_distance_sequence


def _decompose_cue_sequence_into_trials(
    experiment_configuration: MesoscopeExperimentConfiguration,
    cue_sequence: NDArray[np.uint8],
) -> tuple[NDArray[np.int32], NDArray[np.float64]]:
    """Decomposes a single Virtual Reality task wall cue sequence into a sequence of trials.

    This is a convenience wrapper around _decompose_multiple_cue_sequences_into_trials for backward compatibility when
    working with runtimes that only used a single wall cue sequence. Since multiple sequences are only present in
    runtimes that encountered issues at runtime, this function should, in fact, be used during most data processing
    runtimes.

    Args:
        experiment_configuration: The initialized ExperimentConfiguration instance for which to parse the trial data.
        cue_sequence: The cue sequence to decompose into trials.

    Returns:
        A tuple that contains two elements. The first element is an array of trial type indices in the order encountered
        at runtime. The second element is an array of cumulative distances at the end of each trial.

    Raises:
        RuntimeError: If the function is not able to fully decompose the cue sequence.
    """
    trial_indices, trial_distances = _decompose_multiple_cue_sequences_into_trials(
        experiment_configuration=experiment_configuration,
        cue_sequences=[cue_sequence],
        distance_breakpoints=[],
    )

    return trial_indices, trial_distances


def _process_trial_sequence(
    experiment_configuration: MesoscopeExperimentConfiguration,
    trial_types: NDArray[np.int32],
    trial_distances: NDArray[np.float64],
) -> tuple[NDArray[np.uint8], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64]]:
    """Processes the sequence of trials experienced by the animal during runtime to extract various trial metadata
    information.

    This function uses the sequence of trials generated by _decompose_cue_sequence_into_trials() and
    _decompose_multiple_cue_sequences_into_trials() to extract various trial-related metadata. It generates multiple
    data sources critical for trial-based analyses.

    Args:
        experiment_configuration: The initialized ExperimentConfiguration instance for which to generate the
            cue-distance data.
        trial_types: A NumPy array that stores the indices of each trial type experienced by the animal at runtime. The
            indices are used to query the trial data from the ExperimentConfiguration instance.
        trial_distances: A NumPy array that stores the actual cumulative distance, in centimeters, at which the animal
            fully completed the trial at runtime. The entries in this array should be in the same order as indices in
            the trial_types array.

    Returns:
        A tuple of five NumPy arrays. The first array stores the IDs of the cues experienced by the animal at runtime.
        The second array stores the total cumulative distance, in centimeters, traveled by the animal at the onset
        of each cue stored in the first array. The third array stores the cumulative distance traveled by the animal
        when it entered each reward zone encountered at runtime. The fourth array stores the cumulative distance
        traveled by the animal when it exited each reward zone encountered at runtime. The fifth array stores the
        cumulative distance at the onset of each trial experienced by the animal at runtime.

    """
    # Extracts the list of trial type objects from experiment configuration data
    trials: list[ExperimentTrial] = [entry for entry in experiment_configuration.trial_structures.values()]

    # Also extract the dictionary that maps wall cue IDs to the length of each cue, in centimeters and a static
    # offset used to shift the animal's starting position on the VR track.
    cue_offset = experiment_configuration.cue_offset_cm
    cue_map = experiment_configuration.cue_map  # Maps cue_id -> length_cm

    # Pre-initializes output iterables as lists to efficiently support dynamic growth
    distances_list: list[np.float64] = []
    cues_list: list[np.uint8] = []
    reward_zone_starts_list: list[np.float64] = []
    reward_zone_ends_list: list[np.float64] = []
    trial_start_distances_list: list[np.float64] = []

    # Tracks the cumulative distance as the function essentially rebuilds the stitched cue sequence from trial
    # information
    cumulative_distance = np.float64(0)

    # Track whether to apply the cue position offset, which is done at the start and after each trial truncation
    # (sequence regeneration).
    apply_offset_to_next_cue = True

    # Loops over each trial in the sequence experienced by the animal and reconstructs the requested mappings
    previous_trial_end_distance = np.float64(0)
    index: int
    trial: np.int32
    for index, trial in enumerate(trial_types):
        # Uses the trial type to query the corresponding ExperimentTrial object for each trial. Note! This assumes that
        # the items stored in the experiment configuration class always follow the same order and that the order used
        # here and during sequence-to-trial decomposition is the same.
        trial_type = trials[trial]

        # Records the start distance for this trial
        trial_start_distances_list.append(previous_trial_end_distance)

        # Queries the actual distance traveled by the animal while running the processed trial
        actual_trial_distance = trial_distances[index] - previous_trial_end_distance

        # Queries the cue sequence for this trial
        trial_cue_sequence = trial_type.cue_sequence  # List of cue IDs

        # Tracks the distance within this trial to handle truncation
        distance_within_trial = np.float64(0)

        # Processes each cue in the trial
        for cue_idx, cue_id in enumerate(trial_cue_sequence):
            # Determines the length of each cue using the experiment cue_map
            cue_length = cue_map[int(cue_id)]

            # Applies offset if this is the first cue after a sequence start/restart
            if apply_offset_to_next_cue and cue_idx == 0:
                # This is the first cue of a new sequence (initial or after the sequence was regenerated). The animal
                # starts cue_offset cm into this cue
                effective_distance_to_next_cue = cue_length - cue_offset
                apply_offset_to_next_cue = False
            else:
                effective_distance_to_next_cue = cue_length

            # Checks if the trial is truncated (abruptly ended before completion). In this case, the actual trial
            # distance would be less than the end-distance of the currently processed cue
            if distance_within_trial + effective_distance_to_next_cue > actual_trial_distance:
                # In this case, stops processing the trial after this cue
                cues_list.append(np.uint8(cue_id))
                distances_list.append(cumulative_distance)  # Logs current cue onset distance as the end of previous cue

                # Updates the cumulative distance to the actual end of this trial. When the processing continues with
                # the next sequence, this would be used to accurately reflect the partial coverage of this abruptly
                # truncated cue.
                cumulative_distance = previous_trial_end_distance + actual_trial_distance

                # Since this trial was truncated, the next trial will start a new sequence, requiring the offset
                # to be applied again
                apply_offset_to_next_cue = True
                break

            else:
                # Otherwise, includes each cue and associated distance in the distance list.
                cues_list.append(np.uint8(cue_id))
                distances_list.append(cumulative_distance)

                # Updates distance trackers
                cumulative_distance += effective_distance_to_next_cue
                distance_within_trial += effective_distance_to_next_cue

        # Queries reward zone boundaries relative to trial start.
        reward_start_relative = trial_type.reward_zone_start_cm
        reward_end_relative = trial_type.reward_zone_end_cm

        # Converts to absolute positions given the global monotonically increasing traveled distance
        reward_start_absolute = previous_trial_end_distance + reward_start_relative
        reward_end_absolute = previous_trial_end_distance + reward_end_relative

        # Only adds reward zones if the start falls within the actual distance traveled
        if reward_start_absolute <= trial_distances[index]:
            reward_zone_starts_list.append(reward_start_absolute)

            # Clips the end if the trial was truncated before the animal reached the end of the reward zone
            if reward_end_absolute <= trial_distances[index]:
                reward_zone_ends_list.append(reward_end_absolute)
            else:
                # The reward zone was cut off by trial truncation, so 'ends' reward zone using the trial breakpoint
                # data
                # noinspection PyTypeChecker
                reward_zone_ends_list.append(trial_distances[index])

        # Updates previous trial end distance for next iteration
        previous_trial_end_distance = trial_distances[index]

    # Converts lists to numpy arrays and returns them to caller
    distances = np.array(distances_list, dtype=np.float64)
    cues = np.array(cues_list, dtype=np.uint8)
    reward_zone_starts = np.array(reward_zone_starts_list, dtype=np.float64)
    reward_zone_ends = np.array(reward_zone_ends_list, dtype=np.float64)
    trial_start_distances = np.array(trial_start_distances_list, dtype=np.float64)

    return cues, distances, reward_zone_starts, reward_zone_ends, trial_start_distances


def _interpolate_data(
    timestamps: NDArray[np.uint64],
    data: NDArray[np.integer[Any] | np.floating[Any]],
    seed_timestamps: NDArray[np.uint64],
    is_discrete: bool,
) -> NDArray[np.signedinteger[Any] | np.unsignedinteger[Any] | np.floating[Any]]:
    """Interpolates data values for the provided seed timestamps.

    Primarily, this service function is used to time-align different datastreams from the same source. For example, the
    Valve module generates both the solenoid valve data and the auditory tone data, which is generated at non-matching
    rates. This function is used to equalize the data sampling rate between the two data streams, allowing to output
    the data as .feather file.

    Notes:
        This function expects seed_timestamps and timestamps arrays to be monotonically increasing.

        Discrete interpolated data will be returned as an array with the same datatype as the input data. Continuous
        interpolated data will always use float_64 datatype.

    Args:
        timestamps: The one-dimensional numpy array that stores the timestamps for the source data.
        data: The one-dimensional numpy array that stores the source datapoints.
        seed_timestamps: The one-dimensional numpy array that stores the timestamps for which to interpolate the data
            values.
        is_discrete: A boolean flag that determines whether the data is discrete or continuous.

    Returns:
        A numpy NDArray with the same dimension as the seed_timestamps array that stores the interpolated data values.
    """
    # Discrete data
    if is_discrete:
        # Preallocates the output array
        interpolated_data = np.empty(seed_timestamps.shape, dtype=data.dtype)

        # Handles boundary conditions in bulk using boolean masks. All seed timestamps below the minimum source
        # timestamp are statically set to data[0], and all seed timestamps above the maximum source timestamp are set
        # to data[-1].
        below_min = seed_timestamps < timestamps[0]
        above_max = seed_timestamps > timestamps[-1]
        within_bounds = ~(below_min | above_max)  # The portion of the seed that is within the source timestamp boundary

        # Assigns out-of-bounds values in-bulk
        interpolated_data[below_min] = data[0]
        interpolated_data[above_max] = data[-1]

        # Processes within-boundary timestamps by finding the last known certain value to the left of each seed
        # timestamp and setting each seed timestamp to that value.
        if np.any(within_bounds):
            indices = np.searchsorted(timestamps, seed_timestamps[within_bounds], side="right") - 1
            interpolated_data[within_bounds] = data[indices]

        return interpolated_data

    # Continuous data. Note, due to interpolation, continuous data is always returned using float_64 datatype.
    else:
        return np.interp(seed_timestamps, timestamps, data)  # type: ignore


def _parse_encoder_data(
    extracted_module_data: ExtractedModuleData, output_directory: Path, cm_per_pulse: np.float64
) -> None:
    """Extracts and saves the data acquired by the EncoderModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_directory: The path to the directory where to save the parsed data as a .feather file.
        cm_per_pulse: The conversion factor to translate raw encoder pulses into distance in centimeters.
    """
    log_data = extracted_module_data.data

    # Here, we only look for event-codes 51 (CCW displacement) and event-codes 52 (CW displacement).

    # Gets the data, defaulting to an empty list if the data is missing
    ccw_data = log_data.get(np.uint8(51), [])
    cw_data = log_data.get(np.uint8(52), [])

    # The way EncoderModule is implemented guarantees there is at least one CW code message with the displacement
    # of 0 that is received by the PC. In the worst case scenario, there will be no CCW codes and the parsing will
    # not work. To avoid that issue, we generate an artificial zero-code CCW value at the same timestamp + 1
    # microsecond as the original CW zero-code value. This does not affect the accuracy of our data, just makes the
    # code work for edge-cases.
    if not ccw_data:
        first_timestamp = cw_data[0]["timestamp"]
        ccw_data = [{"timestamp": first_timestamp + 1, "data": 0}]
    elif not cw_data:
        first_timestamp = ccw_data[0]["timestamp"]
        cw_data = [{"timestamp": first_timestamp + 1, "data": 0}]

    # Precreates the output arrays, based on the number of recorded CW and CCW displacements.
    total_length = len(ccw_data) + len(cw_data)
    timestamps: NDArray[np.uint64] = np.empty(total_length, dtype=np.uint64)
    displacements: NDArray[Any] = np.empty(total_length, dtype=np.float64)

    # Processes CCW rotations (Code 51). CCW rotation is interpreted as positive displacement
    n_ccw = len(ccw_data)
    timestamps[:n_ccw] = [value["timestamp"] for value in ccw_data]  # Extracts timestamps for each value
    # The values are initially using the uint32 type. This converts them to float64 during the initial assignment
    displacements[:n_ccw] = [np.float64(value["data"]) for value in ccw_data]

    # Processes CW rotations (Code 52). CW rotation is interpreted as negative displacement
    timestamps[n_ccw:] = [value["timestamp"] for value in cw_data]  # CW data just fills remaining space after CCW.
    displacements[n_ccw:] = [-np.float64(value["data"]) for value in cw_data]

    # Sorts both arrays based on timestamps.
    sort_indices = np.argsort(timestamps)
    timestamps = timestamps[sort_indices]
    displacements = displacements[sort_indices]

    # Converts individual displacement vectors into aggregated absolute position of the mouse. The position is also
    # translated from encoder pulse counts into centimeters. The position is referenced to the start of the
    # experimental trial (beginning of the VR track) as 0-value. Positive positions mean moving forward along the
    # track, negative positions mean moving backward along the track.
    # noinspection PyTypeChecker
    positions: NDArray[Any] = np.round(np.cumsum(displacements * cm_per_pulse), decimals=8)

    # Replaces -0.0 values with 0.0. This is a convenience conversion to improve the visual appearance of numbers
    # to users
    positions = np.where(np.isclose(positions, -0.0) & (np.signbit(positions)), 0.0, positions)

    # Creates a Polars DataFrame with the processed data
    module_dataframe = pl.DataFrame(
        {
            "time_us": timestamps,
            "traveled_distance_cm": positions,
        }
    )

    # Saves the DataFrame to the output directory as a Feather file with lz4 compression
    module_dataframe.write_ipc(file=output_directory.joinpath("encoder_data.feather"), compression="lz4")


def _parse_ttl_data(extracted_module_data: ExtractedModuleData, output_directory: Path, log_name: str) -> None:
    """Extracts and saves the data acquired by the TTLModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_directory: The path to the directory where to save the parsed data as a .feather file.
        log_name: The unique name to use for the output .feather file. Since we use more than a single TTLModule
            instance, it may be necessary to distinguish different TTL log files from each other by using unique file
            names to store the parsed data.
    """
    log_data = extracted_module_data.data

    # Here, we only look for event-codes 52 (InputON) and event-codes 53 (InputOFF).

    # Gets the data for both message types. The way the module is written guarantees that the PC receives code 53
    # at least once. No such guarantee is made for code 52, however. We still default to empty lists for both
    # to make this code a bit friendlier to future changes.
    on_data = log_data.get(np.uint8(52), [])
    off_data = log_data.get(np.uint8(53), [])

    # Since this code ultimately looks for rising edges, it will not find any unless there is at least one ON and
    # one OFF message. Therefore, if any of the codes is actually missing, does NOT return any data. It is expected
    # that this will be interpreted as having no ttl data during analysis.
    if len(on_data) == 0 or len(off_data) == 0:
        return

    # Determines the total length of the output array using the length of ON and OFF data arrays.
    total_length = len(on_data) + len(off_data)

    # Precreates the storage numpy arrays for both message types. Timestamps use uint64 datatype, and the trigger
    # values are boolean. We use uint8 as it has the same memory footprint as a boolean and allows us to use integer
    # types across the entire dataset.
    timestamps: NDArray[np.uint64] = np.empty(total_length, dtype=np.uint64)
    triggers: NDArray[np.uint8] = np.empty(total_length, dtype=np.uint8)

    # Extracts ON (Code 52) trigger codes. Statically assigns the value '1' to denote ON signals.
    n_on = len(on_data)
    timestamps[:n_on] = [value["timestamp"] for value in on_data]
    triggers[:n_on] = np.uint8(1)  # All code 52 signals are ON (High)

    # Extracts OFF (Code 53) trigger codes.
    timestamps[n_on:] = [value["timestamp"] for value in off_data]
    triggers[n_on:] = np.uint8(0)  # All code 53 signals are OFF (Low)

    # Sorts both arrays based on the timestamps, so that the data is in the chronological order.
    sort_indices = np.argsort(timestamps)
    timestamps = timestamps[sort_indices]
    triggers = triggers[sort_indices]

    # If the last value is not 0, adds a zero-value to the end of the data sequence, one microsecond
    # after the last readout. This is to properly mark the end of the monitoring sequence.
    if triggers[-1] != 0:
        timestamps = np.append(timestamps, timestamps[-1] + 1)
        triggers = np.append(triggers, 0)

    # Creates a Polars DataFrame with the processed data
    module_dataframe = pl.DataFrame(
        {
            "time_us": timestamps,
            "ttl_state": triggers,
        }
    )

    # Saves the DataFrame to the output directory as a Feather file with lz4 compression
    module_dataframe.write_ipc(file=output_directory.joinpath(f"{log_name}.feather"), compression="lz4")


def _parse_break_data(
    extracted_module_data: ExtractedModuleData,
    output_directory: Path,
    maximum_break_strength: np.float64,
    minimum_break_strength: np.float64,
) -> None:
    """Extracts and saves the data acquired by the BreakModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_directory: The path to the directory where to save the parsed data as a .feather file.
        maximum_break_strength: The maximum torque of the break in Newton centimeters.
        minimum_break_strength: The minimum torque of the break in Newton centimeters.

    Notes:
        This method assumes that the break was used in the absolute force mode. It does not extract variable
        breaking power data.
    """
    log_data = extracted_module_data.data

    # Here, we only look for event-codes 52 (Engaged) and event-codes 53 (Disengaged) as no experiment requires
    # variable breaking power. If we ever use variable breaking power, this section would need to be expanded to
    # allow parsing code 54 events.

    # Gets the data, defaulting to an empty list if the data is missing
    engaged_data = log_data.get(np.uint8(52), [])
    disengaged_data = log_data.get(np.uint8(53), [])

    # Precreates the storage numpy arrays for both message types. Timestamps use uint64 datatype. Although trigger
    # values are boolean, we translate them into the actual torque applied by the break in Newton centimeters and
    # store them as float 64 values.
    total_length = len(engaged_data) + len(disengaged_data)
    timestamps: NDArray[np.uint64] = np.empty(total_length, dtype=np.uint64)
    torques: NDArray[np.float64] = np.empty(total_length, dtype=np.float64)

    # Processes Engaged (code 52) triggers. When the motor is engaged, it applies the maximum possible torque to
    # the break.
    n_engaged = len(engaged_data)
    timestamps[:n_engaged] = [value["timestamp"] for value in engaged_data]  # Extracts timestamps for each value
    # Since engaged strength means that the torque is delivering maximum force, uses the maximum force in N cm as
    # the torque value for each 'engaged' state.
    torques[:n_engaged] = [maximum_break_strength for _ in engaged_data]  # Already in rounded float 64

    # Processes Disengaged (code 53) triggers. Contrary to naive expectation, the torque of a disengaged break is
    # NOT zero. Instead, it is at least the same as the minimum break strength, likely larger due to all mechanical
    # couplings in the system.
    timestamps[n_engaged:] = [value["timestamp"] for value in disengaged_data]
    torques[n_engaged:] = [minimum_break_strength for _ in disengaged_data]  # Already in rounded float 64

    # Sorts both arrays based on timestamps.
    sort_indices = np.argsort(timestamps)
    timestamps = timestamps[sort_indices]
    torques = torques[sort_indices]

    # Creates a Polars DataFrame with the processed data
    module_dataframe = pl.DataFrame(
        {
            "time_us": timestamps,
            "break_torque_N_cm": torques,
        }
    )

    # Saves the DataFrame to the output directory as a Feather file with lz4 compression
    module_dataframe.write_ipc(file=output_directory.joinpath("break_data.feather"), compression="lz4")


def _parse_valve_data(
    extracted_module_data: ExtractedModuleData,
    output_directory: Path,
    scale_coefficient: np.float64,
    nonlinearity_exponent: np.float64,
) -> None:
    """Extracts and saves the data acquired by the ValveModule during runtime as a .feather file.

    Notes:
        Unlike other processing methods, this method generates a .feather dataset with 3 columns: time, dispensed
        water volume, and the state of the tone buzzer.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_directory: The path to the directory where to save the parsed data as a .feather file.
        scale_coefficient: Stores the scale coefficient used in the fitted power law equation that translates valve
            pulses into dispensed water volumes.
        nonlinearity_exponent: Stores the nonlinearity exponent used in the fitted power law equation that
            translates valve pulses into dispensed water volumes.
    """
    log_data = extracted_module_data.data

    # Here, we primarily look for event-codes 52 (Valve Open) and event-codes 53 (Valve Closed).
    # We also look for codes 55 (ToneON) and 56 (ToneOFF), however, and these codes are parsed similar to the
    # ttl state codes.

    # The way this module is implemented guarantees there is at least one code 53 message, but there may be no code
    # 52 messages.
    open_data = log_data.get(np.uint8(52), [])
    closed_data = log_data[np.uint8(53)]

    # If there were no valve open events, no water was dispensed. In this case, uses the first code 53 timestamp
    # to report a zero-volume reward and ends the runtime early. If the valve was never opened, there were no
    # tones, so this shorts both tone-parsing and valve-parsing
    if not open_data:
        module_dataframe = pl.DataFrame(
            {
                "time_us": np.array([closed_data[0]["timestamp"]], dtype=np.uint64),
                "dispensed_water_volume_uL": np.array([0], dtype=np.float64),
                "tone_state": np.array([0], dtype=np.uint8),
            }
        )
        module_dataframe.write_ipc(file=output_directory.joinpath("valve_data.feather"), compression="lz4")
        return

    # Precreates the storage numpy arrays for both message types. Timestamps use uint64 datatype. Although valve
    # trigger values are boolean, we translate them into the total volume of water, in microliters, dispensed to the
    # animal at each time-point and store that value as a float64.
    total_length = len(open_data) + len(closed_data)
    timestamps: NDArray[np.uint64] = np.empty(total_length, dtype=np.uint64)
    volume: NDArray[np.float64] = np.empty(total_length, dtype=np.float64)

    # The water is dispensed gradually while the valve stays open. Therefore, the full reward volume is dispensed
    # when the valve goes from open to closed. Based on calibration data, we have a conversion factor to translate
    # the time the valve remains open into the fluid volume dispensed to the animal, which we use to convert each
    # Open/Close cycle duration into the dispensed volume.

    # Extracts Open (Code 52) trigger codes. Statically assigns the value '1' to denote Open signals.
    n_on = len(open_data)
    timestamps[:n_on] = [value["timestamp"] for value in open_data]
    volume[:n_on] = np.uint8(1)  # All code 52 signals are Open (High)

    # Extracts Closed (Code 53) trigger codes.
    timestamps[n_on:] = [value["timestamp"] for value in closed_data]
    volume[n_on:] = np.uint8(0)  # All code 53 signals are Closed (Low)

    # Sorts both arrays based on timestamps.
    sort_indices = np.argsort(timestamps)
    timestamps = timestamps[sort_indices]
    volume = volume[sort_indices]

    # Find falling and rising edges. Falling edges are valve closing events, rising edges are valve opening events.
    rising_edges = np.where((volume[:-1] == 0) & (volume[1:] == 1))[0] + 1
    falling_edges = np.where((volume[:-1] == 1) & (volume[1:] == 0))[0] + 1

    # Samples the timestamp array to only include timestamps for the falling edges. That is, when the valve has
    # finished delivering water
    reward_timestamps = timestamps[falling_edges]

    # Calculates pulse durations in microseconds for each open-close cycle. Since the original timestamp array
    # contains alternating HIGH / LOW edges, each falling edge has to match to a rising edge.
    pulse_durations: NDArray[np.float64] = (timestamps[falling_edges] - timestamps[rising_edges]).astype(np.float64)

    # Converts the time the Valve stayed open into the dispensed water volume, in microliters.
    # noinspection PyTypeChecker
    volumes: NDArray[Any] = np.round(
        np.cumsum(scale_coefficient * np.power(pulse_durations, nonlinearity_exponent)),
        decimals=8,
    )

    # The processing logic above removes the initial water volume of 0. This re-adds the initial volume using the
    # first timestamp of the module data. That timestamp communicates the initial valve state, which should be 0.
    reward_timestamps = np.insert(reward_timestamps, 0, timestamps[0])
    volumes = np.insert(volumes, 0, 0.0)

    # Now carries out similar processing for the Tone signals
    # Same logic as with code 52 applies to code 55
    tone_on_data = log_data.get(np.uint8(55), [])
    tone_off_data = log_data.get(np.uint8(56), [])  # The empty default is to appease mypy

    tone_length = len(tone_on_data) + len(tone_off_data)
    tone_timestamps: NDArray[np.uint64] = np.empty(tone_length, dtype=np.uint64)
    tone_states: NDArray[np.uint8] = np.empty(tone_length, dtype=np.uint8)

    # Extracts ON (Code 55) Tone codes. Statically assigns the value '1' to denote On signals.
    tone_on_n = len(tone_on_data)
    tone_timestamps[:tone_on_n] = [value["timestamp"] for value in tone_on_data]
    tone_states[:tone_on_n] = np.uint8(1)  # All code 55 signals are On (High)

    # Extracts Closed (Code 53) trigger codes.
    tone_timestamps[tone_on_n:] = [value["timestamp"] for value in tone_off_data]
    tone_states[tone_on_n:] = np.uint8(0)  # All code 56 signals are Off (Low)

    # Sorts both arrays based on timestamps.
    sort_indices = np.argsort(tone_timestamps)
    tone_timestamps = tone_timestamps[sort_indices]
    tone_states = tone_states[sort_indices]

    # If the last value is not 0, adds a zero-value to the end of the data sequence, one microsecond
    # after the last readout. This is to properly mark the end of the monitoring sequence.
    if tone_states[-1] != 0:
        tone_timestamps = np.append(tone_timestamps, tone_timestamps[-1] + 1)
        tone_states = np.append(tone_states, 0)

    # Constructs a shared array that includes all reward and tone timestamps. This will be used to interpolate tone
    # and timestamp values. Sorts the generated array to arrange all timestamps in monotonically ascending order
    shared_stamps = np.concatenate([tone_timestamps, reward_timestamps])
    sort_indices = np.argsort(shared_stamps)
    shared_stamps = shared_stamps[sort_indices]

    # Interpolates the reward volumes for each tone state and tone states for each reward volume.
    out_reward = _interpolate_data(
        timestamps=reward_timestamps, data=volumes, seed_timestamps=shared_stamps, is_discrete=True
    )
    out_tones = _interpolate_data(
        timestamps=tone_timestamps, data=tone_states, seed_timestamps=shared_stamps, is_discrete=True
    )

    # Creates a Polars DataFrame with the processed data
    module_dataframe = pl.DataFrame(
        {
            "time_us": shared_stamps,
            "dispensed_water_volume_uL": out_reward,
            "tone_state": out_tones,
        }
    )

    # Saves the DataFrame to the output directory as a Feather file with lz4 compression
    module_dataframe.write_ipc(file=output_directory.joinpath("valve_data.feather"), compression="lz4")


def _parse_lick_data(
    extracted_module_data: ExtractedModuleData, output_directory: Path, lick_threshold: np.uint16
) -> None:
    """Extracts and saves the data acquired by the LickModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_directory: The path to the directory where to save the parsed data as a .feather file.
        lick_threshold: The voltage threshold for detecting the interaction with the sensor as a lick.

    Notes:
        The extraction classifies lick events based on the lick threshold used by the class during runtime. The
        time-difference between consecutive ON and OFF event edges corresponds to the time, in microseconds, the
        tongue maintained contact with the lick tube. This may include both the time the tongue physically
        touched the tube and the time there was a conductive fluid bridge between the tongue and the lick tube.

        In addition to classifying the licks and providing binary lick state data, the extraction preserves the raw
        12-bit ADC voltages associated with each lick. This way, it is possible to spot issues with the lick detection
        system by applying a different lick threshold from the one used at runtime, potentially augmenting data
        analysis.
    """
    log_data = extracted_module_data.data

    # LickModule only sends messages with code 51 (Voltage level changed). Therefore, this extraction pipeline has
    # to apply the threshold filter, similar to how the real-time processing method.

    # Unlike the other parsing methods, this one will always work as expected since it only deals with one code and
    # that code is guaranteed to be received for each runtime.

    # Precreates the storage numpy arrays for both message types. Timestamps use uint64 datatype. Lick sensor
    # voltage levels come in as uint16, but we later also mark them with binary uint8 1 and 0 values.
    voltage_data = log_data[np.uint8(51)]
    total_length = len(voltage_data)
    timestamps: NDArray[np.uint64] = np.empty(total_length, dtype=np.uint64)
    voltages: NDArray[np.uint16] = np.empty(total_length, dtype=np.uint16)

    # Extract timestamps and voltage levels
    timestamps[:] = [value["timestamp"] for value in voltage_data]
    voltages[:] = [value["data"] for value in voltage_data]

    # Sorts all arrays by timestamp. This is technically not needed as the extracted values are already sorted by
    # timestamp, but this is still done for additional safety.
    sort_indices = np.argsort(timestamps)
    timestamps = timestamps[sort_indices]
    voltages = voltages[sort_indices]

    # Creates a lick binary classification column based on the class threshold. Note, the threshold is inclusive.
    licks = np.where(voltages >= lick_threshold, np.uint8(1), np.uint8(0))

    # Creates a Polars DataFrame with the processed data
    module_dataframe = pl.DataFrame(
        {
            "time_us": timestamps,
            "voltage_12_bit_adc": voltages,
            "lick_state": licks,
        }
    )

    # Saves the DataFrame to the output directory as a Feather file with lz4 compression
    module_dataframe.write_ipc(file=output_directory.joinpath("lick_data.feather"), compression="lz4")


def _parse_torque_data(
    extracted_module_data: ExtractedModuleData, output_directory: Path, torque_per_adc_unit: np.float64
) -> None:
    """Extracts and saves the data acquired by the TorqueModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_directory: The path to the directory where to save the parsed data as a .feather file.
        torque_per_adc_unit: The conversion actor used to translate ADC units recorded by the torque sensor into
            the torque in Newton centimeter, applied by the animal to the wheel.

    Notes:
        Despite this method trying to translate the detected torque into Newton centimeters, it may not be accurate.
        Partially, the accuracy of the translation depends on the calibration of the interface class, which is very
        hard with our current setup. The accuracy also depends on the used hardware, and currently our hardware is
        not very well suited for working with millivolt differential voltage levels used by the sensor to report
        torque. Therefore, currently, it is best to treat the torque data extracted from this module as a very rough
        estimate of how active the animal is at a given point in time.
    """
    log_data = extracted_module_data.data

    # Here, we only look for event-codes 51 (CCW Torque) and event-codes 52 (CW Torque). CCW torque is interpreted
    # as torque in the positive direction, and CW torque is interpreted as torque in the negative direction.

    # Gets the data, defaulting to an empty list if the data is missing
    ccw_data = log_data.get(np.uint8(51), [])
    cw_data = log_data.get(np.uint8(52), [])

    # The way TorqueModule is implemented guarantees there is at least one CW code message with the displacement
    # of 0 that is received by the PC. In the worst case scenario, there will be no CCW codes and the parsing will
    # not work. To avoid that issue, we generate an artificial zero-code CCW value at the same timestamp + 1
    # microsecond as the original CW zero-code value. This does not affect the accuracy of our data, just makes the
    # code work for edge-cases.
    if not ccw_data:
        first_timestamp = cw_data[0]["timestamp"]
        ccw_data = [{"timestamp": first_timestamp + 1, "data": 0}]
    elif not cw_data:
        first_timestamp = ccw_data[0]["timestamp"]
        cw_data = [{"timestamp": first_timestamp + 1, "data": 0}]

    # Precreates the storage numpy arrays for both message types. Timestamps use uint64 datatype. Although torque
    # values are uint16, we translate them into the actual torque applied by the animal in Newton centimeters and
    # store them as float 64 values.
    total_length = len(ccw_data) + len(cw_data)
    timestamps: NDArray[np.uint64] = np.empty(total_length, dtype=np.uint64)
    torques: NDArray[np.float64] = np.empty(total_length, dtype=np.float64)

    # Processes CCW torques (Code 51). CCW torque is interpreted as positive torque
    n_ccw = len(ccw_data)
    timestamps[:n_ccw] = [value["timestamp"] for value in ccw_data]  # Extracts timestamps for each value
    # The values are initially using the uint16 type. This converts them to float64 and translates from raw ADC
    # units into Newton centimeters.
    torques[:n_ccw] = [np.round(np.float64(value["data"]) * torque_per_adc_unit, decimals=8) for value in ccw_data]

    # Processes CW torques (Code 52). CW torque is interpreted as negative torque
    timestamps[n_ccw:] = [value["timestamp"] for value in cw_data]  # CW data just fills remaining space after CCW.
    torques[n_ccw:] = [np.round(-np.float64(value["data"]) * torque_per_adc_unit, decimals=8) for value in cw_data]

    # Sorts both arrays based on timestamps.
    sort_indices = np.argsort(timestamps)
    timestamps = timestamps[sort_indices]
    torques = torques[sort_indices]

    # If the last value is not 0, adds a zero-value to the end of the data sequence, one microsecond
    # after the last readout. This is to properly mark the end of the monitoring sequence.
    if torques[-1] != 0:
        timestamps = np.append(timestamps, timestamps[-1] + 1)
        torques = np.append(torques, 0)

    # Replaces -0.0 values with 0.0. This is a convenience conversion to improve the visual appearance of numbers
    # to users
    torques = np.where(np.isclose(torques, -0.0) & (np.signbit(torques)), 0.0, torques)

    # Creates a Polars DataFrame with the processed data
    module_dataframe = pl.DataFrame(
        {
            "time_us": timestamps,
            "torque_N_cm": torques,
        }
    )

    # Saves the DataFrame to the output directory as a Feather file with lz4 compression
    module_dataframe.write_ipc(file=output_directory.joinpath("torque_data.feather"), compression="lz4")


def _parse_screen_data(extracted_module_data: ExtractedModuleData, output_directory: Path, initially_on: bool) -> None:
    """Extracts and saves the data acquired by the ScreenModule during runtime as a .feather file.

    Args:
        extracted_module_data: The ExtractedModuleData instance that stores the data logged by the module during
            runtime.
        output_directory: The path to the directory where to save the parsed data as a .feather file.
        initially_on: Communicates the initial state of the screen at module interface initialization. This is used
            to determine the state of the screens after each processed screen toggle signal.

    Notes:
        This extraction method works similar to the TTLModule method. This is intentional, as ScreenInterface is
        essentially a group of 3 TTLModules.
    """
    log_data = extracted_module_data.data
    # Here, we only look for event-codes 52 (pulse ON) and event-codes 53 (pulse OFF).

    # The way the module is implemented guarantees there is at least one code 53 message. However, if the screen state
    # is never toggled, there may be no code 52 messages.
    on_data = log_data.get(np.uint8(52), [])
    off_data = log_data[np.uint8(53)]

    # If there were no ON pulses, screens never changed state. In this case, shorts to returning the data for the
    # initial screen state using the initial Off timestamp. Otherwise, parses the data
    if not on_data:
        module_dataframe = pl.DataFrame(
            {
                "time_us": np.array([off_data[0]["timestamp"]], dtype=np.uint64),
                "screen_state": np.array([initially_on], dtype=np.uint8),
            }
        )
        module_dataframe.write_ipc(file=output_directory.joinpath("screen_data.feather"), compression="lz4")
        return

    # Precreates the storage numpy arrays for both message types. Timestamps use uint64 datatype, and the trigger
    # values are boolean. We use uint8 as it has the same memory footprint as a boolean and allows us to use integer
    # types across the entire dataset.
    total_length = len(on_data) + len(off_data)
    timestamps: NDArray[np.uint64] = np.empty(total_length, dtype=np.uint64)
    triggers: NDArray[np.uint8] = np.empty(total_length, dtype=np.uint8)

    # Extracts ON (Code 52) trigger codes. Statically assigns the value '1' to denote ON signals.
    n_on = len(on_data)
    timestamps[:n_on] = [value["timestamp"] for value in on_data]
    triggers[:n_on] = np.uint8(1)  # All code 52 signals are ON (High)

    # Extracts OFF (Code 53) trigger codes.
    timestamps[n_on:] = [value["timestamp"] for value in off_data]
    triggers[n_on:] = np.uint8(0)  # All code 53 signals are OFF (Low)

    # Sorts both arrays based on the timestamps, so that the data is in the chronological order.
    sort_indices = np.argsort(timestamps)
    timestamps = timestamps[sort_indices]
    triggers = triggers[sort_indices]

    # Finds rising edges (where the signal goes from 0 to 1). Then uses the indices for such events to extract the
    # timestamps associated with each rising edge, before returning them to the caller.
    rising_edges = np.where((triggers[:-1] == 0) & (triggers[1:] == 1))[0] + 1
    screen_timestamps = timestamps[rising_edges]

    # Adds the initial state of the screen using the first recorded timestamp. The module is configured to send the
    # initial state of the relay (Off) during Setup, so the first recorded timestamp will always be 0 and correspond
    # to the initial state of the screen.
    screen_timestamps = np.concatenate(([timestamps[0]], screen_timestamps))

    # Builds an array of screen states. Starts with the initial screen state and then flips the state for each
    # consecutive timestamp matching a rising edge of the toggle pulse.
    screen_states = np.zeros(len(screen_timestamps), dtype=np.uint8)
    screen_states[0] = initially_on
    for i in range(1, len(screen_states)):
        screen_states[i] = 1 - screen_states[i - 1]  # Flips between 0 and 1

    # Creates a Polars DataFrame with the processed data
    module_dataframe = pl.DataFrame(
        {
            "time_us": screen_timestamps,
            "screen_state": screen_states,
        }
    )

    # Saves the DataFrame to the output directory as a Feather file with lz4 compression
    module_dataframe.write_ipc(file=output_directory.joinpath("screen_data.feather"), compression="lz4")


def _process_camera_timestamps(log_path: Path, output_path: Path) -> None:
    """Reads the log .npz archive specified by the log_path and extracts the camera frame timestamps
    as a Polars Series saved to the output_path as a Feather file.

    Args:
        log_path: The path to the .npz log archive to be parsed.
        output_path: The path to the output .feather file where to save the extracted data.
    """
    # Extracts timestamp data from log archive
    timestamp_data = extract_logged_video_system_data(log_path)

    # Converts extracted data to Polars series.
    timestamps_series = pl.Series(name="frame_time_us", values=timestamp_data)

    # Saves extracted data using Feather format and 'lz4' compression. Lz4 allows optimizing processing time and
    # file size. These extracted files are temporary and will be removed during later processing steps.
    timestamps_series.to_frame().write_ipc(file=output_path, compression="lz4")


def _process_runtime_data(
    log_path: Path, output_directory: Path, experiment_configuration: MesoscopeExperimentConfiguration | None = None
) -> None:
    """Extracts the acquisition system states, experiment states, and any additional system-specific data from the log
    generated during an experiment runtime and saves the extracted data as Polars DataFrame .feather files.

    This extraction method functions similar to camera log extraction and hardware module log extraction methods. The
    key difference is that this function contains additional arguments that allow specializing it for extracting the
    data generated by different acquisition systems used in the Sun lab.

    Args:
        log_path: The path to the .npz archive containing the VR and experiment data to parse.
        output_directory: The path to the directory where to save the extracted data as .feather files.
        experiment_configuration: The ExperimentConfiguration class for the runtime, if the processed runtime is an
            experiment.
    """
    # Loads the archive into RAM
    archive: NpzFile = np.load(file=log_path)

    # Precreates the variables used to store extracted data
    system_states = []
    system_timestamps = []
    experiment_states = []
    experiment_timestamps = []
    guidance_states = []
    guidance_timestamps = []
    reward_visibility_states = []
    reward_visibility_timestamps = []
    cue_sequences: list[NDArray[np.uint8]] = []
    cue_sequence_breakpoints: list[np.float64] = []

    # Locates the logging onset timestamp. The onset is used to convert the timestamps for logged data into absolute
    # UTC timestamps. Originally, all timestamps other than onset are stored as elapsed time in microseconds
    # relative to the onset timestamp.
    timestamp_offset = 0
    onset_us = np.uint64(0)
    timestamp: np.uint64
    for number, item in enumerate(archive.files):
        message: NDArray[np.uint8] = archive[item]  # Extracts message payload from the compressed .npy file

        # Recovers the uint64 timestamp value from each message. The timestamp occupies 8 bytes of each logged
        # message starting at index 1. If the timestamp value is 0, the message contains the onset timestamp value
        # stored as an 8-byte payload. Index 0 stores the source ID (uint8 value)
        if np.uint64(message[1:9].view(np.uint64)[0]) == 0:
            # Extracts the byte-serialized UTC timestamp stored as microseconds since epoch onset.
            onset_us = np.uint64(message[9:].view("<i8")[0].copy())

            # Breaks the loop once the onset is found. Generally, the onset is expected to be found very early into
            # the loop
            timestamp_offset = number  # Records the item number at which the onset value was found.
            break

    # Once the onset has been discovered, loops over all remaining messages and extracts data stored in these
    # messages.
    for item in archive.files[timestamp_offset + 1 :]:
        message = archive[item]

        # Extracts the elapsed microseconds since timestamp and uses it to calculate the global timestamp for the
        # message, in microseconds since epoch onset.
        elapsed_microseconds = np.uint64(message[1:9].view(np.uint64)[0].copy())
        timestamp = onset_us + elapsed_microseconds

        payload = message[9:]  # Extracts the payload from the message

        # If the message is longer than 500 bytes, it is a sequence of wall cues. It is very unlikely that we
        # will log any other data with this length, so it is a safe heuristic to use.
        if len(payload) > 500 and experiment_configuration is not None:
            # Since some runtimes now support generating multiple cue sequences, each sequence is cached into a storage
            # list to be processed later
            cue_sequences.append(payload.view(np.uint8).copy())  # Keeps the original numpy uint8 format

        # If the first element is 1, the message communicates the VR state code.
        elif payload[0] == 1:
            # Extracts the VR state code from the second byte of the message.
            system_states.append(np.uint8(payload[1]))
            system_timestamps.append(timestamp)

        # If the starting code is 2, the message communicates the experiment state code.
        elif payload[0] == 2:
            # Extracts the experiment state code from the second byte of the message.
            experiment_states.append(np.uint8(payload[1]))
            experiment_timestamps.append(timestamp)

        # If the starting code is 3, the message communicates the current lick guidance state
        elif payload[0] == 3:
            guidance_states.append(np.uint8(payload[1]))
            guidance_timestamps.append(timestamp)

        # If the starting code is 4, the message communicates the current reward collision wall visibility state
        elif payload[0] == 4:
            reward_visibility_states.append(np.uint8(payload[1]))
            reward_visibility_timestamps.append(timestamp)

        # If the starting code is 5, the message communicates the breakpoint distance for the current cue sequence.
        elif payload[0] == 5:
            # Skips the first byte (message code) and gets the next 8 bytes storing the distance as a float64
            distance_bytes = payload[1:9]
            traveled_distance = distance_bytes.view(dtype="<f8")[0]  # Converts back to float64
            # noinspection PyTypeChecker
            cue_sequence_breakpoints.append(traveled_distance)

        # Otherwise, the payload cannot be attributed to a known type and is, therefore, ignored

    # Closes the archive to free up memory
    archive.close()

    # Converts extracted data into Polar Feather files:
    # System states
    system_dataframe = pl.DataFrame(
        {
            "time_us": system_timestamps,
            "system_state": system_states,
        }
    )
    system_dataframe.write_ipc(output_directory.joinpath("system_state_data.feather"), compression="lz4")

    # Experiment states
    exp_dataframe = pl.DataFrame(
        {
            "time_us": experiment_timestamps,
            "experiment_state": experiment_states,
        }
    )
    exp_dataframe.write_ipc(output_directory.joinpath("experiment_state_data.feather"), compression="lz4")

    # Note, although lick guidance and reward visibility are parsed for all sessions, this data only exists for
    # experiment sessions. Therefore, only attempt to export the data if the processed session is an experiment session.
    # The same holds with respect to the VR track data parsed below.
    if experiment_configuration is not None:
        # Lick guidance states
        system_dataframe = pl.DataFrame(
            {
                "time_us": guidance_timestamps,
                "lick_guidance_state": guidance_states,
            }
        )
        system_dataframe.write_ipc(output_directory.joinpath("guidance_state_data.feather"), compression="lz4")

        # Reward visibility states
        system_dataframe = pl.DataFrame(
            {
                "time_us": reward_visibility_timestamps,
                "reward_visibility_state": reward_visibility_states,
            }
        )
        system_dataframe.write_ipc(output_directory.joinpath("reward_visibility_state_data.feather"), compression="lz4")

        # Cue sequence for Mesoscope-VR system

        # Most sessions should only have a single cue sequence. However, if necessary, the runtime also supports
        # stitching multiple abruptly terminated sequences to recover useful information from sessions that encountered
        # issues during runtime.
        if len(cue_sequences) > 1:
            trial_types, trial_distances = _decompose_multiple_cue_sequences_into_trials(
                experiment_configuration=experiment_configuration,
                cue_sequences=cue_sequences,
                distance_breakpoints=cue_sequence_breakpoints,
            )
        else:
            trial_types, trial_distances = _decompose_cue_sequence_into_trials(
                experiment_configuration=experiment_configuration, cue_sequence=cue_sequences.pop()
            )

        # Uses the computed sequence of trials and the information stored inside the ExperimentConfiguration class to
        # determine which cues were seen by the animal at which cumulative traveled distances. Also computes the
        # traveled distance boundaries for reward zones.
        cue_sequence, distance_sequence, reward_start, reward_stop, trial_start = _process_trial_sequence(
            experiment_configuration, trial_types, trial_distances
        )

        # Exports the cue-distance mapping as a Polars dataframe
        cue_dataframe = pl.DataFrame(
            {
                "vr_cue": cue_sequence,
                "traveled_distance_cm": distance_sequence,
            }
        )
        cue_dataframe.write_ipc(output_directory.joinpath("vr_cue_data.feather"), compression="lz4")

        # Exports reward_zone-distance mapping as a Polars dataframe
        reward_dataframe = pl.DataFrame(
            {
                "reward_zone_start_cm": reward_start,
                "reward_zone_end_cm": reward_stop,
            }
        )
        reward_dataframe.write_ipc(output_directory.joinpath("vr_reward_zone_data.feather"), compression="lz4")

        # Exports trial-distance mapping as a Polars dataframe
        trial_dataframe = pl.DataFrame(
            {
                "trial_type_index": trial_types,
                "traveled_distance_cm": trial_start,
            }
        )
        trial_dataframe.write_ipc(output_directory.joinpath("trial_data.feather"), compression="lz4")


def _process_actor_data(log_path: Path, output_directory: Path, hardware_state: MesoscopeHardwareState) -> None:
    """Extracts the data logged by the AMC Actor microcontroller modules used during runtime and saves it as multiple
    .feather files.

    Args:
        log_path: The path to the .npz archive containing the Actor AMC data to parse.
        output_directory: The path to the directory where to save the extracted data as .feather files.
        hardware_state: A HardwareState instance representing the state of the acquisition system that generated the
            data.
    """

    # Resolves the modules for which to extract the data. Not all runtimes use all the modules supported by the AMC.
    module_type_id = []  # Determines the data to parse
    data_indices: list[int | None] = []  # Tracks the index under which module's data is returned

    # Break
    index = 0
    if hardware_state.minimum_break_strength is not None and hardware_state.maximum_break_strength is not None:
        module_type_id.append((3, 1))
        data_indices.append(index)
        index += 1
    else:
        data_indices.append(None)

    # Valve
    if hardware_state.valve_nonlinearity_exponent is not None and hardware_state.valve_scale_coefficient is not None:
        module_type_id.append((5, 1))
        data_indices.append(index)
        index += 1
    else:
        data_indices.append(None)

    # Screens
    if hardware_state.screens_initially_on is not None:
        module_type_id.append((7, 1))
        data_indices.append(index)
        index += 1
    else:
        data_indices.append(None)

    # Aborts early if no module data needs to be parsed.
    if set(data_indices) == {None}:
        return

    # Returns the data in the same order as the input module type_ids.
    log_data_tuple = extract_logged_hardware_module_data(log_path=log_path, module_type_id=tuple(module_type_id))

    # Since the most time-consuming step is reading the compressed data log, the time loss due to executing the
    # parsing steps sequentially is negligible.

    # Break
    if data_indices[0] is not None:
        _parse_break_data(
            extracted_module_data=log_data_tuple[data_indices[0]],
            output_directory=output_directory,
            minimum_break_strength=np.float64(hardware_state.minimum_break_strength),
            maximum_break_strength=np.float64(hardware_state.maximum_break_strength),
        )

    # Valve
    if data_indices[1] is not None:
        _parse_valve_data(
            extracted_module_data=log_data_tuple[data_indices[1]],
            output_directory=output_directory,
            scale_coefficient=np.float64(hardware_state.valve_scale_coefficient),
            nonlinearity_exponent=np.float64(hardware_state.valve_nonlinearity_exponent),
        )

    # Screens
    if data_indices[2] is not None:
        _parse_screen_data(
            extracted_module_data=log_data_tuple[data_indices[2]],
            output_directory=output_directory,
            initially_on=hardware_state.screens_initially_on,  # type: ignore
        )


def _process_sensor_data(log_path: Path, output_directory: Path, hardware_state: MesoscopeHardwareState) -> None:
    """Extracts the data logged by the AMC Sensor microcontroller modules used during runtime and saves it as multiple
    .feather files.

    Args:
        log_path: The path to the .npz archive containing the Sensor AMC data to parse.
        output_directory: The path to the directory where to save the extracted data as .feather files.
        hardware_state: A HardwareState instance representing the state of the acquisition system that generated the
            data.
    """

    # Resolves the modules for which to extract the data
    module_type_id = []  # Determines the data to parse
    data_indices: list[int | None] = []  # Tracks the index under which module's data is returned

    # Lick Sensor
    index = 0
    if hardware_state.lick_threshold is not None:
        module_type_id.append((4, 1))
        data_indices.append(index)
        index += 1
    else:
        data_indices.append(None)

    # Torque Sensor
    if hardware_state.torque_per_adc_unit is not None:
        module_type_id.append((6, 1))
        data_indices.append(index)
        index += 1
    else:
        data_indices.append(None)

    # Mesoscope Frame TTL module. Note, while we record other TTL data too, currently, we do not use that data for
    # analysis.
    if hardware_state.recorded_mesoscope_ttl:
        module_type_id.append((1, 1))
        data_indices.append(index)
        index += 1
    else:
        data_indices.append(None)

    # Aborts early if no module data needs to be parsed.
    if set(data_indices) == {None}:
        return

    # Extract all module data at once
    log_data_tuple = extract_logged_hardware_module_data(log_path=log_path, module_type_id=tuple(module_type_id))

    # Parse each module's data
    # Lick Sensor
    if data_indices[0] is not None:
        _parse_lick_data(
            extracted_module_data=log_data_tuple[data_indices[0]],
            output_directory=output_directory,
            lick_threshold=np.uint16(hardware_state.lick_threshold),  # type: ignore
        )

    # Torque Sensor
    if data_indices[1] is not None:
        _parse_torque_data(
            extracted_module_data=log_data_tuple[data_indices[1]],
            output_directory=output_directory,
            torque_per_adc_unit=np.float64(hardware_state.torque_per_adc_unit),
        )

    # Mesoscope Frame TTL module
    if data_indices[2] is not None:
        _parse_ttl_data(
            extracted_module_data=log_data_tuple[data_indices[2]],
            output_directory=output_directory,
            log_name="mesoscope_frame_data",
        )


def _process_encoder_data(log_path: Path, output_directory: Path, hardware_state: MesoscopeHardwareState) -> None:
    """Extracts the data logged by the AMC Encoder microcontroller modules used during runtime and saves it as
    multiple .feather files.

    Notes:
        Currently, Encoder only records data from a single 'EncoderModule'.

    Args:
        log_path: The path to the .npz archive containing the Encoder AMC data to parse.
        output_directory: The path to the directory where to save the extracted data as .feather files.
        hardware_state: A HardwareState instance representing the state of the acquisition system that generated the
            data.
    """

    # Resolves the module for which to extract the data
    module_type_id = []  # Determines the data to parse
    data_indices: list[int | None] = []  # Tracks the index under which module's data is returned

    # Encoder
    index = 0
    if hardware_state.cm_per_pulse is not None:
        module_type_id.append((2, 1))
        data_indices.append(index)
        index += 1
    else:
        data_indices.append(None)

    # Aborts early if no module data needs to be parsed.
    if set(data_indices) == {None}:
        return

    # Extract module data
    log_data_tuple = extract_logged_hardware_module_data(log_path=log_path, module_type_id=tuple(module_type_id))

    # Parse encoder data
    if data_indices[0] is not None:
        _parse_encoder_data(
            extracted_module_data=log_data_tuple[data_indices[0]],
            output_directory=output_directory,
            cm_per_pulse=np.float64(hardware_state.cm_per_pulse),
        )


def extract_log_data(
    session_data: SessionData, manager_id: int, parallel_workers: int = 7, update_manifest: bool = False
) -> None:
    """Reads the compressed .npz log files stored in the raw_data directory of the target session and extracts all
    relevant behavior data stored in these files into the processed_data directory.

    This function is intended to run on the BioHPC server as part of the 'general' data processing pipeline. It is
    optimized to process all log files in parallel and extract the data stored inside the files into the behavior_data
    directory and camera_frames directory.

    Args:
        session_data: The SessionData instance for the processed session.
        manager_id: The xxHash-64 hash-value that specifies the unique identifier of the manager process that
            manages the log processing runtime.
        parallel_workers: The number of CPU cores (workers) to use for processing the data in parallel. Note, this
            number should not exceed the number of available log files.
        update_manifest: Determines whether to update (regenerate) the project manifest file for the processed
            session's project. This should always be enabled when working with remote compute server(s) to ensure that
            the project manifest file contains the most actual snapshot of the project's state.
    """

    # Instantiates the ProcessingTracker instance for behavior log processing and configures the underlying tracker file
    # to indicate that the processing is ongoing. Note, this automatically invalidates any previous processing runtimes.
    tracker = get_processing_tracker(
        root=session_data.processed_data.processed_data_path, file_name=TrackerFileNames.BEHAVIOR
    )
    tracker.start(manager_id=manager_id)

    try:
        # Resolves the paths to the specific directories used during processing
        log_directory = session_data.raw_data.behavior_data_path
        behavior_data_directory = session_data.processed_data.behavior_data_path
        camera_data_directory = session_data.processed_data.camera_data_path

        # Should exist inside the raw data directory
        hardware_configuration_path = session_data.raw_data.hardware_state_path

        if session_data.acquisition_system not in _supported_acquisition_systems:
            message = (
                f"Unable to process behavior data for session '{session_data.session_name}' of "
                f"animal {session_data.animal_id} and project {session_data.project_name}. The input session was "
                f"acquired with an unsupported acquisition system: {session_data.acquisition_system}. Currently, "
                f"only sessions acquired using the following acquisition systems are supported: "
                f"{', '.join(_supported_acquisition_systems)}."
            )
            console.error(message=message, error=ValueError)

        if session_data.session_type not in _supported_session_types:
            message = (
                f"Unable to process behavior data for session '{session_data.session_name}' of "
                f"animal {session_data.animal_id} and project {session_data.project_name}. The input session is of an "
                f"unsupported type {session_data.session_type}. Currently, only the following session types are "
                f"supported: {', '.join(_supported_session_types)}."
            )
            console.error(message=message, error=ValueError)

        # Finds all .npz log files inside the input log file directory. Assumes there are no uncompressed log files.
        compressed_files: list[Path] = [file for file in log_directory.glob("*.npz")]

        # Loads the input MesoscopeHardwareState file to read the hardware parameters necessary to parse the data
        hardware_configuration: MesoscopeHardwareState = MesoscopeHardwareState.from_yaml(  # type: ignore
            file_path=hardware_configuration_path,
        )

        experiment_configuration: MesoscopeExperimentConfiguration | None = None
        if session_data.raw_data.experiment_configuration_path.exists():
            experiment_configuration = MesoscopeExperimentConfiguration.from_yaml(  # type: ignore
                file_path=session_data.raw_data.experiment_configuration_path
            )

        # If there are no compressed log files to process, returns immediately
        if len(compressed_files) == 0:
            return

        # Mesoscope VR Processing
        if session_data.acquisition_system == AcquisitionSystems.MESOSCOPE_VR:
            # Iterates over all compressed log files and processes them in-parallel
            with ProcessPoolExecutor(max_workers=parallel_workers) as executor:
                message = (
                    f"Processing behavior log files acquired with the Mesoscope-VR acquisition system during the "
                    f"session {session_data.session_name} of animal {session_data.animal_id} and project "
                    f"{session_data.project_name}..."
                )
                console.echo(message=message, level=LogLevel.INFO)

                futures = set()
                for file in compressed_files:
                    # Acquisition System log file. Currently, all valid runtimes generate log data, so this file is
                    # always parsed.
                    if file.stem == "1_log":
                        futures.add(
                            executor.submit(
                                _process_runtime_data,
                                file,
                                behavior_data_directory,
                                experiment_configuration,
                            )
                        )

                    # Face Camera timestamps
                    if file.stem == "51_log":
                        futures.add(
                            executor.submit(
                                _process_camera_timestamps,
                                file,
                                camera_data_directory.joinpath("face_camera_timestamps.feather"),
                            )
                        )

                    # Left Camera timestamps
                    if file.stem == "62_log":
                        futures.add(
                            executor.submit(
                                _process_camera_timestamps,
                                file,
                                camera_data_directory.joinpath("left_camera_timestamps.feather"),
                            )
                        )

                    # Right Camera timestamps
                    if file.stem == "73_log":
                        futures.add(
                            executor.submit(
                                _process_camera_timestamps,
                                file,
                                camera_data_directory.joinpath("right_camera_timestamps.feather"),
                            )
                        )

                    # Actor AMC module data
                    if file.stem == "101_log":
                        futures.add(
                            executor.submit(
                                _process_actor_data,
                                file,
                                behavior_data_directory,
                                hardware_configuration,
                            )
                        )

                    # Sensor AMC module data
                    if file.stem == "152_log":
                        futures.add(
                            executor.submit(
                                _process_sensor_data,
                                file,
                                behavior_data_directory,
                                hardware_configuration,
                            )
                        )

                    # Encoder AMC module data
                    if file.stem == "203_log":
                        futures.add(
                            executor.submit(
                                _process_encoder_data,
                                file,
                                behavior_data_directory,
                                hardware_configuration,
                            )
                        )

                # Displays a progress bar to track the parsing status if the function is called in the verbose mode.
                with tqdm(
                    total=len(futures),
                    desc=f"Processing log files",
                    unit="file",
                ) as pbar:
                    for future in as_completed(futures):
                        # Propagates any exceptions from the worker processes
                        future.result()
                        pbar.update(1)

                    # Configures the tracker to indicate that the processing runtime completed successfully
                    tracker.stop(manager_id=manager_id)

        # Aborts with an error if processing logic for the target acquisition system is not implemented
        else:
            message = (
                f"Behavior data processing logic for the acquisition system {session_data.acquisition_system} "
                f"is not implemented. Unable to process the session {session_data.session_name} of "
                f"animal {session_data.animal_id} and project {session_data.project_name}."
            )
            console.error(message=message, error=NotImplementedError)

        console.echo(message="Log processing: Complete.", level=LogLevel.SUCCESS)

    finally:
        # If the code reaches this section while the tracker indicates that the processing is still running,
        # this means that the processing runtime encountered an error. Configures the tracker to indicate that this
        # runtime finished with an error to prevent deadlocking future runtime calls.
        if tracker.is_running:
            tracker.error(manager_id=manager_id)

        # If the runtime is configured to generate the project manifest file, attempts to generate and overwrite the
        # existing manifest file for the target project.
        if update_manifest:
            # All sessions are stored under root/project/animal/session. SessionData exposes paths to either raw_data or
            # processed_data subdirectories under the root session directory on each volume. Indexing parents of
            # SessionData paths gives project-specific directory at index 2 and the root for that directory at index 3.
            raw_directory = session_data.raw_data.raw_data_path.parents[2]
            processed_directory = session_data.processed_data.processed_data_path.parents[3]

            # Generates the manifest file inside the root raw data project directory
            generate_project_manifest(
                raw_project_directory=raw_directory,
                processed_data_root=processed_directory,
                output_directory=raw_directory,
            )
