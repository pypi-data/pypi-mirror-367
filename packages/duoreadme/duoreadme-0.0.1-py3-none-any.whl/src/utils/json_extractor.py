"""
JSON content extractor

Used to extract JSON content from various response formats.
"""

import re
import json
from typing import Dict, Any, Optional, Tuple


class JSONExtractor:
    """JSON content extractor class"""
    
    @staticmethod
    def extract_json_from_response(response_text: str) -> Optional[Dict[str, Any]]:
        """
        Extract JSON content from response text
        
        Args:
            response_text: Response text
            
        Returns:
            Optional[Dict[str, Any]]: Extracted JSON data, returns None if extraction fails
        """
        if not response_text or not response_text.strip():
            return None
            
        # Method 1: Try to extract JSON code block
        json_data = JSONExtractor._extract_json_code_block(response_text)
        if json_data:
            return json_data
            
        # Method 2: Try to extract complete JSON object
        json_data = JSONExtractor._extract_complete_json_object(response_text)
        if json_data:
            return json_data
            
        # Method 3: Try to fix and parse incomplete JSON
        json_data = JSONExtractor._extract_and_fix_incomplete_json(response_text)
        if json_data:
            return json_data
            
        return None
    
    @staticmethod
    def _extract_json_code_block(response_text: str) -> Optional[Dict[str, Any]]:
        """Extract JSON from code block"""
        try:
            # Find ```json ... ``` format
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                json_text = json_match.group(1).strip()
                return json.loads(json_text)
                
            # Find ``` ... ``` format (might be JSON)
            code_match = re.search(r'```\s*(.*?)\s*```', response_text, re.DOTALL)
            if code_match:
                json_text = code_match.group(1).strip()
                # Check if it looks like JSON
                if json_text.startswith('{') and json_text.endswith('}'):
                    return json.loads(json_text)
        except (json.JSONDecodeError, AttributeError):
            pass
        return None
    
    @staticmethod
    def _extract_complete_json_object(response_text: str) -> Optional[Dict[str, Any]]:
        """Extract complete JSON object"""
        try:
            # Find first { and last }
            start = response_text.find('{')
            if start == -1:
                return None
                
            # Find matching closing brace
            brace_count = 0
            end = -1
            for i in range(start, len(response_text)):
                if response_text[i] == '{':
                    brace_count += 1
                elif response_text[i] == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        end = i + 1
                        break
            
            if end != -1:
                json_text = response_text[start:end]
                # Clean control characters
                json_text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_text)
                return json.loads(json_text)
        except (json.JSONDecodeError, IndexError):
            pass
        return None
    
    @staticmethod
    def _extract_and_fix_incomplete_json(response_text: str) -> Optional[Dict[str, Any]]:
        """Extract and fix incomplete JSON"""
        try:
            # Find JSON start position
            json_start = response_text.find('"English readme"')
            if json_start == -1:
                return None
                
            # Look backward for object start
            brace_start = response_text.rfind('{', 0, json_start)
            if brace_start == -1:
                return None
                
            # Try to find matching closing brace
            brace_count = 0
            brace_end = -1
            for i in range(brace_start, len(response_text)):
                if response_text[i] == '{':
                    brace_count += 1
                elif response_text[i] == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        brace_end = i + 1
                        break
            
            if brace_end == -1:
                # If no matching closing brace found, try to fix
                return JSONExtractor._fix_truncated_json(response_text[brace_start:])
            
            json_text = response_text[brace_start:brace_end]
            # Clean control characters
            json_text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_text)
            return json.loads(json_text)
            
        except (json.JSONDecodeError, IndexError):
            return None
    
    @staticmethod
    def _fix_truncated_json(json_text: str) -> Optional[Dict[str, Any]]:
        """Fix truncated JSON"""
        try:
            # Clean control characters
            json_text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_text)
            
            # If JSON is truncated, try to add necessary closing parts
            if not json_text.endswith('}'):
                # Find last complete key-value pair
                last_comma = json_text.rfind(',')
                if last_comma != -1:
                    # Remove last comma and add closing brace
                    json_text = json_text[:last_comma] + '}'
                else:
                    # If no comma, directly add closing brace
                    json_text += '}'
            
            return json.loads(json_text)
        except (json.JSONDecodeError, IndexError):
            return None
    
    @staticmethod
    def extract_language_content(json_data: Dict[str, Any]) -> Dict[str, str]:
        """
        Extract language content from JSON data
        
        Args:
            json_data: JSON data
            
        Returns:
            Dict[str, str]: Language code to content mapping
        """
        # Support multiple possible key name formats
        language_map = {
            # Standard language codes
            "zh-Hans": "zh-Hans",
            "zh-Hant": "zh-Hant", 
            "en": "en",
            "ja": "ja",
            "ko": "ko",
            "fr": "fr",
            "de": "de",
            "es": "es",
            "it": "it",
            "pt": "pt",
            "pt-PT": "pt-PT",
            "ru": "ru",
            "th": "th",
            "vi": "vi",
            "hi": "hi",
            "ar": "ar",
            "tr": "tr",
            "pl": "pl",
            "nl": "nl",
            "sv": "sv",
            "da": "da",
            "no": "no",
            "nb": "nb",
            "fi": "fi",
            "cs": "cs",
            "sk": "sk",
            "hu": "hu",
            "ro": "ro",
            "bg": "bg",
            "hr": "hr",
            "sl": "sl",
            "et": "et",
            "lv": "lv",
            "lt": "lt",
            "mt": "mt",
            "el": "el",
            "ca": "ca",
            "eu": "eu",
            "gl": "gl",
            "af": "af",
            "zu": "zu",
            "xh": "xh",
            "st": "st",
            "sw": "sw",
            "yo": "yo",
            "ig": "ig",
            "ha": "ha",
            "am": "am",
            "or": "or",
            "bn": "bn",
            "gu": "gu",
            "pa": "pa",
            "te": "te",
            "kn": "kn",
            "ml": "ml",
            "ta": "ta",
            "si": "si",
            "my": "my",
            "km": "km",
            "lo": "lo",
            "ne": "ne",
            "ur": "ur",
            "fa": "fa",
            "ps": "ps",
            "sd": "sd",
            "he": "he",
            "yue": "yue",
            
            # Language names (English)
            "English": "en",
            "Chinese": "zh-Hans",
            "Traditional Chinese": "zh-Hant",
            "Japanese": "ja",
            "Korean": "ko",
            "French": "fr",
            "German": "de",
            "Spanish": "es",
            "Italian": "it",
            "Portuguese": "pt",
            "Portuguese (Portugal)": "pt-PT",
            "Russian": "ru",
            "Thai": "th",
            "Vietnamese": "vi",
            "Hindi": "hi",
            "Arabic": "ar",
            "Turkish": "tr",
            "Polish": "pl",
            "Dutch": "nl",
            "Swedish": "sv",
            "Danish": "da",
            "Norwegian": "no",
            "Norwegian Bokm√•l": "nb",
            "Finnish": "fi",
            "Czech": "cs",
            "Slovak": "sk",
            "Hungarian": "hu",
            "Romanian": "ro",
            "Bulgarian": "bg",
            "Croatian": "hr",
            "Slovenian": "sl",
            "Estonian": "et",
            "Latvian": "lv",
            "Lithuanian": "lt",
            "Maltese": "mt",
            "Greek": "el",
            "Catalan": "ca",
            "Basque": "eu",
            "Galician": "gl",
            "Afrikaans": "af",
            "Zulu": "zu",
            "Xhosa": "xh",
            "Sotho": "st",
            "Swahili": "sw",
            "Yoruba": "yo",
            "Igbo": "ig",
            "Hausa": "ha",
            "Amharic": "am",
            "Odia": "or",
            "Bengali": "bn",
            "Gujarati": "gu",
            "Punjabi": "pa",
            "Telugu": "te",
            "Kannada": "kn",
            "Malayalam": "ml",
            "Tamil": "ta",
            "Sinhala": "si",
            "Burmese": "my",
            "Khmer": "km",
            "Lao": "lo",
            "Nepali": "ne",
            "Urdu": "ur",
            "Persian": "fa",
            "Pashto": "ps",
            "Sindhi": "sd",
            "Hebrew": "he",
            "Cantonese": "yue",
            
            # Format with "readme" suffix
            "English readme": "en",
            "Chinese readme": "zh-Hans",
            "Traditional Chinese readme": "zh-Hant",
            "Japanese readme": "ja",
            "Korean readme": "ko",
            "French readme": "fr",
            "German readme": "de",
            "Spanish readme": "es",
            "Italian readme": "it",
            "Portuguese readme": "pt",
            "Portuguese (Portugal) readme": "pt-PT",
            "Russian readme": "ru",
            "Thai readme": "th",
            "Vietnamese readme": "vi",
            "Hindi readme": "hi",
            "Arabic readme": "ar",
            "Turkish readme": "tr",
            "Polish readme": "pl",
            "Dutch readme": "nl",
            "Swedish readme": "sv",
            "Danish readme": "da",
            "Norwegian readme": "no",
            "Norwegian Bokm√•l readme": "nb",
            "Finnish readme": "fi",
            "Czech readme": "cs",
            "Slovak readme": "sk",
            "Hungarian readme": "hu",
            "Romanian readme": "ro",
            "Bulgarian readme": "bg",
            "Croatian readme": "hr",
            "Slovenian readme": "sl",
            "Estonian readme": "et",
            "Latvian readme": "lv",
            "Lithuanian readme": "lt",
            "Maltese readme": "mt",
            "Greek readme": "el",
            "Catalan readme": "ca",
            "Basque readme": "eu",
            "Galician readme": "gl",
            "Afrikaans readme": "af",
            "Zulu readme": "zu",
            "Xhosa readme": "xh",
            "Sotho readme": "st",
            "Swahili readme": "sw",
            "Yoruba readme": "yo",
            "Igbo readme": "ig",
            "Hausa readme": "ha",
            "Amharic readme": "am",
            "Odia readme": "or",
            "Bengali readme": "bn",
            "Gujarati readme": "gu",
            "Punjabi readme": "pa",
            "Telugu readme": "te",
            "Kannada readme": "kn",
            "Malayalam readme": "ml",
            "Tamil readme": "ta",
            "Sinhala readme": "si",
            "Burmese readme": "my",
            "Khmer readme": "km",
            "Lao readme": "lo",
            "Nepali readme": "ne",
            "Urdu readme": "ur",
            "Persian readme": "fa",
            "Pashto readme": "ps",
            "Sindhi readme": "sd",
            "Hebrew readme": "he",
            "Cantonese readme": "yue",
            
            # Other possible formats
            "Êó•Êú¨Ë™û readme": "ja",
            "‰∏≠Êñá readme": "zh-Hans",
            "ÁπÅÈ´î‰∏≠Êñá readme": "zh-Hant",
            "ÌïúÍµ≠Ïñ¥ readme": "ko",
            "Fran√ßais readme": "fr",
            "Deutsch readme": "de",
            "Espa√±ol readme": "es",
            "Italiano readme": "it",
            "Portugu√™s readme": "pt",
            "Portugu√™s (Portugal) readme": "pt-PT",
            "–†—É—Å—Å–∫–∏–π readme": "ru",
            "‡πÑ‡∏ó‡∏¢ readme": "th",
            "‡§π‡§ø‡§®‡•ç‡§¶‡•Ä readme": "hi",
            "ÿßŸÑÿπÿ±ÿ®Ÿäÿ© readme": "ar",
            "Ti·∫øng Vi·ªát readme": "vi",
            "T√ºrk√ße readme": "tr",
            "Polski readme": "pl",
            "Nederlands readme": "nl",
            "Svenska readme": "sv",
            "Dansk readme": "da",
            "Norsk readme": "no",
            "Norsk Bokm√•l readme": "nb",
            "Suomi readme": "fi",
            "ƒåe≈°tina readme": "cs",
            "Slovenƒçina readme": "sk",
            "Magyar readme": "hu",
            "Rom√¢nƒÉ readme": "ro",
            "–±—ä–ª–≥–∞—Ä—Å–∫–∏ readme": "bg",
            "Hrvatski readme": "hr",
            "Sloven≈°ƒçina readme": "sl",
            "Eesti readme": "et",
            "Latvie≈°u readme": "lv",
            "Lietuvi≈≥ readme": "lt",
            "Malti readme": "mt",
            "ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ readme": "el",
            "Catal√† readme": "ca",
            "Euskara readme": "eu",
            "Galego readme": "gl",
            "Afrikaans readme": "af",
            "IsiZulu readme": "zu",
            "isiXhosa readme": "xh",
            "Sesotho readme": "st",
            "Kiswahili readme": "sw",
            "√àd√® Yor√πb√° readme": "yo",
            "As·ª•s·ª• Igbo readme": "ig",
            "Hausa readme": "ha",
            "·ä†·àõ·à≠·äõ readme": "am",
            "‡¨ì‡¨°‡¨º‡¨ø‡¨Ü readme": "or",
            "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ readme": "bn",
            "‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä readme": "gu",
            "‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä readme": "pa",
            "‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å readme": "te",
            "‡≤ï‡≤®‡≥ç‡≤®‡≤° readme": "kn",
            "‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç readme": "ml",
            "‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç readme": "ta",
            "‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω readme": "si",
            "·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨ readme": "my",
            "·ûó·û∂·ûü·û∂·ûÅ·üí·ûò·üÇ·ûö readme": "km",
            "‡∫•‡∫≤‡∫ß readme": "lo",
            "‡§®‡•á‡§™‡§æ‡§≤‡•Ä readme": "ne",
            "ÿßÿ±ÿØŸà readme": "ur",
            "ŸÅÿßÿ±ÿ≥€å readme": "fa",
            "Ÿæ⁄öÿ™Ÿà readme": "ps",
            "ÿ≥ŸÜ⁄åŸä readme": "sd",
            "◊¢◊ë◊®◊ô◊™ readme": "he",
            "Á≤µË™û readme": "yue",
            
            # Native language names (without "readme" suffix)
            "‰∏≠Êñá": "zh-Hans",
            "ÁπÅÈ´î‰∏≠Êñá": "zh-Hant",
            "Êó•Êú¨Ë™û": "ja",
            "ÌïúÍµ≠Ïñ¥": "ko",
            "Fran√ßais": "fr",
            "Deutsch": "de",
            "Espa√±ol": "es",
            "Italiano": "it",
            "Portugu√™s": "pt",
            "Portugu√™s (Portugal)": "pt-PT",
            "–†—É—Å—Å–∫–∏–π": "ru",
            "‡πÑ‡∏ó‡∏¢": "th",
            "‡§π‡§ø‡§®‡•ç‡§¶‡•Ä": "hi",
            "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©": "ar",
            "Ti·∫øng Vi·ªát": "vi",
            "T√ºrk√ße": "tr",
            "Polski": "pl",
            "Nederlands": "nl",
            "Svenska": "sv",
            "Dansk": "da",
            "Norsk": "no",
            "Norsk Bokm√•l": "nb",
            "Suomi": "fi",
            "ƒåe≈°tina": "cs",
            "Slovenƒçina": "sk",
            "Magyar": "hu",
            "Rom√¢nƒÉ": "ro",
            "–±—ä–ª–≥–∞—Ä—Å–∫–∏": "bg",
            "Hrvatski": "hr",
            "Sloven≈°ƒçina": "sl",
            "Eesti": "et",
            "Latvie≈°u": "lv",
            "Lietuvi≈≥": "lt",
            "Malti": "mt",
            "ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨": "el",
            "Catal√†": "ca",
            "Euskara": "eu",
            "Galego": "gl",
            "Afrikaans": "af",
            "IsiZulu": "zu",
            "isiXhosa": "xh",
            "Sesotho": "st",
            "Kiswahili": "sw",
            "√àd√® Yor√πb√°": "yo",
            "As·ª•s·ª• Igbo": "ig",
            "Hausa": "ha",
            "·ä†·àõ·à≠·äõ": "am",
            "‡¨ì‡¨°‡¨º‡¨ø‡¨Ü": "or",
            "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ": "bn",
            "‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä": "gu",
            "‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä": "pa",
            "‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å": "te",
            "‡≤ï‡≤®‡≥ç‡≤®‡≤°": "kn",
            "‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç": "ml",
            "‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç": "ta",
            "‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω": "si",
            "·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨": "my",
            "·ûó·û∂·ûü·û∂·ûÅ·üí·ûò·üÇ·ûö": "km",
            "‡∫•‡∫≤‡∫ß": "lo",
            "‡§®‡•á‡§™‡§æ‡§≤‡•Ä": "ne",
            "ÿßÿ±ÿØŸà": "ur",
            "ŸÅÿßÿ±ÿ≥€å": "fa",
            "Ÿæ⁄öÿ™Ÿà": "ps",
            "ÿ≥ŸÜ⁄åŸä": "sd",
            "◊¢◊ë◊®◊ô◊™": "he",
            "Á≤µË™û": "yue"
        }
        
        results = {}
        for key, content in json_data.items():
            # Try direct key name matching
            lang_code = language_map.get(key)
            if lang_code and content and str(content).strip():
                results[lang_code] = str(content).strip()
                continue
            
            # If direct matching fails, try to normalize key name
            normalized_key = key.strip().lower()
            for map_key, map_value in language_map.items():
                if normalized_key == map_key.lower():
                    results[map_value] = str(content).strip()
                    break
        
        return results


def extract_json_content(response_text: str) -> Tuple[Optional[Dict[str, Any]], Dict[str, str]]:
    """
    Extract JSON content from response text and parse language content
    
    Args:
        response_text: Response text
        
    Returns:
        Tuple[Optional[Dict[str, Any]], Dict[str, str]]: (JSON data, language content mapping)
    """
    extractor = JSONExtractor()
    json_data = extractor.extract_json_from_response(response_text)
    
    if json_data:
        language_content = extractor.extract_language_content(json_data)
        return json_data, language_content
    else:
        return None, {} 