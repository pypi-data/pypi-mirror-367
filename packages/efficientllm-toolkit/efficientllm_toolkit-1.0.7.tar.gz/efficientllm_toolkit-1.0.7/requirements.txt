# Core dependencies for EfficientLLM
torch>=2.0.0
transformers>=4.35.0,<=4.52.4,!=4.52.0
datasets>=2.14.0
numpy>=1.21.0,<2.0.0
pandas>=1.3.0
tensorboard>=2.10.0
tqdm>=4.64.0
pyyaml>=6.0
psutil>=5.9.0
nvidia-ml-py3>=7.352.0

# Model-specific dependencies
vllm>=0.2.0
accelerate>=0.24.0
sentencepiece>=0.1.97
tokenizers>=0.19.0
protobuf>=3.20.0
packaging

# For Mamba models
mamba-ssm>=1.2.0
causal-conv1d>=1.4.0

# For RWKV models  
pytorch-lightning>=1.9.5

# For evaluation
einops
scipy
fire
omegaconf

# For distributed training
deepspeed

# For PEFT fine-tuning
peft>=0.12.0
trl>=0.8.0

# Utility
matplotlib>=3.7.0