trainer:
  strategy: ddp_find_unused_parameters_true
  log_every_n_steps: 300
  gradient_clip_val: 500
  limit_train_batches: 14000
  limit_val_batches: 2000
  reload_dataloaders_every_n_epochs: 1
  accumulate_grad_batches: 2
model:
  nhead: 20
  lr: 0.00001
  nlayers: 32
  layers_cls: [512]
  d_model: 1280
data:
  batch_size: 3
  num_workers: 9
