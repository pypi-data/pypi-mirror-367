Metadata-Version: 2.4
Name: promptfold
Version: 1.0.15
Summary: Python client for PromptFold API - optimize prompts with PromptFold
Author-email: PromptFold Team <team@promptfold.com>
License: MIT
Project-URL: Homepage, https://github.com/paulcrowley/promptfold
Project-URL: Repository, https://github.com/paulcrowley/promptfold
Project-URL: Issues, https://github.com/paulcrowley/promptfold/issues
Keywords: promptfold,optimization,api,client
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Text Processing :: Linguistic
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.25.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: black>=21.0; extra == "dev"
Requires-Dist: flake8>=3.8; extra == "dev"

# PromptFold Client Library

This package provides a simple Python client for the PromptFold API available on PyPI.

## Installation
```bash
pip install promptfold
```

## Usage

```python
import openai
from promptfold_client import PromptFold

# Initialize PromptFold client, compress your system prompt
pf_client = PromptFold(api_key="YOUR_PROMPTFOLD_API_KEY", system_prompt="Your system prompt.")

# Compress the original user prompt and system prompt
compressed = pf_client.compress_prompt(user_prompt="Input user prompt")

# Call OpenAI's GPT-4 with the compressed prompt
openai.api_key = "YOUR_OPENAI_API_KEY"
response = openai.ChatCompletion.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": compressed.compressed_system_prompt},
        {"role": "user", "content": compressed.compressed_user_prompt}
    ]
)

# Print the response from GPT-4
print(response["choices"][0]["message"]["content"])

```

## Publishing a New Version (for Maintainers)

Publishing the client is handled by a script that automates the entire process.

**Prerequisites:**
1.  **PyPI Account:** You need an account on [PyPI](https://pypi.org) and an API token.
2.  **Twine Configuration:** Your local machine must be configured to authenticate with PyPI. You can do this by setting the `TWINE_USERNAME` and `TWINE_PASSWORD` environment variables.

**To publish a new version:**
1.  Navigate to the client directory: `cd promptfold_client`
2.  Run the publishing script. You have two options:
    *   **To automatically bump the patch version** (e.g., `1.0.1` -> `1.0.2`), run the script without arguments:
        ```bash
        ./publish_pypi.sh
        ```
    *   **To specify an exact version** (e.g., for a major release like `2.0.0`), provide it as an argument:
        ```bash
        ./publish_pypi.sh 2.0.0
        ```
3.  The script will handle everything else automatically.
