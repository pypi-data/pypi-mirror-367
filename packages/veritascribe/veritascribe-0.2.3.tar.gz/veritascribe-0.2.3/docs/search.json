[
  {
    "objectID": "usage.html",
    "href": "usage.html",
    "title": "Usage Guide",
    "section": "",
    "text": "This comprehensive guide covers all aspects of using VeritaScribe to analyze thesis documents.\n\n\nVeritaScribe provides several commands for different use cases:\n\n\n\n\n\n\n\n\nCommand\nPurpose\nUse Case\n\n\n\n\ndemo\nCreate and analyze sample document\nTesting setup\n\n\nquick\nFast analysis of document subset\nQuick feedback\n\n\nanalyze\nFull document analysis\nComplete review\n\n\nconfig\nView configuration\nTroubleshooting\n\n\nproviders\nList available LLM providers\nProvider setup\n\n\noptimize-prompts\nFine-tune analysis prompts\nAccuracy improvement\n\n\ntest\nSystem diagnostics\nVerify installation\n\n\n\n\n\n\nVeritaScribe supports multiple LLM providers. Choose based on your needs:\n\n\nuv run python -m veritascribe providers\nThis shows all supported providers, their models, and configuration examples.\n\n\n\nFor Academic Use: - OpenAI: Most reliable, extensive model selection - Anthropic: Excellent reasoning, safety-focused - OpenRouter: Access to multiple providers, competitive pricing\nFor Cost Optimization: - OpenRouter: Free models available (z-ai/glm-4.5-air:free) - Local Ollama: No API costs, privacy-focused - OpenAI gpt-3.5-turbo: Cheapest commercial option\nFor Privacy/Security: - Local Ollama: Complete data privacy - Custom endpoints: Organizational control - Azure OpenAI: Enterprise compliance\n\n\n\n# OpenAI (standard)\necho \"LLM_PROVIDER=openai\" &gt;&gt; .env\necho \"OPENAI_API_KEY=your-key\" &gt;&gt; .env\n\n# OpenRouter (100+ models)\necho \"LLM_PROVIDER=openrouter\" &gt;&gt; .env  \necho \"OPENROUTER_API_KEY=your-key\" &gt;&gt; .env\necho \"DEFAULT_MODEL=anthropic/claude-3.5-sonnet\" &gt;&gt; .env\n\n# Anthropic (direct Claude)\necho \"LLM_PROVIDER=anthropic\" &gt;&gt; .env\necho \"ANTHROPIC_API_KEY=your-key\" &gt;&gt; .env\n\n# Local Ollama (free)\necho \"LLM_PROVIDER=custom\" &gt;&gt; .env\necho \"OPENAI_BASE_URL=http://localhost:11434/v1\" &gt;&gt; .env\necho \"DEFAULT_MODEL=llama3.1:8b\" &gt;&gt; .env\n\n\n\n\n\n\nStart with the demo to familiarize yourself with VeritaScribe:\nuv run python -m veritascribe demo\nThis command will: - Create a sample thesis PDF (demo_thesis.pdf) - Perform quick analysis if API key is configured - Show example output and reports\n\n\n\nFor rapid feedback on your document:\nuv run python -m veritascribe quick your_thesis.pdf\nQuick analysis: - Analyzes first 5 text blocks by default - Provides immediate feedback - Useful during writing process - Lower API costs\nCustomize block count:\nuv run python -m veritascribe quick your_thesis.pdf --blocks 10\n\n\n\nFor comprehensive document review:\nuv run python -m veritascribe analyze your_thesis.pdf\nThis performs: - Complete document analysis - All error types detection - Detailed reporting - Visualization generation\n\n\n\n\n\n\nThe primary command for comprehensive thesis analysis.\n\n\nuv run python -m veritascribe analyze thesis.pdf\n\n\n\nuv run python -m veritascribe analyze thesis.pdf \\\n  --output ./results \\\n  --citation-style APA \\\n  --annotate \\\n  --verbose\n\n\n\n\n\n\nOption\nShort\nDescription\nDefault\n\n\n\n\n--output\n-o\nOutput directory\n./analysis_output\n\n\n--citation-style\n-c\nCitation style\nAPA\n\n\n--quick\n-q\nQuick mode (10 blocks)\nfalse\n\n\n--no-viz\n\nSkip visualizations\nfalse\n\n\n--annotate\n\nGenerate annotated PDF\nfalse\n\n\n--verbose\n-v\nVerbose logging\nfalse\n\n\n\n\n\n\n# American Psychological Association\n--citation-style APA\n\n# Modern Language Association  \n--citation-style MLA\n\n# Chicago Manual of Style\n--citation-style Chicago\n\n# IEEE format\n--citation-style IEEE\n\n# Harvard referencing\n--citation-style Harvard\n\n\n\nStandard Analysis:\nuv run python -m veritascribe analyze thesis.pdf\nGenerate Annotated PDF:\nuv run python -m veritascribe analyze thesis.pdf --annotate\nThe annotated PDF will contain: - Color-coded highlights on problematic text (red/orange/yellow by severity) - Detailed sticky note annotations with suggestions and explanations - All original document formatting preserved\nCustom Output Location:\nuv run python -m veritascribe analyze thesis.pdf \\\n  --output ~/Documents/thesis_review\n\n\n\n\nIdeal for iterative writing and quick feedback.\n\n\nuv run python -m veritascribe quick thesis.pdf\n\n\n\n# Analyze first 3 blocks\nuv run python -m veritascribe quick thesis.pdf --blocks 3\n\n# Analyze first 15 blocks  \nuv run python -m veritascribe quick thesis.pdf --blocks 15\n\n\n\n\nFine-tunes the analysis prompts using few-shot learning with bilingual training data for improved accuracy.\nuv run python -m veritascribe optimize-prompts\n\n\nThe prompt optimization process:\n\nTrains Language-Specific Modules: Creates optimized DSPy modules for both English and German\nUses Curated Training Data: Leverages hand-crafted examples of grammar, content, and citation errors\nApplies Few-Shot Learning: Uses DSPy’s BootstrapFewShot compilation to improve prompt performance\nEnhances Accuracy: Results in significantly better error detection and fewer false positives\n\n\n\n\n\nAfter Installation: Run once to set up optimized prompts for better results\nWhen Analysis Quality is Poor: If you notice many false positives or missed errors\nAfter Updating Training Data: When you’ve added new examples to the training dataset\nFor Research/Academic Use: When maximum accuracy is more important than processing speed\n\n\n\n\n# The optimization process will:\n# 1. Load bilingual training examples\n# 2. Compile optimized modules for each analysis type\n# 3. Save compiled modules for future use\n# 4. Take 3-5 minutes to complete\n\nuv run python -m veritascribe optimize-prompts\nNote: This process requires significant LLM API usage as it trains multiple modules. Budget approximately $2-5 in API costs for the full optimization process.\n\n\n\n\nCreates and analyzes a demo thesis document for testing and demonstration.\nuv run python -m veritascribe demo\nThis command: - Creates a sample PDF document (demo_thesis.pdf) with intentional errors - Runs quick analysis if API key is configured - Provides example output to familiarize you with the system - Perfect for testing your setup and configuration\n\n\n\nDisplays current configuration settings and provider information.\nuv run python -m veritascribe config\nShows: - Active LLM provider and model - API key configuration status - Analysis settings (temperature, max tokens, etc.) - Recommended models for your provider - Configuration validation results\n\n\n\nShows all supported LLM providers, models, and configuration examples.\nuv run python -m veritascribe providers\nDisplays: - Available providers (OpenAI, OpenRouter, Anthropic, Custom) - Recommended models for each provider - Configuration examples - Quick setup instructions for each provider\n\n\n\nVerifies that all components are working correctly.\nuv run python -m veritascribe test\nTests: - Configuration loading - PDF processing functionality - Analysis modules (if API key configured) - System integration and dependencies - Provides diagnostic information for troubleshooting\n\n\n\n\n\n\nVeritaScribe provides rich console output with progress indicators and summaries:\nStarting analysis of: thesis.pdf\nOutput directory: ./analysis_output\n\nAnalyzing document... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100%\n\nAnalysis Results: thesis.pdf\n┌─────────────────────────────────────────────────────────────────────────────────┐\n│ 📄 Pages: 45                                                                    │\n│ 📝 Words: 12,543                                                               │\n│ 🔍 Text blocks analyzed: 87                                                     │\n│ ⚠️  Total errors: 23                                                            │\n│ 📊 Error rate: 1.83 per 1,000 words                                           │\n│ ⏱️  Processing time: 45.32s                                                     │\n│ 🔤 Token usage: 15,234 tokens                                                    │\n│ 💰 Estimated cost: $0.0457 USD                                                   │\n└─────────────────────────────────────────────────────────────────────────────────┘\n\nErrors by Type\n...\n\n\n\nEach analysis produces several output files:\n\n\nComprehensive Markdown report with summaries, detailed error listings, and cost information.\n\n\n\nStructured data for programmatic access, including all errors, locations, and analysis statistics.\n\n\n\nCharts and graphs showing error distribution, density, and severity.\n\n\n\nAn interactive PDF that transforms your original document into a comprehensive visual review tool.\nWhat You Get:\n\nVisual Error Highlighting: Problematic text is highlighted directly on the page using a severity-based color system:\n\n🔴 Red Highlights: High-severity errors requiring immediate attention (grammar mistakes, logical inconsistencies, missing citations)\n🟠 Orange Highlights: Medium-severity errors needing improvement (style issues, minor grammar problems, formatting inconsistencies)\n🟡 Yellow Highlights: Low-severity suggestions for enhancement (stylistic preferences, optional improvements)\n\nDetailed Sticky Note Annotations: Each error includes a comprehensive sticky note with:\nERROR: Grammar\nSeverity: High\n\nOriginal: The results shows that our hypothesis\nSuggested: The results show that our hypothesis\n\nExplanation: Subject-verb disagreement: 'results' is plural \nand requires the plural verb 'show'\n\nConfidence: 95.0%\nSmart Annotation Positioning: Annotations are automatically positioned to avoid overlaps while maintaining readability\nPreserves Original Document: All original formatting, images, and layout are maintained while adding the review layer\n\nPerfect Use Cases: - Supervisor Review: Share annotated PDFs with advisors for targeted feedback discussions - Collaborative Editing: Team members can see exactly what needs attention - Iterative Writing: Quickly identify areas needing revision during the writing process - Self-Review: Visual representation helps you understand error patterns in your writing - Academic Presentations: Demonstrate quality control processes to committees\nImportant Notes: - Annotated PDFs are only generated when errors are found - The --annotate flag must be used explicitly - Annotations preserve the original PDF’s formatting and can be viewed in any standard PDF reader\n\n\n\n\n\nVeritaScribe provides intelligent multi-language support with automatic language detection and language-specific analysis.\n\n\nThe system automatically detects document language and applies appropriate analysis:\n# English document - automatically detected and analyzed with English grammar rules\nuv run python -m veritascribe analyze english_thesis.pdf\n\n# German document - automatically detected and analyzed with German grammar rules  \nuv run python -m veritascribe analyze deutsche_abschlussarbeit.pdf\n\n# Mixed-language document - intelligently handles language switching\nuv run python -m veritascribe analyze multilingual_thesis.pdf\n\n\n\n\n\n\nGrammar: Subject-verb agreement, tense consistency, article usage\nAcademic Style: Formal writing conventions, passive voice usage\nCitations: APA, MLA, Chicago style formatting\nContent: Logical flow, argument structure, evidence validation\n\n\n\n\n\nGrammar: Kasus-Kongruenz (case agreement), Subjekt-Verb-Kongruenz\nAcademic Style: German academic writing conventions, complex sentence structure\nCitations: German academic citation styles, bibliography formatting\nContent: German academic argumentation patterns, cultural context awareness\n\n\n\n\n\n# Run prompt optimization to improve accuracy for both languages\nuv run python -m veritascribe optimize-prompts\n\n# This creates optimized modules for:\n# - English grammar, content, and citation analysis\n# - German grammar, content, and citation analysis\n# - Language detection and switching logic\n\n\n\n\nLanguage Consistency: Ensure your document maintains consistent language usage\nCultural Context: Be aware of different academic writing conventions\nCitation Styles: Use appropriate citation styles for your document’s language\nOptimization: Run prompt optimization for best results with non-English documents\n\n\n\n\n\n\n\nProcess multiple documents:\n# Create script for batch processing\ncat &gt; batch_analyze.sh &lt;&lt; 'EOF'\n#!/bin/bash\nfor pdf in *.pdf; do\n  echo \"Analyzing $pdf...\"\n  uv run python -m veritascribe analyze \"$pdf\" \\\n    --output \"./results/$(basename \"$pdf\" .pdf)\"\ndone\nEOF\n\nchmod +x batch_analyze.sh\n./batch_analyze.sh\n\n\n\nWorkflow for document improvement:\n# Step 1: Initial quick review\nuv run python -m veritascribe quick draft.pdf --blocks 10\n\n# Step 2: Address major issues, then full analysis with annotation\nuv run python -m veritascribe analyze draft.pdf --output ./review_1 --annotate\n\n# The annotated PDF will visually show all errors with severity-based highlighting\n\n# Step 3: After revisions, re-analyze\nuv run python -m veritascribe analyze revised_draft.pdf --output ./review_2\n\n# Step 4: Compare results\ndiff ./review_1/draft_*_data.json ./review_2/revised_draft_*_data.json\n\n\n\nOptimize API usage for large documents using different providers and models:\n# Strategy 1: Use free OpenRouter models\nLLM_PROVIDER=openrouter \\\nDEFAULT_MODEL=z-ai/glm-4.5-air:free \\\nuv run python -m veritascribe analyze large_thesis.pdf\n\n# Strategy 2: Use cheaper OpenAI models\nLLM_PROVIDER=openai \\\nDEFAULT_MODEL=gpt-3.5-turbo \\\nuv run python -m veritascribe analyze large_thesis.pdf\n\n# Strategy 3: Use local models (no API costs)\nLLM_PROVIDER=custom \\\nOPENAI_BASE_URL=http://localhost:11434/v1 \\\nDEFAULT_MODEL=llama3.1:8b \\\nuv run python -m veritascribe analyze large_thesis.pdf\n\n\n\n\n\n\n\nUse text-based PDFs: Avoid scanned documents when possible\nEnsure proper formatting: Well-structured documents analyze better\nCheck PDF integrity: Corrupted files may cause issues\nRemove passwords: Encrypted PDFs cannot be processed\n\n\n\n\n\nStart with quick analysis: Get overview before full analysis\nChoose appropriate provider: Match your needs and budget\nFocus on high-priority issues: Address critical errors first\nUse optimize-prompts: Fine-tune prompts for better accuracy, especially for non-English documents\nConsider document language: German and other non-English documents benefit significantly from prompt optimization\n\n\nFor troubleshooting common issues, see the Troubleshooting Guide."
  },
  {
    "objectID": "usage.html#command-overview",
    "href": "usage.html#command-overview",
    "title": "Usage Guide",
    "section": "",
    "text": "VeritaScribe provides several commands for different use cases:\n\n\n\n\n\n\n\n\nCommand\nPurpose\nUse Case\n\n\n\n\ndemo\nCreate and analyze sample document\nTesting setup\n\n\nquick\nFast analysis of document subset\nQuick feedback\n\n\nanalyze\nFull document analysis\nComplete review\n\n\nconfig\nView configuration\nTroubleshooting\n\n\nproviders\nList available LLM providers\nProvider setup\n\n\noptimize-prompts\nFine-tune analysis prompts\nAccuracy improvement\n\n\ntest\nSystem diagnostics\nVerify installation"
  },
  {
    "objectID": "usage.html#provider-selection",
    "href": "usage.html#provider-selection",
    "title": "Usage Guide",
    "section": "",
    "text": "VeritaScribe supports multiple LLM providers. Choose based on your needs:\n\n\nuv run python -m veritascribe providers\nThis shows all supported providers, their models, and configuration examples.\n\n\n\nFor Academic Use: - OpenAI: Most reliable, extensive model selection - Anthropic: Excellent reasoning, safety-focused - OpenRouter: Access to multiple providers, competitive pricing\nFor Cost Optimization: - OpenRouter: Free models available (z-ai/glm-4.5-air:free) - Local Ollama: No API costs, privacy-focused - OpenAI gpt-3.5-turbo: Cheapest commercial option\nFor Privacy/Security: - Local Ollama: Complete data privacy - Custom endpoints: Organizational control - Azure OpenAI: Enterprise compliance\n\n\n\n# OpenAI (standard)\necho \"LLM_PROVIDER=openai\" &gt;&gt; .env\necho \"OPENAI_API_KEY=your-key\" &gt;&gt; .env\n\n# OpenRouter (100+ models)\necho \"LLM_PROVIDER=openrouter\" &gt;&gt; .env  \necho \"OPENROUTER_API_KEY=your-key\" &gt;&gt; .env\necho \"DEFAULT_MODEL=anthropic/claude-3.5-sonnet\" &gt;&gt; .env\n\n# Anthropic (direct Claude)\necho \"LLM_PROVIDER=anthropic\" &gt;&gt; .env\necho \"ANTHROPIC_API_KEY=your-key\" &gt;&gt; .env\n\n# Local Ollama (free)\necho \"LLM_PROVIDER=custom\" &gt;&gt; .env\necho \"OPENAI_BASE_URL=http://localhost:11434/v1\" &gt;&gt; .env\necho \"DEFAULT_MODEL=llama3.1:8b\" &gt;&gt; .env"
  },
  {
    "objectID": "usage.html#getting-started",
    "href": "usage.html#getting-started",
    "title": "Usage Guide",
    "section": "",
    "text": "Start with the demo to familiarize yourself with VeritaScribe:\nuv run python -m veritascribe demo\nThis command will: - Create a sample thesis PDF (demo_thesis.pdf) - Perform quick analysis if API key is configured - Show example output and reports\n\n\n\nFor rapid feedback on your document:\nuv run python -m veritascribe quick your_thesis.pdf\nQuick analysis: - Analyzes first 5 text blocks by default - Provides immediate feedback - Useful during writing process - Lower API costs\nCustomize block count:\nuv run python -m veritascribe quick your_thesis.pdf --blocks 10\n\n\n\nFor comprehensive document review:\nuv run python -m veritascribe analyze your_thesis.pdf\nThis performs: - Complete document analysis - All error types detection - Detailed reporting - Visualization generation"
  },
  {
    "objectID": "usage.html#command-details",
    "href": "usage.html#command-details",
    "title": "Usage Guide",
    "section": "",
    "text": "The primary command for comprehensive thesis analysis.\n\n\nuv run python -m veritascribe analyze thesis.pdf\n\n\n\nuv run python -m veritascribe analyze thesis.pdf \\\n  --output ./results \\\n  --citation-style APA \\\n  --annotate \\\n  --verbose\n\n\n\n\n\n\nOption\nShort\nDescription\nDefault\n\n\n\n\n--output\n-o\nOutput directory\n./analysis_output\n\n\n--citation-style\n-c\nCitation style\nAPA\n\n\n--quick\n-q\nQuick mode (10 blocks)\nfalse\n\n\n--no-viz\n\nSkip visualizations\nfalse\n\n\n--annotate\n\nGenerate annotated PDF\nfalse\n\n\n--verbose\n-v\nVerbose logging\nfalse\n\n\n\n\n\n\n# American Psychological Association\n--citation-style APA\n\n# Modern Language Association  \n--citation-style MLA\n\n# Chicago Manual of Style\n--citation-style Chicago\n\n# IEEE format\n--citation-style IEEE\n\n# Harvard referencing\n--citation-style Harvard\n\n\n\nStandard Analysis:\nuv run python -m veritascribe analyze thesis.pdf\nGenerate Annotated PDF:\nuv run python -m veritascribe analyze thesis.pdf --annotate\nThe annotated PDF will contain: - Color-coded highlights on problematic text (red/orange/yellow by severity) - Detailed sticky note annotations with suggestions and explanations - All original document formatting preserved\nCustom Output Location:\nuv run python -m veritascribe analyze thesis.pdf \\\n  --output ~/Documents/thesis_review\n\n\n\n\nIdeal for iterative writing and quick feedback.\n\n\nuv run python -m veritascribe quick thesis.pdf\n\n\n\n# Analyze first 3 blocks\nuv run python -m veritascribe quick thesis.pdf --blocks 3\n\n# Analyze first 15 blocks  \nuv run python -m veritascribe quick thesis.pdf --blocks 15\n\n\n\n\nFine-tunes the analysis prompts using few-shot learning with bilingual training data for improved accuracy.\nuv run python -m veritascribe optimize-prompts\n\n\nThe prompt optimization process:\n\nTrains Language-Specific Modules: Creates optimized DSPy modules for both English and German\nUses Curated Training Data: Leverages hand-crafted examples of grammar, content, and citation errors\nApplies Few-Shot Learning: Uses DSPy’s BootstrapFewShot compilation to improve prompt performance\nEnhances Accuracy: Results in significantly better error detection and fewer false positives\n\n\n\n\n\nAfter Installation: Run once to set up optimized prompts for better results\nWhen Analysis Quality is Poor: If you notice many false positives or missed errors\nAfter Updating Training Data: When you’ve added new examples to the training dataset\nFor Research/Academic Use: When maximum accuracy is more important than processing speed\n\n\n\n\n# The optimization process will:\n# 1. Load bilingual training examples\n# 2. Compile optimized modules for each analysis type\n# 3. Save compiled modules for future use\n# 4. Take 3-5 minutes to complete\n\nuv run python -m veritascribe optimize-prompts\nNote: This process requires significant LLM API usage as it trains multiple modules. Budget approximately $2-5 in API costs for the full optimization process.\n\n\n\n\nCreates and analyzes a demo thesis document for testing and demonstration.\nuv run python -m veritascribe demo\nThis command: - Creates a sample PDF document (demo_thesis.pdf) with intentional errors - Runs quick analysis if API key is configured - Provides example output to familiarize you with the system - Perfect for testing your setup and configuration\n\n\n\nDisplays current configuration settings and provider information.\nuv run python -m veritascribe config\nShows: - Active LLM provider and model - API key configuration status - Analysis settings (temperature, max tokens, etc.) - Recommended models for your provider - Configuration validation results\n\n\n\nShows all supported LLM providers, models, and configuration examples.\nuv run python -m veritascribe providers\nDisplays: - Available providers (OpenAI, OpenRouter, Anthropic, Custom) - Recommended models for each provider - Configuration examples - Quick setup instructions for each provider\n\n\n\nVerifies that all components are working correctly.\nuv run python -m veritascribe test\nTests: - Configuration loading - PDF processing functionality - Analysis modules (if API key configured) - System integration and dependencies - Provides diagnostic information for troubleshooting"
  },
  {
    "objectID": "usage.html#understanding-output",
    "href": "usage.html#understanding-output",
    "title": "Usage Guide",
    "section": "",
    "text": "VeritaScribe provides rich console output with progress indicators and summaries:\nStarting analysis of: thesis.pdf\nOutput directory: ./analysis_output\n\nAnalyzing document... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100%\n\nAnalysis Results: thesis.pdf\n┌─────────────────────────────────────────────────────────────────────────────────┐\n│ 📄 Pages: 45                                                                    │\n│ 📝 Words: 12,543                                                               │\n│ 🔍 Text blocks analyzed: 87                                                     │\n│ ⚠️  Total errors: 23                                                            │\n│ 📊 Error rate: 1.83 per 1,000 words                                           │\n│ ⏱️  Processing time: 45.32s                                                     │\n│ 🔤 Token usage: 15,234 tokens                                                    │\n│ 💰 Estimated cost: $0.0457 USD                                                   │\n└─────────────────────────────────────────────────────────────────────────────────┘\n\nErrors by Type\n...\n\n\n\nEach analysis produces several output files:\n\n\nComprehensive Markdown report with summaries, detailed error listings, and cost information.\n\n\n\nStructured data for programmatic access, including all errors, locations, and analysis statistics.\n\n\n\nCharts and graphs showing error distribution, density, and severity.\n\n\n\nAn interactive PDF that transforms your original document into a comprehensive visual review tool.\nWhat You Get:\n\nVisual Error Highlighting: Problematic text is highlighted directly on the page using a severity-based color system:\n\n🔴 Red Highlights: High-severity errors requiring immediate attention (grammar mistakes, logical inconsistencies, missing citations)\n🟠 Orange Highlights: Medium-severity errors needing improvement (style issues, minor grammar problems, formatting inconsistencies)\n🟡 Yellow Highlights: Low-severity suggestions for enhancement (stylistic preferences, optional improvements)\n\nDetailed Sticky Note Annotations: Each error includes a comprehensive sticky note with:\nERROR: Grammar\nSeverity: High\n\nOriginal: The results shows that our hypothesis\nSuggested: The results show that our hypothesis\n\nExplanation: Subject-verb disagreement: 'results' is plural \nand requires the plural verb 'show'\n\nConfidence: 95.0%\nSmart Annotation Positioning: Annotations are automatically positioned to avoid overlaps while maintaining readability\nPreserves Original Document: All original formatting, images, and layout are maintained while adding the review layer\n\nPerfect Use Cases: - Supervisor Review: Share annotated PDFs with advisors for targeted feedback discussions - Collaborative Editing: Team members can see exactly what needs attention - Iterative Writing: Quickly identify areas needing revision during the writing process - Self-Review: Visual representation helps you understand error patterns in your writing - Academic Presentations: Demonstrate quality control processes to committees\nImportant Notes: - Annotated PDFs are only generated when errors are found - The --annotate flag must be used explicitly - Annotations preserve the original PDF’s formatting and can be viewed in any standard PDF reader"
  },
  {
    "objectID": "usage.html#multi-language-document-analysis",
    "href": "usage.html#multi-language-document-analysis",
    "title": "Usage Guide",
    "section": "",
    "text": "VeritaScribe provides intelligent multi-language support with automatic language detection and language-specific analysis.\n\n\nThe system automatically detects document language and applies appropriate analysis:\n# English document - automatically detected and analyzed with English grammar rules\nuv run python -m veritascribe analyze english_thesis.pdf\n\n# German document - automatically detected and analyzed with German grammar rules  \nuv run python -m veritascribe analyze deutsche_abschlussarbeit.pdf\n\n# Mixed-language document - intelligently handles language switching\nuv run python -m veritascribe analyze multilingual_thesis.pdf\n\n\n\n\n\n\nGrammar: Subject-verb agreement, tense consistency, article usage\nAcademic Style: Formal writing conventions, passive voice usage\nCitations: APA, MLA, Chicago style formatting\nContent: Logical flow, argument structure, evidence validation\n\n\n\n\n\nGrammar: Kasus-Kongruenz (case agreement), Subjekt-Verb-Kongruenz\nAcademic Style: German academic writing conventions, complex sentence structure\nCitations: German academic citation styles, bibliography formatting\nContent: German academic argumentation patterns, cultural context awareness\n\n\n\n\n\n# Run prompt optimization to improve accuracy for both languages\nuv run python -m veritascribe optimize-prompts\n\n# This creates optimized modules for:\n# - English grammar, content, and citation analysis\n# - German grammar, content, and citation analysis\n# - Language detection and switching logic\n\n\n\n\nLanguage Consistency: Ensure your document maintains consistent language usage\nCultural Context: Be aware of different academic writing conventions\nCitation Styles: Use appropriate citation styles for your document’s language\nOptimization: Run prompt optimization for best results with non-English documents"
  },
  {
    "objectID": "usage.html#advanced-usage-patterns",
    "href": "usage.html#advanced-usage-patterns",
    "title": "Usage Guide",
    "section": "",
    "text": "Process multiple documents:\n# Create script for batch processing\ncat &gt; batch_analyze.sh &lt;&lt; 'EOF'\n#!/bin/bash\nfor pdf in *.pdf; do\n  echo \"Analyzing $pdf...\"\n  uv run python -m veritascribe analyze \"$pdf\" \\\n    --output \"./results/$(basename \"$pdf\" .pdf)\"\ndone\nEOF\n\nchmod +x batch_analyze.sh\n./batch_analyze.sh\n\n\n\nWorkflow for document improvement:\n# Step 1: Initial quick review\nuv run python -m veritascribe quick draft.pdf --blocks 10\n\n# Step 2: Address major issues, then full analysis with annotation\nuv run python -m veritascribe analyze draft.pdf --output ./review_1 --annotate\n\n# The annotated PDF will visually show all errors with severity-based highlighting\n\n# Step 3: After revisions, re-analyze\nuv run python -m veritascribe analyze revised_draft.pdf --output ./review_2\n\n# Step 4: Compare results\ndiff ./review_1/draft_*_data.json ./review_2/revised_draft_*_data.json\n\n\n\nOptimize API usage for large documents using different providers and models:\n# Strategy 1: Use free OpenRouter models\nLLM_PROVIDER=openrouter \\\nDEFAULT_MODEL=z-ai/glm-4.5-air:free \\\nuv run python -m veritascribe analyze large_thesis.pdf\n\n# Strategy 2: Use cheaper OpenAI models\nLLM_PROVIDER=openai \\\nDEFAULT_MODEL=gpt-3.5-turbo \\\nuv run python -m veritascribe analyze large_thesis.pdf\n\n# Strategy 3: Use local models (no API costs)\nLLM_PROVIDER=custom \\\nOPENAI_BASE_URL=http://localhost:11434/v1 \\\nDEFAULT_MODEL=llama3.1:8b \\\nuv run python -m veritascribe analyze large_thesis.pdf"
  },
  {
    "objectID": "usage.html#best-practices",
    "href": "usage.html#best-practices",
    "title": "Usage Guide",
    "section": "",
    "text": "Use text-based PDFs: Avoid scanned documents when possible\nEnsure proper formatting: Well-structured documents analyze better\nCheck PDF integrity: Corrupted files may cause issues\nRemove passwords: Encrypted PDFs cannot be processed\n\n\n\n\n\nStart with quick analysis: Get overview before full analysis\nChoose appropriate provider: Match your needs and budget\nFocus on high-priority issues: Address critical errors first\nUse optimize-prompts: Fine-tune prompts for better accuracy, especially for non-English documents\nConsider document language: German and other non-English documents benefit significantly from prompt optimization\n\n\nFor troubleshooting common issues, see the Troubleshooting Guide."
  },
  {
    "objectID": "troubleshooting.html",
    "href": "troubleshooting.html",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "This guide helps you diagnose and resolve common issues with VeritaScribe.\n\n\nBefore diving into specific issues, run these diagnostic commands:\n# Check system status\nuv run python -m veritascribe test\n\n# View current configuration\nuv run python -m veritascribe config\n\n# View available providers\nuv run python -m veritascribe providers\n\n# Try demo analysis\nuv run python -m veritascribe demo\n\n\n\n\n\nProblem: uv: command not found\nSolutions:\n\nInstall uv:\n# macOS/Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows PowerShell\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Alternative: pip install\npip install uv\nRestart terminal after installation\nCheck PATH:\necho $PATH | grep -o \"[^:]*uv[^:]*\"\n\n\n\n\nProblem: Python 3.13+ required but found 3.x.x\nSolutions:\n\nCheck available Python versions:\npython --version\npython3 --version\npython3.13 --version\nInstall Python 3.13:\n# macOS with Homebrew\nbrew install python@3.13\n\n# Ubuntu/Debian\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update && sudo apt install python3.13\nUse specific Python version:\nuv python install 3.13\nuv venv --python 3.13\n\n\n\n\nProblem: uv sync fails with compilation errors\nSolutions:\n\nUpdate uv:\nuv self update\nClear cache:\nuv cache clean\nInstall system dependencies:\n# macOS\nxcode-select --install\n\n# Ubuntu/Debian\nsudo apt update\nsudo apt install build-essential python3-dev\n\n# CentOS/RHEL\nsudo yum groupinstall \"Development Tools\"\nsudo yum install python3-devel\nUse pre-compiled wheels:\nuv sync --only-binary=all\n\n\n\n\nProblem: Permission errors during installation\nSolutions:\n\nDon’t use sudo with uv:\n# Wrong\nsudo uv sync\n\n# Correct\nuv sync\nFix directory permissions:\n# macOS/Linux\nsudo chown -R $(whoami) ~/.local/share/uv\nUse virtual environment:\nuv venv venv\nsource venv/bin/activate  # Linux/macOS\n# or\nvenv\\Scripts\\activate     # Windows\n\n\n\n\n\n\n\nProblem: API key is required for analysis or provider-specific errors\nDiagnosis:\n# Check if .env file exists\nls -la .env\n\n# Check current provider configuration\nuv run python -m veritascribe config\n\n# Check environment variables for your provider\necho $OPENAI_API_KEY      # For OpenAI or custom\necho $OPENROUTER_API_KEY  # For OpenRouter\necho $ANTHROPIC_API_KEY   # For Anthropic\n\n# Test API key validity (adjust for your provider)\nuv run python -c \"\nfrom veritascribe.config import get_settings, get_dspy_config\ntry:\n    settings = get_settings()\n    dspy_config = get_dspy_config()\n    lm = dspy_config.initialize_llm()\n    print('✓ API key and provider configuration valid')\nexcept Exception as e:\n    print(f'✗ Configuration error: {e}')\n\"\nSolutions:\n\nCreate .env file:\ncp .env.example .env\n# Edit .env and configure your chosen provider\nProvider-specific setup:\nOpenAI:\nLLM_PROVIDER=openai\nOPENAI_API_KEY=sk-your-key-here  # Starts with 'sk-', 51+ chars\nOpenRouter:\nLLM_PROVIDER=openrouter\nOPENROUTER_API_KEY=sk-or-your-key-here  # Starts with 'sk-or-'\nAnthropic:\nLLM_PROVIDER=anthropic\nANTHROPIC_API_KEY=sk-ant-your-key-here  # Starts with 'sk-ant-'\nCustom/Local:\nLLM_PROVIDER=custom\nOPENAI_API_KEY=any-value-for-local\nOPENAI_BASE_URL=http://localhost:11434/v1\nSet environment variables directly:\n# For OpenRouter example\nexport LLM_PROVIDER=openrouter\nexport OPENROUTER_API_KEY=\"your-key-here\"\nuv run python -m veritascribe config\nCheck API key status and billing:\n\nOpenAI: Platform Dashboard\nOpenRouter: Dashboard\nAnthropic: Console\nVerify key permissions and billing/credit status\n\n\n\n\n\nProblem: Model 'model-name' not available or model formatting errors\nDiagnosis:\n# Check current provider and model configuration\nuv run python -m veritascribe config\n\n# View available providers and their models\nuv run python -m veritascribe providers\n\n# Test model formatting\nuv run python -c \"\nfrom veritascribe.config import get_settings\nsettings = get_settings()\nformatted = settings.format_model_name()\nprint(f'Provider: {settings.llm_provider}')\nprint(f'Original model: {settings.default_model}')\nprint(f'Formatted model: {formatted}')\n\"\nSolutions:\n\nUse provider-specific model names:\nOpenAI:\nDEFAULT_MODEL=gpt-4  # or gpt-3.5-turbo, gpt-4-turbo\nOpenRouter (automatically prefixed):\nDEFAULT_MODEL=anthropic/claude-3.5-sonnet\n# DEFAULT_MODEL=openai/gpt-4\n# DEFAULT_MODEL=z-ai/glm-4.5-air:free\nAnthropic:\nDEFAULT_MODEL=claude-3-5-sonnet-20241022\n# DEFAULT_MODEL=claude-3-haiku-20240307\nCustom:\nDEFAULT_MODEL=llama3.1:8b  # Ollama format\n# DEFAULT_MODEL=gpt-4      # Azure deployment name\nCheck provider-specific availability:\n\nOpenAI: Usage Dashboard\nOpenRouter: Model List\nAnthropic: Console\nLocal: Check your model availability\n\nTry fallback models:\n# Safe fallback for each provider\n# OpenAI\nDEFAULT_MODEL=gpt-3.5-turbo\n\n# OpenRouter  \nDEFAULT_MODEL=z-ai/glm-4.5-air:free\n\n# Anthropic\nDEFAULT_MODEL=claude-3-haiku-20240307\n\n\n\n\nProblem: Failed to load configuration\nDiagnosis:\n# Check .env file format\ncat .env | grep -E \"^[A-Z_]+=.*$\"\n\n# Validate configuration\nuv run python -c \"\nfrom veritascribe.config import load_settings\ntry:\n    settings = load_settings()\n    print('✓ Configuration valid')\nexcept Exception as e:\n    print(f'✗ Configuration error: {e}')\n\"\nSolutions:\n\nFix .env format:\n# Correct format\nOPENAI_API_KEY=sk-your-key-here\nDEFAULT_MODEL=gpt-4\n\n# Wrong format (quotes, spaces)\nOPENAI_API_KEY = \"sk-your-key-here\"\nCheck file encoding:\nfile .env\n# Should show UTF-8 encoding\nReset to defaults:\ncp .env.example .env\n# Edit with minimal required settings\n\n\n\n\n\n\n\nProblem: Error: PDF file not found\nSolutions:\n\nCheck file path:\n# Use absolute path\nuv run python -m veritascribe analyze /full/path/to/thesis.pdf\n\n# Or relative from current directory\nls -la *.pdf\nuv run python -m veritascribe analyze ./thesis.pdf\nVerify file permissions:\nls -la thesis.pdf\n# Should show read permissions\nCheck file extension:\nfile thesis.pdf\n# Should show \"PDF document\"\n\n\n\n\nProblem: No text blocks extracted or PDF processing failed\nDiagnosis:\n# Test PDF with simple extraction\nuv run python -c \"\nimport fitz\ntry:\n    doc = fitz.open('thesis.pdf')\n    text = doc[0].get_text()\n    print(f'✓ Extracted {len(text)} characters from first page')\n    doc.close()\nexcept Exception as e:\n    print(f'✗ PDF error: {e}')\n\"\nSolutions:\n\nCheck PDF type:\n# Text-based PDFs work best\npdfinfo thesis.pdf | grep -E \"(Pages|Producer|Creator)\"\nTry different PDF:\n# Test with demo PDF\nuv run python -m veritascribe demo\nHandle password-protected PDFs:\n# Remove password first\nqpdf --password=PASSWORD --decrypt input.pdf output.pdf\nConvert scanned PDFs:\n# Use OCR tools first\nocrmypdf input.pdf output.pdf\n\n\n\n\nProblem: Out of memory or slow processing\nSolutions:\n\nReduce block size:\nMAX_TEXT_BLOCK_SIZE=1000 uv run python -m veritascribe analyze large.pdf\nDisable parallel processing:\nPARALLEL_PROCESSING=false uv run python -m veritascribe analyze large.pdf\nUse quick analysis:\nuv run python -m veritascribe quick large.pdf --blocks 20\nSplit large documents:\n# Split PDF into smaller parts\npdftk input.pdf burst output page_%02d.pdf\n\n\n\n\n\n\n\nProblem: Analysis modules failed, timeout errors, or provider-specific issues\nDiagnosis:\n# Test LLM connectivity for your provider\nuv run python -c \"\nfrom veritascribe.config import get_settings, get_dspy_config\n\ntry:\n    settings = get_settings()\n    dspy_config = get_dspy_config()\n    print(f'Provider: {settings.llm_provider}')\n    print(f'Model: {settings.format_model_name()}')\n    \n    lm = dspy_config.initialize_llm()\n    response = lm('Test prompt: Say \"Hello VeritaScribe\"')\n    print('✓ LLM connection working')\n    print(f'Response: {response}')\nexcept Exception as e:\n    print(f'✗ LLM error: {e}')\n    import traceback\n    traceback.print_exc()\n\"\nSolutions:\n\nReduce concurrency:\nMAX_CONCURRENT_REQUESTS=2 uv run python -m veritascribe analyze thesis.pdf\nIncrease timeout/retries:\nMAX_RETRIES=5 RETRY_DELAY=2.0 uv run python -m veritascribe analyze thesis.pdf\nCheck rate limits:\n\nVisit OpenAI Usage\nVerify you haven’t hit rate limits\nConsider upgrading API tier\n\nTry different models by provider:\n# OpenAI - use simpler model\nDEFAULT_MODEL=gpt-3.5-turbo uv run python -m veritascribe analyze thesis.pdf\n\n# OpenRouter - try free model\nLLM_PROVIDER=openrouter DEFAULT_MODEL=z-ai/glm-4.5-air:free uv run python -m veritascribe analyze thesis.pdf\n\n# Anthropic - use fastest model\nLLM_PROVIDER=anthropic DEFAULT_MODEL=claude-3-haiku-20240307 uv run python -m veritascribe analyze thesis.pdf\nCheck provider-specific rate limits:\n\nOpenAI: Rate limits page\nOpenRouter: Usage dashboard\nAnthropic: Rate limits\n\n\n\n\n\nProblem: JSON parsing error or invalid responses\nSolutions:\n\nEnable verbose logging:\nuv run python -m veritascribe analyze thesis.pdf --verbose\nReduce temperature:\nTEMPERATURE=0.0 uv run python -m veritascribe analyze thesis.pdf\nCheck token limits:\nMAX_TOKENS=1500 uv run python -m veritascribe analyze thesis.pdf\n\n\n\n\nProblem: Unexpected high token usage\nSolutions:\n\nMonitor usage:\n# Check configuration\nuv run python -m veritascribe config\nOptimize settings by provider:\n# OpenAI cost optimization\nLLM_PROVIDER=openai\nDEFAULT_MODEL=gpt-3.5-turbo\nMAX_TOKENS=1500\n\n# OpenRouter free model\nLLM_PROVIDER=openrouter\nDEFAULT_MODEL=z-ai/glm-4.5-air:free\n\n# Anthropic cost optimization\nLLM_PROVIDER=anthropic\nDEFAULT_MODEL=claude-3-haiku-20240307\n\n# Local model (no API costs)\nLLM_PROVIDER=custom\nOPENAI_BASE_URL=http://localhost:11434/v1\nDEFAULT_MODEL=llama3.1:8b\n\n# General optimizations\nMAX_TEXT_BLOCK_SIZE=1000\nPARALLEL_PROCESSING=false\nUse quick analysis:\nuv run python -m veritascribe quick thesis.pdf --blocks 10\nDisable analysis types:\nCONTENT_ANALYSIS_ENABLED=false uv run python -m veritascribe analyze thesis.pdf\n\n\n\n\n\n\n\nProblem: Report generation failed or missing output files\nSolutions:\n\nCheck output directory permissions:\nmkdir -p ./analysis_output\nchmod 755 ./analysis_output\nSpecify output directory:\nuv run python -m veritascribe analyze thesis.pdf --output ~/Documents/analysis\nDisable problematic outputs:\n# Skip visualizations if matplotlib issues\nuv run python -m veritascribe analyze thesis.pdf --no-viz\n\n\n\n\nProblem: Chart generation fails\nSolutions:\n\nInstall GUI backend:\n# macOS\nbrew install python-tk\n\n# Ubuntu/Debian\nsudo apt install python3-tk\nUse headless backend:\nuv run python -c \"\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nprint('✓ Matplotlib working')\n\"\nSkip visualizations:\nGENERATE_VISUALIZATIONS=false uv run python -m veritascribe analyze thesis.pdf\n\n\n\n\n\n\n\nProblem: Analysis takes too long\nDiagnosis:\n# Profile analysis\ntime uv run python -m veritascribe quick thesis.pdf --blocks 5\nSolutions:\n\nEnable parallel processing:\nPARALLEL_PROCESSING=true MAX_CONCURRENT_REQUESTS=5\nUse faster model:\nDEFAULT_MODEL=gpt-3.5-turbo\nReduce analysis scope:\n# Disable expensive analysis\nCONTENT_ANALYSIS_ENABLED=false\nOptimize block size:\nMAX_TEXT_BLOCK_SIZE=1500\n\n\n\n\nProblem: High memory consumption\nSolutions:\n\nMonitor memory:\n# Use memory profiler\npip install memory-profiler\nmprof run uv run python -m veritascribe analyze thesis.pdf\nmprof plot\nReduce batch size:\nMAX_CONCURRENT_REQUESTS=2\nClear cache:\n# Clear Python cache\nfind . -name \"*.pyc\" -delete\nfind . -name \"__pycache__\" -delete\n\n\n\n\n\n\n\nProblem: Connection timeout or network errors\nSolutions:\n\nCheck internet connectivity:\ncurl -I https://api.openai.com/v1/models\nConfigure proxy (if needed):\nexport HTTPS_PROXY=http://proxy.company.com:8080\nexport HTTP_PROXY=http://proxy.company.com:8080\nIncrease timeout:\n# Configure longer timeouts in requests\nREQUESTS_TIMEOUT=60\n\n\n\n\nProblem: Requests blocked by firewall\nSolutions:\n\nWhitelist OpenAI domains:\n\napi.openai.com\nopenai.com\n\nCheck corporate policies:\n\nContact IT about OpenAI API access\nConsider VPN if needed\n\nTest with curl:\ncurl -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n     https://api.openai.com/v1/models\n\n\n\n\n\n\n\nFor any issue, enable verbose logging:\n# Enable debug output\nuv run python -m veritascribe analyze thesis.pdf --verbose\n\n# Python logging\nPYTHONPATH=. python -c \"\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\nfrom veritascribe.main import main\nmain()\n\"\n\n\n\n# System info script\ncat &gt; debug_info.sh &lt;&lt; 'EOF'\n#!/bin/bash\necho \"=== System Information ===\"\nuname -a\npython --version\nuv --version\n\necho -e \"\\n=== VeritaScribe Configuration ===\"\nuv run python -m veritascribe config\n\necho -e \"\\n=== Environment Variables ===\"\nenv | grep -E \"(OPENAI|PYTHON|UV)\" | sort\n\necho -e \"\\n=== System Tests ===\"\nuv run python -m veritascribe test\n\necho -e \"\\n=== Dependencies ===\"\nuv tree\nEOF\n\nchmod +x debug_info.sh\n./debug_info.sh &gt; debug_info.txt\n\n\n\n# Create minimal test case\ncat &gt; minimal_test.py &lt;&lt; 'EOF'\n#!/usr/bin/env python3\n\"\"\"Minimal reproduction script.\"\"\"\n\nfrom veritascribe.config import load_settings\nfrom veritascribe.pdf_processor import PDFProcessor\nfrom veritascribe.pipeline import create_quick_pipeline\n\ndef main():\n    try:\n        # Test configuration\n        print(\"Testing configuration...\")\n        settings = load_settings()\n        print(f\"✓ Config loaded, model: {settings.default_model}\")\n        \n        # Test PDF processing\n        print(\"Testing PDF processing...\")\n        processor = PDFProcessor()\n        # Add your test PDF here\n        \n        # Test analysis\n        print(\"Testing analysis...\")\n        pipeline = create_quick_pipeline()\n        # Add your test case here\n        \n        print(\"✓ All tests passed\")\n        \n    except Exception as e:\n        print(f\"✗ Error: {e}\")\n        import traceback\n        traceback.print_exc()\n\nif __name__ == \"__main__\":\n    main()\nEOF\n\nuv run python minimal_test.py\n\n\n\n\n\n\n\n\n\n\n\nError Message\nLikely Cause\nQuick Fix\n\n\n\n\nuv: command not found\nuv not installed\nInstall uv\n\n\nAPI key is required\nMissing API key\nSet provider-specific API key\n\n\nLLM Provider NOT provided\nMissing provider prefix\nCheck model formatting\n\n\nPDF file not found\nWrong file path\nCheck file path\n\n\nNo text blocks extracted\nScanned PDF\nUse OCR first\n\n\nConnection timeout\nNetwork issue\nCheck connectivity\n\n\nRate limit exceeded\nToo many requests\nReduce concurrency\n\n\nModel not available\nWrong model name\nCheck provider models\n\n\nJSON parsing error\nMalformed LLM response\nReduce temperature\n\n\nPermission denied\nFile permissions\nCheck file access\n\n\nOut of memory\nLarge document\nReduce block size\n\n\n\n\n\n\nCreate an issue on the project repository with:\n\nError message and full traceback\nSystem information from debug script\nMinimal reproduction case\nSteps taken to resolve the issue\nExpected vs. actual behavior\n\n\nIf none of these solutions work, please create an issue with detailed information about your environment and the specific error you’re encountering."
  },
  {
    "objectID": "troubleshooting.html#quick-diagnostic-commands",
    "href": "troubleshooting.html#quick-diagnostic-commands",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Before diving into specific issues, run these diagnostic commands:\n# Check system status\nuv run python -m veritascribe test\n\n# View current configuration\nuv run python -m veritascribe config\n\n# View available providers\nuv run python -m veritascribe providers\n\n# Try demo analysis\nuv run python -m veritascribe demo"
  },
  {
    "objectID": "troubleshooting.html#installation-issues",
    "href": "troubleshooting.html#installation-issues",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Problem: uv: command not found\nSolutions:\n\nInstall uv:\n# macOS/Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows PowerShell\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Alternative: pip install\npip install uv\nRestart terminal after installation\nCheck PATH:\necho $PATH | grep -o \"[^:]*uv[^:]*\"\n\n\n\n\nProblem: Python 3.13+ required but found 3.x.x\nSolutions:\n\nCheck available Python versions:\npython --version\npython3 --version\npython3.13 --version\nInstall Python 3.13:\n# macOS with Homebrew\nbrew install python@3.13\n\n# Ubuntu/Debian\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update && sudo apt install python3.13\nUse specific Python version:\nuv python install 3.13\nuv venv --python 3.13\n\n\n\n\nProblem: uv sync fails with compilation errors\nSolutions:\n\nUpdate uv:\nuv self update\nClear cache:\nuv cache clean\nInstall system dependencies:\n# macOS\nxcode-select --install\n\n# Ubuntu/Debian\nsudo apt update\nsudo apt install build-essential python3-dev\n\n# CentOS/RHEL\nsudo yum groupinstall \"Development Tools\"\nsudo yum install python3-devel\nUse pre-compiled wheels:\nuv sync --only-binary=all\n\n\n\n\nProblem: Permission errors during installation\nSolutions:\n\nDon’t use sudo with uv:\n# Wrong\nsudo uv sync\n\n# Correct\nuv sync\nFix directory permissions:\n# macOS/Linux\nsudo chown -R $(whoami) ~/.local/share/uv\nUse virtual environment:\nuv venv venv\nsource venv/bin/activate  # Linux/macOS\n# or\nvenv\\Scripts\\activate     # Windows"
  },
  {
    "objectID": "troubleshooting.html#configuration-issues",
    "href": "troubleshooting.html#configuration-issues",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Problem: API key is required for analysis or provider-specific errors\nDiagnosis:\n# Check if .env file exists\nls -la .env\n\n# Check current provider configuration\nuv run python -m veritascribe config\n\n# Check environment variables for your provider\necho $OPENAI_API_KEY      # For OpenAI or custom\necho $OPENROUTER_API_KEY  # For OpenRouter\necho $ANTHROPIC_API_KEY   # For Anthropic\n\n# Test API key validity (adjust for your provider)\nuv run python -c \"\nfrom veritascribe.config import get_settings, get_dspy_config\ntry:\n    settings = get_settings()\n    dspy_config = get_dspy_config()\n    lm = dspy_config.initialize_llm()\n    print('✓ API key and provider configuration valid')\nexcept Exception as e:\n    print(f'✗ Configuration error: {e}')\n\"\nSolutions:\n\nCreate .env file:\ncp .env.example .env\n# Edit .env and configure your chosen provider\nProvider-specific setup:\nOpenAI:\nLLM_PROVIDER=openai\nOPENAI_API_KEY=sk-your-key-here  # Starts with 'sk-', 51+ chars\nOpenRouter:\nLLM_PROVIDER=openrouter\nOPENROUTER_API_KEY=sk-or-your-key-here  # Starts with 'sk-or-'\nAnthropic:\nLLM_PROVIDER=anthropic\nANTHROPIC_API_KEY=sk-ant-your-key-here  # Starts with 'sk-ant-'\nCustom/Local:\nLLM_PROVIDER=custom\nOPENAI_API_KEY=any-value-for-local\nOPENAI_BASE_URL=http://localhost:11434/v1\nSet environment variables directly:\n# For OpenRouter example\nexport LLM_PROVIDER=openrouter\nexport OPENROUTER_API_KEY=\"your-key-here\"\nuv run python -m veritascribe config\nCheck API key status and billing:\n\nOpenAI: Platform Dashboard\nOpenRouter: Dashboard\nAnthropic: Console\nVerify key permissions and billing/credit status\n\n\n\n\n\nProblem: Model 'model-name' not available or model formatting errors\nDiagnosis:\n# Check current provider and model configuration\nuv run python -m veritascribe config\n\n# View available providers and their models\nuv run python -m veritascribe providers\n\n# Test model formatting\nuv run python -c \"\nfrom veritascribe.config import get_settings\nsettings = get_settings()\nformatted = settings.format_model_name()\nprint(f'Provider: {settings.llm_provider}')\nprint(f'Original model: {settings.default_model}')\nprint(f'Formatted model: {formatted}')\n\"\nSolutions:\n\nUse provider-specific model names:\nOpenAI:\nDEFAULT_MODEL=gpt-4  # or gpt-3.5-turbo, gpt-4-turbo\nOpenRouter (automatically prefixed):\nDEFAULT_MODEL=anthropic/claude-3.5-sonnet\n# DEFAULT_MODEL=openai/gpt-4\n# DEFAULT_MODEL=z-ai/glm-4.5-air:free\nAnthropic:\nDEFAULT_MODEL=claude-3-5-sonnet-20241022\n# DEFAULT_MODEL=claude-3-haiku-20240307\nCustom:\nDEFAULT_MODEL=llama3.1:8b  # Ollama format\n# DEFAULT_MODEL=gpt-4      # Azure deployment name\nCheck provider-specific availability:\n\nOpenAI: Usage Dashboard\nOpenRouter: Model List\nAnthropic: Console\nLocal: Check your model availability\n\nTry fallback models:\n# Safe fallback for each provider\n# OpenAI\nDEFAULT_MODEL=gpt-3.5-turbo\n\n# OpenRouter  \nDEFAULT_MODEL=z-ai/glm-4.5-air:free\n\n# Anthropic\nDEFAULT_MODEL=claude-3-haiku-20240307\n\n\n\n\nProblem: Failed to load configuration\nDiagnosis:\n# Check .env file format\ncat .env | grep -E \"^[A-Z_]+=.*$\"\n\n# Validate configuration\nuv run python -c \"\nfrom veritascribe.config import load_settings\ntry:\n    settings = load_settings()\n    print('✓ Configuration valid')\nexcept Exception as e:\n    print(f'✗ Configuration error: {e}')\n\"\nSolutions:\n\nFix .env format:\n# Correct format\nOPENAI_API_KEY=sk-your-key-here\nDEFAULT_MODEL=gpt-4\n\n# Wrong format (quotes, spaces)\nOPENAI_API_KEY = \"sk-your-key-here\"\nCheck file encoding:\nfile .env\n# Should show UTF-8 encoding\nReset to defaults:\ncp .env.example .env\n# Edit with minimal required settings"
  },
  {
    "objectID": "troubleshooting.html#pdf-processing-issues",
    "href": "troubleshooting.html#pdf-processing-issues",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Problem: Error: PDF file not found\nSolutions:\n\nCheck file path:\n# Use absolute path\nuv run python -m veritascribe analyze /full/path/to/thesis.pdf\n\n# Or relative from current directory\nls -la *.pdf\nuv run python -m veritascribe analyze ./thesis.pdf\nVerify file permissions:\nls -la thesis.pdf\n# Should show read permissions\nCheck file extension:\nfile thesis.pdf\n# Should show \"PDF document\"\n\n\n\n\nProblem: No text blocks extracted or PDF processing failed\nDiagnosis:\n# Test PDF with simple extraction\nuv run python -c \"\nimport fitz\ntry:\n    doc = fitz.open('thesis.pdf')\n    text = doc[0].get_text()\n    print(f'✓ Extracted {len(text)} characters from first page')\n    doc.close()\nexcept Exception as e:\n    print(f'✗ PDF error: {e}')\n\"\nSolutions:\n\nCheck PDF type:\n# Text-based PDFs work best\npdfinfo thesis.pdf | grep -E \"(Pages|Producer|Creator)\"\nTry different PDF:\n# Test with demo PDF\nuv run python -m veritascribe demo\nHandle password-protected PDFs:\n# Remove password first\nqpdf --password=PASSWORD --decrypt input.pdf output.pdf\nConvert scanned PDFs:\n# Use OCR tools first\nocrmypdf input.pdf output.pdf\n\n\n\n\nProblem: Out of memory or slow processing\nSolutions:\n\nReduce block size:\nMAX_TEXT_BLOCK_SIZE=1000 uv run python -m veritascribe analyze large.pdf\nDisable parallel processing:\nPARALLEL_PROCESSING=false uv run python -m veritascribe analyze large.pdf\nUse quick analysis:\nuv run python -m veritascribe quick large.pdf --blocks 20\nSplit large documents:\n# Split PDF into smaller parts\npdftk input.pdf burst output page_%02d.pdf"
  },
  {
    "objectID": "troubleshooting.html#analysis-issues",
    "href": "troubleshooting.html#analysis-issues",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Problem: Analysis modules failed, timeout errors, or provider-specific issues\nDiagnosis:\n# Test LLM connectivity for your provider\nuv run python -c \"\nfrom veritascribe.config import get_settings, get_dspy_config\n\ntry:\n    settings = get_settings()\n    dspy_config = get_dspy_config()\n    print(f'Provider: {settings.llm_provider}')\n    print(f'Model: {settings.format_model_name()}')\n    \n    lm = dspy_config.initialize_llm()\n    response = lm('Test prompt: Say \"Hello VeritaScribe\"')\n    print('✓ LLM connection working')\n    print(f'Response: {response}')\nexcept Exception as e:\n    print(f'✗ LLM error: {e}')\n    import traceback\n    traceback.print_exc()\n\"\nSolutions:\n\nReduce concurrency:\nMAX_CONCURRENT_REQUESTS=2 uv run python -m veritascribe analyze thesis.pdf\nIncrease timeout/retries:\nMAX_RETRIES=5 RETRY_DELAY=2.0 uv run python -m veritascribe analyze thesis.pdf\nCheck rate limits:\n\nVisit OpenAI Usage\nVerify you haven’t hit rate limits\nConsider upgrading API tier\n\nTry different models by provider:\n# OpenAI - use simpler model\nDEFAULT_MODEL=gpt-3.5-turbo uv run python -m veritascribe analyze thesis.pdf\n\n# OpenRouter - try free model\nLLM_PROVIDER=openrouter DEFAULT_MODEL=z-ai/glm-4.5-air:free uv run python -m veritascribe analyze thesis.pdf\n\n# Anthropic - use fastest model\nLLM_PROVIDER=anthropic DEFAULT_MODEL=claude-3-haiku-20240307 uv run python -m veritascribe analyze thesis.pdf\nCheck provider-specific rate limits:\n\nOpenAI: Rate limits page\nOpenRouter: Usage dashboard\nAnthropic: Rate limits\n\n\n\n\n\nProblem: JSON parsing error or invalid responses\nSolutions:\n\nEnable verbose logging:\nuv run python -m veritascribe analyze thesis.pdf --verbose\nReduce temperature:\nTEMPERATURE=0.0 uv run python -m veritascribe analyze thesis.pdf\nCheck token limits:\nMAX_TOKENS=1500 uv run python -m veritascribe analyze thesis.pdf\n\n\n\n\nProblem: Unexpected high token usage\nSolutions:\n\nMonitor usage:\n# Check configuration\nuv run python -m veritascribe config\nOptimize settings by provider:\n# OpenAI cost optimization\nLLM_PROVIDER=openai\nDEFAULT_MODEL=gpt-3.5-turbo\nMAX_TOKENS=1500\n\n# OpenRouter free model\nLLM_PROVIDER=openrouter\nDEFAULT_MODEL=z-ai/glm-4.5-air:free\n\n# Anthropic cost optimization\nLLM_PROVIDER=anthropic\nDEFAULT_MODEL=claude-3-haiku-20240307\n\n# Local model (no API costs)\nLLM_PROVIDER=custom\nOPENAI_BASE_URL=http://localhost:11434/v1\nDEFAULT_MODEL=llama3.1:8b\n\n# General optimizations\nMAX_TEXT_BLOCK_SIZE=1000\nPARALLEL_PROCESSING=false\nUse quick analysis:\nuv run python -m veritascribe quick thesis.pdf --blocks 10\nDisable analysis types:\nCONTENT_ANALYSIS_ENABLED=false uv run python -m veritascribe analyze thesis.pdf"
  },
  {
    "objectID": "troubleshooting.html#output-issues",
    "href": "troubleshooting.html#output-issues",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Problem: Report generation failed or missing output files\nSolutions:\n\nCheck output directory permissions:\nmkdir -p ./analysis_output\nchmod 755 ./analysis_output\nSpecify output directory:\nuv run python -m veritascribe analyze thesis.pdf --output ~/Documents/analysis\nDisable problematic outputs:\n# Skip visualizations if matplotlib issues\nuv run python -m veritascribe analyze thesis.pdf --no-viz\n\n\n\n\nProblem: Chart generation fails\nSolutions:\n\nInstall GUI backend:\n# macOS\nbrew install python-tk\n\n# Ubuntu/Debian\nsudo apt install python3-tk\nUse headless backend:\nuv run python -c \"\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nprint('✓ Matplotlib working')\n\"\nSkip visualizations:\nGENERATE_VISUALIZATIONS=false uv run python -m veritascribe analyze thesis.pdf"
  },
  {
    "objectID": "troubleshooting.html#performance-issues",
    "href": "troubleshooting.html#performance-issues",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Problem: Analysis takes too long\nDiagnosis:\n# Profile analysis\ntime uv run python -m veritascribe quick thesis.pdf --blocks 5\nSolutions:\n\nEnable parallel processing:\nPARALLEL_PROCESSING=true MAX_CONCURRENT_REQUESTS=5\nUse faster model:\nDEFAULT_MODEL=gpt-3.5-turbo\nReduce analysis scope:\n# Disable expensive analysis\nCONTENT_ANALYSIS_ENABLED=false\nOptimize block size:\nMAX_TEXT_BLOCK_SIZE=1500\n\n\n\n\nProblem: High memory consumption\nSolutions:\n\nMonitor memory:\n# Use memory profiler\npip install memory-profiler\nmprof run uv run python -m veritascribe analyze thesis.pdf\nmprof plot\nReduce batch size:\nMAX_CONCURRENT_REQUESTS=2\nClear cache:\n# Clear Python cache\nfind . -name \"*.pyc\" -delete\nfind . -name \"__pycache__\" -delete"
  },
  {
    "objectID": "troubleshooting.html#network-issues",
    "href": "troubleshooting.html#network-issues",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "Problem: Connection timeout or network errors\nSolutions:\n\nCheck internet connectivity:\ncurl -I https://api.openai.com/v1/models\nConfigure proxy (if needed):\nexport HTTPS_PROXY=http://proxy.company.com:8080\nexport HTTP_PROXY=http://proxy.company.com:8080\nIncrease timeout:\n# Configure longer timeouts in requests\nREQUESTS_TIMEOUT=60\n\n\n\n\nProblem: Requests blocked by firewall\nSolutions:\n\nWhitelist OpenAI domains:\n\napi.openai.com\nopenai.com\n\nCheck corporate policies:\n\nContact IT about OpenAI API access\nConsider VPN if needed\n\nTest with curl:\ncurl -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n     https://api.openai.com/v1/models"
  },
  {
    "objectID": "troubleshooting.html#getting-help",
    "href": "troubleshooting.html#getting-help",
    "title": "Troubleshooting Guide",
    "section": "",
    "text": "For any issue, enable verbose logging:\n# Enable debug output\nuv run python -m veritascribe analyze thesis.pdf --verbose\n\n# Python logging\nPYTHONPATH=. python -c \"\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\nfrom veritascribe.main import main\nmain()\n\"\n\n\n\n# System info script\ncat &gt; debug_info.sh &lt;&lt; 'EOF'\n#!/bin/bash\necho \"=== System Information ===\"\nuname -a\npython --version\nuv --version\n\necho -e \"\\n=== VeritaScribe Configuration ===\"\nuv run python -m veritascribe config\n\necho -e \"\\n=== Environment Variables ===\"\nenv | grep -E \"(OPENAI|PYTHON|UV)\" | sort\n\necho -e \"\\n=== System Tests ===\"\nuv run python -m veritascribe test\n\necho -e \"\\n=== Dependencies ===\"\nuv tree\nEOF\n\nchmod +x debug_info.sh\n./debug_info.sh &gt; debug_info.txt\n\n\n\n# Create minimal test case\ncat &gt; minimal_test.py &lt;&lt; 'EOF'\n#!/usr/bin/env python3\n\"\"\"Minimal reproduction script.\"\"\"\n\nfrom veritascribe.config import load_settings\nfrom veritascribe.pdf_processor import PDFProcessor\nfrom veritascribe.pipeline import create_quick_pipeline\n\ndef main():\n    try:\n        # Test configuration\n        print(\"Testing configuration...\")\n        settings = load_settings()\n        print(f\"✓ Config loaded, model: {settings.default_model}\")\n        \n        # Test PDF processing\n        print(\"Testing PDF processing...\")\n        processor = PDFProcessor()\n        # Add your test PDF here\n        \n        # Test analysis\n        print(\"Testing analysis...\")\n        pipeline = create_quick_pipeline()\n        # Add your test case here\n        \n        print(\"✓ All tests passed\")\n        \n    except Exception as e:\n        print(f\"✗ Error: {e}\")\n        import traceback\n        traceback.print_exc()\n\nif __name__ == \"__main__\":\n    main()\nEOF\n\nuv run python minimal_test.py\n\n\n\n\n\n\n\n\n\n\n\nError Message\nLikely Cause\nQuick Fix\n\n\n\n\nuv: command not found\nuv not installed\nInstall uv\n\n\nAPI key is required\nMissing API key\nSet provider-specific API key\n\n\nLLM Provider NOT provided\nMissing provider prefix\nCheck model formatting\n\n\nPDF file not found\nWrong file path\nCheck file path\n\n\nNo text blocks extracted\nScanned PDF\nUse OCR first\n\n\nConnection timeout\nNetwork issue\nCheck connectivity\n\n\nRate limit exceeded\nToo many requests\nReduce concurrency\n\n\nModel not available\nWrong model name\nCheck provider models\n\n\nJSON parsing error\nMalformed LLM response\nReduce temperature\n\n\nPermission denied\nFile permissions\nCheck file access\n\n\nOut of memory\nLarge document\nReduce block size\n\n\n\n\n\n\nCreate an issue on the project repository with:\n\nError message and full traceback\nSystem information from debug script\nMinimal reproduction case\nSteps taken to resolve the issue\nExpected vs. actual behavior\n\n\nIf none of these solutions work, please create an issue with detailed information about your environment and the specific error you’re encountering."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "VeritaScribe Documentation",
    "section": "",
    "text": "VeritaScribe is an intelligent document analysis system that automatically reviews PDF thesis documents for quality issues including grammar errors, content plausibility problems, and citation format inconsistencies.\n\n\nVeritaScribe combines advanced AI language models with structured document processing to provide comprehensive academic document review. Built with modern Python tools including DSPy for LLM orchestration, Pydantic for structured data modeling, and PyMuPDF for PDF processing.\n\n\n\n\n\n\n\nGrammar and linguistic error detection\nContent plausibility validation\n\nCitation format verification\nError severity classification\n\n\n\n\n\nDetailed error reports with locations\nVisual analytics and charts\nJSON data export\nMarkdown reports\n\n\n\n\n\nMultiple LLM model support\nCustomizable analysis parameters\nCitation style configuration\nProcessing optimization settings\n\n\n\n\n\nCommand-line interface\nQuick analysis mode\nDemo mode for testing\nComprehensive error messages\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n    A[PDF Input] --&gt; B[Text Extraction]\n    B --&gt; C[LLM Analysis]\n    C --&gt; D[Error Detection]\n    D --&gt; E[Report Generation]\n    E --&gt; F[Visualizations]\n\n\n\n\n\n\n\nPDF Processing: Extracts text while preserving layout and location information\nAI Analysis: Uses large language models to analyze content for various types of errors\nError Classification: Categorizes and scores errors by type and severity\nReport Generation: Creates comprehensive reports and visualizations\n\n\n\n\nGet started with VeritaScribe in just a few steps:\n\nInstall dependencies:\nuv sync\nConfigure API key:\ncp .env.example .env\n# Edit .env to add your OpenAI API key\nTry the demo:\nuv run python -m veritascribe demo\nAnalyze your document:\nuv run python -m veritascribe analyze your_thesis.pdf\n\n\n\n\n\n\n\nSpelling mistakes and typos\nGrammatical inconsistencies\nPunctuation errors\nStyle and readability issues\n\n\n\n\n\nLogical inconsistencies\nFactual accuracy concerns\nArgument structure problems\nCitation-content mismatches\n\n\n\n\n\nIncorrect citation style formatting\nMissing or incomplete references\nInconsistent bibliography formatting\nCitation accuracy issues\n\n\n\n\n\nVeritaScribe follows a modular pipeline architecture:\n\nConfiguration Layer: Environment-based settings management\nPDF Processing: Text extraction with layout preservation\nLLM Analysis: DSPy-based structured analysis modules\nData Models: Pydantic schemas for type safety\nReport Generation: Multi-format output with visualizations\n\n\n\n\n\nInstallation Guide: Detailed setup instructions\nConfiguration Reference: Complete configuration options\nUsage Guide: Comprehensive usage examples\nAPI Reference: Technical documentation\nArchitecture Guide: System design and development\n\n\n\n\nIf you encounter issues or have questions:\n\nCheck the Troubleshooting Guide\nRun system diagnostics: uv run python -m veritascribe test\nReview configuration: uv run python -m veritascribe config\n\n\nVeritaScribe is designed for defensive security and academic quality assurance purposes only.",
    "crumbs": [
      "Home",
      "VeritaScribe Documentation"
    ]
  },
  {
    "objectID": "index.html#what-is-veritascribe",
    "href": "index.html#what-is-veritascribe",
    "title": "VeritaScribe Documentation",
    "section": "",
    "text": "VeritaScribe combines advanced AI language models with structured document processing to provide comprehensive academic document review. Built with modern Python tools including DSPy for LLM orchestration, Pydantic for structured data modeling, and PyMuPDF for PDF processing.",
    "crumbs": [
      "Home",
      "VeritaScribe Documentation"
    ]
  },
  {
    "objectID": "index.html#key-features",
    "href": "index.html#key-features",
    "title": "VeritaScribe Documentation",
    "section": "",
    "text": "Grammar and linguistic error detection\nContent plausibility validation\n\nCitation format verification\nError severity classification\n\n\n\n\n\nDetailed error reports with locations\nVisual analytics and charts\nJSON data export\nMarkdown reports\n\n\n\n\n\nMultiple LLM model support\nCustomizable analysis parameters\nCitation style configuration\nProcessing optimization settings\n\n\n\n\n\nCommand-line interface\nQuick analysis mode\nDemo mode for testing\nComprehensive error messages",
    "crumbs": [
      "Home",
      "VeritaScribe Documentation"
    ]
  },
  {
    "objectID": "index.html#how-it-works",
    "href": "index.html#how-it-works",
    "title": "VeritaScribe Documentation",
    "section": "",
    "text": "flowchart LR\n    A[PDF Input] --&gt; B[Text Extraction]\n    B --&gt; C[LLM Analysis]\n    C --&gt; D[Error Detection]\n    D --&gt; E[Report Generation]\n    E --&gt; F[Visualizations]\n\n\n\n\n\n\n\nPDF Processing: Extracts text while preserving layout and location information\nAI Analysis: Uses large language models to analyze content for various types of errors\nError Classification: Categorizes and scores errors by type and severity\nReport Generation: Creates comprehensive reports and visualizations",
    "crumbs": [
      "Home",
      "VeritaScribe Documentation"
    ]
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "VeritaScribe Documentation",
    "section": "",
    "text": "Get started with VeritaScribe in just a few steps:\n\nInstall dependencies:\nuv sync\nConfigure API key:\ncp .env.example .env\n# Edit .env to add your OpenAI API key\nTry the demo:\nuv run python -m veritascribe demo\nAnalyze your document:\nuv run python -m veritascribe analyze your_thesis.pdf",
    "crumbs": [
      "Home",
      "VeritaScribe Documentation"
    ]
  },
  {
    "objectID": "index.html#error-types-detected",
    "href": "index.html#error-types-detected",
    "title": "VeritaScribe Documentation",
    "section": "",
    "text": "Spelling mistakes and typos\nGrammatical inconsistencies\nPunctuation errors\nStyle and readability issues\n\n\n\n\n\nLogical inconsistencies\nFactual accuracy concerns\nArgument structure problems\nCitation-content mismatches\n\n\n\n\n\nIncorrect citation style formatting\nMissing or incomplete references\nInconsistent bibliography formatting\nCitation accuracy issues",
    "crumbs": [
      "Home",
      "VeritaScribe Documentation"
    ]
  },
  {
    "objectID": "index.html#architecture-overview",
    "href": "index.html#architecture-overview",
    "title": "VeritaScribe Documentation",
    "section": "",
    "text": "VeritaScribe follows a modular pipeline architecture:\n\nConfiguration Layer: Environment-based settings management\nPDF Processing: Text extraction with layout preservation\nLLM Analysis: DSPy-based structured analysis modules\nData Models: Pydantic schemas for type safety\nReport Generation: Multi-format output with visualizations",
    "crumbs": [
      "Home",
      "VeritaScribe Documentation"
    ]
  },
  {
    "objectID": "index.html#next-steps",
    "href": "index.html#next-steps",
    "title": "VeritaScribe Documentation",
    "section": "",
    "text": "Installation Guide: Detailed setup instructions\nConfiguration Reference: Complete configuration options\nUsage Guide: Comprehensive usage examples\nAPI Reference: Technical documentation\nArchitecture Guide: System design and development",
    "crumbs": [
      "Home",
      "VeritaScribe Documentation"
    ]
  },
  {
    "objectID": "index.html#support",
    "href": "index.html#support",
    "title": "VeritaScribe Documentation",
    "section": "",
    "text": "If you encounter issues or have questions:\n\nCheck the Troubleshooting Guide\nRun system diagnostics: uv run python -m veritascribe test\nReview configuration: uv run python -m veritascribe config\n\n\nVeritaScribe is designed for defensive security and academic quality assurance purposes only.",
    "crumbs": [
      "Home",
      "VeritaScribe Documentation"
    ]
  },
  {
    "objectID": "configuration.html",
    "href": "configuration.html",
    "title": "Configuration Reference",
    "section": "",
    "text": "VeritaScribe uses environment variables for configuration, providing flexibility and security for different deployment scenarios.\n\n\nConfiguration is managed through:\n\nEnvironment variables (highest priority)\n.env file (for local development)\nDefault values (built into the application)\n\n\n\n\nVeritaScribe supports multiple LLM providers for flexibility, cost optimization, and access to different models.\n\n\n# Choose your LLM provider (default: openai)\nLLM_PROVIDER=openai  # or: openrouter, anthropic, custom\nAvailable Providers: - openai: Direct OpenAI API access - openrouter: Access to 100+ models through OpenRouter - anthropic: Direct Anthropic Claude API access\n- custom: OpenAI-compatible endpoints (Ollama, Azure, etc.)\n\n\n\nFor LLM_PROVIDER=openai:\nOPENAI_API_KEY=your_openai_api_key_here\nGetting an OpenAI API Key: 1. Visit OpenAI Platform 2. Sign in or create an account 3. Click “Create new secret key” 4. Copy the key and add it to your .env file\n\n\n\nFor LLM_PROVIDER=openrouter (access to 100+ models):\nOPENROUTER_API_KEY=sk-or-your_openrouter_api_key_here\nGetting an OpenRouter API Key: 1. Visit OpenRouter 2. Sign up and verify your account 3. Create a new API key 4. Add credits or set up billing\n\n\n\nFor LLM_PROVIDER=anthropic (direct Claude access):\nANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key_here\nGetting an Anthropic API Key: 1. Visit Anthropic Console 2. Sign up and verify your account 3. Navigate to API Keys section 4. Create a new key and add credits\n\n\n\nFor LLM_PROVIDER=custom (Ollama, Azure OpenAI, etc.):\nOPENAI_API_KEY=your_custom_api_key\nOPENAI_BASE_URL=https://your-endpoint.com/v1\nCommon Custom Endpoints: - Ollama: http://localhost:11434/v1 - Azure OpenAI: https://your-resource.openai.azure.com/ - Other providers: Check provider documentation\n\n\n\n\n\n\nAPI Key Security\n\n\n\n\nNever commit API keys to version control\nUse environment variables in production\nThe .env file is already in .gitignore\nRotate keys regularly for security\nDifferent providers have different key formats\n\n\n\n\n\n\n\n\n\nEach provider uses different model naming conventions:\nOpenAI Provider Models:\nLLM_PROVIDER=openai\nDEFAULT_MODEL=gpt-4  # or: gpt-4-turbo, gpt-4o, gpt-3.5-turbo\nOpenRouter Provider Models:\nLLM_PROVIDER=openrouter\n# Note: OpenRouter models are automatically prefixed with 'openrouter/'\nDEFAULT_MODEL=anthropic/claude-3.5-sonnet    # Claude models\n# DEFAULT_MODEL=openai/gpt-4                 # OpenAI via OpenRouter\n# DEFAULT_MODEL=meta-llama/llama-3.1-70b-instruct  # Open source\n# DEFAULT_MODEL=z-ai/glm-4.5-air:free       # Free models\nAnthropic Provider Models:\nLLM_PROVIDER=anthropic\nDEFAULT_MODEL=claude-3-5-sonnet-20241022  # Latest Sonnet\n# DEFAULT_MODEL=claude-3-5-haiku-20241022  # Fast and cost-effective\n# DEFAULT_MODEL=claude-3-opus-20240229     # Highest quality\nCustom Provider Models:\nLLM_PROVIDER=custom\nDEFAULT_MODEL=llama3.1:8b  # Ollama format\n# DEFAULT_MODEL=gpt-4       # Azure OpenAI deployment name\n\n\n\nOpenAI: - Quality: gpt-4 - Best analysis quality - Speed: gpt-4o-mini - Fast and cost-effective - Cost: gpt-3.5-turbo - Most economical\nOpenRouter: - Quality: anthropic/claude-3-opus - Highest quality - Speed: anthropic/claude-3-haiku - Fast Claude model - Cost: z-ai/glm-4.5-air:free - Free model\nAnthropic: - Quality: claude-3-opus-20240229 - Best Claude model - Speed: claude-3-5-haiku-20241022 - Fast and efficient - Cost: claude-3-haiku-20240307 - Most economical\n\n\n\n\n\n\nProvider Comparison\n\n\n\n\nOpenAI: Most mature, reliable API, extensive model selection\nOpenRouter: Access to 100+ models, competitive pricing, free options\nAnthropic: Excellent reasoning, safety-focused, direct API access\nCustom: Use local models (Ollama), private deployments, cost control\n\n\n\n\n\n\n# Maximum tokens per LLM request (default: 2000)\nMAX_TOKENS=2000\n\n# LLM temperature for consistency (default: 0.1)\n# Range: 0.0 (deterministic) to 1.0 (creative)\nTEMPERATURE=0.1\n\n\n\n\n\n\nOptimizing Token Usage\n\n\n\n\nLower MAX_TOKENS reduces costs but may truncate analysis\nHigher values allow more detailed analysis\nMonitor usage with uv run python -m veritascribe config\n\n\n\n\n\n\n\n\n\n# Grammar and linguistic analysis (default: true)\nGRAMMAR_ANALYSIS_ENABLED=true\n\n# Content plausibility checking (default: true)\nCONTENT_ANALYSIS_ENABLED=true\n\n# Citation format validation (default: true)\nCITATION_ANALYSIS_ENABLED=true\nUse Cases: - Disable expensive analysis types for cost optimization - Focus on specific error types during review phases - Customize analysis for different document types\n\n\n\n# Threshold for high severity classification (default: 0.8)\nHIGH_SEVERITY_THRESHOLD=0.8\n\n# Threshold for medium severity classification (default: 0.5)\nMEDIUM_SEVERITY_THRESHOLD=0.5\nErrors are classified as: - High: Score ≥ HIGH_SEVERITY_THRESHOLD - Medium: Score ≥ MEDIUM_SEVERITY_THRESHOLD\n- Low: Score &lt; MEDIUM_SEVERITY_THRESHOLD\n\n\n\n\n\n\n# Maximum characters per analysis block (default: 2000)\nMAX_TEXT_BLOCK_SIZE=2000\n\n# Minimum characters for analysis (default: 50)\nMIN_TEXT_BLOCK_SIZE=50\nOptimization Guidelines:\n\n\n\nDocument Size\nRecommended MAX_TEXT_BLOCK_SIZE\n\n\n\n\nSmall (&lt; 50 pages)\n2000-3000\n\n\nMedium (50-100 pages)\n1500-2000\n\n\nLarge (&gt; 100 pages)\n1000-1500\n\n\n\n\n\n\n# Enable parallel LLM requests (default: true)\nPARALLEL_PROCESSING=true\n\n# Maximum concurrent requests (default: 5)\nMAX_CONCURRENT_REQUESTS=5\n\n\n\n\n\n\nRate Limiting\n\n\n\nSetting MAX_CONCURRENT_REQUESTS too high may trigger API rate limits. Start with 3-5 and increase gradually based on your API tier.\n\n\n\n\n\n# Maximum retry attempts for failed requests (default: 3)\nMAX_RETRIES=3\n\n# Delay between retries in seconds (default: 1.0)\nRETRY_DELAY=1.0\n\n\n\n\n\n\n# Default output directory (default: ./analysis_output)\nOUTPUT_DIRECTORY=./analysis_output\n\n# Generate error visualization charts (default: true)\nGENERATE_VISUALIZATIONS=true\n\n# Save detailed text reports (default: true)\nSAVE_DETAILED_REPORTS=true\n\n\n\n\n\n\nCreate a .env.dev file for development settings:\n# Development-specific settings\nDEFAULT_MODEL=gpt-3.5-turbo\nMAX_TOKENS=1500\nPARALLEL_PROCESSING=false\nMAX_CONCURRENT_REQUESTS=2\nGENERATE_VISUALIZATIONS=true\n\n\n\nSet environment variables directly:\nexport OPENAI_API_KEY=\"your-production-key\"\nexport DEFAULT_MODEL=\"gpt-4\"\nexport MAX_TOKENS=2000\nexport PARALLEL_PROCESSING=true\nexport MAX_CONCURRENT_REQUESTS=10\nexport OUTPUT_DIRECTORY=\"/app/analysis_output\"\n\n\n\nExample docker-compose.yml:\nversion: '3.8'\nservices:\n  veritascribe:\n    build: .\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n      - DEFAULT_MODEL=gpt-4-turbo\n      - MAX_TOKENS=2000\n      - PARALLEL_PROCESSING=true\n      - MAX_CONCURRENT_REQUESTS=5\n    volumes:\n      - ./analysis_output:/app/analysis_output\n\n\n\n\n\n\nCheck your current settings:\nuv run python -m veritascribe config\n\n\n\nSee all supported providers and their models:\nuv run python -m veritascribe providers\n\n\n\nValidate your configuration with system tests:\nuv run python -m veritascribe test\n\n\n\n\n\n\nExample 1: Standard OpenAI\nLLM_PROVIDER=openai\nOPENAI_API_KEY=sk-your-key-here\nDEFAULT_MODEL=gpt-4\nExample 2: OpenRouter with Claude\nLLM_PROVIDER=openrouter\nOPENROUTER_API_KEY=sk-or-your-key-here\nDEFAULT_MODEL=anthropic/claude-3.5-sonnet\nExample 3: Direct Anthropic Claude\nLLM_PROVIDER=anthropic\nANTHROPIC_API_KEY=sk-ant-your-key-here\nDEFAULT_MODEL=claude-3-5-sonnet-20241022\nExample 4: Local Ollama\nLLM_PROVIDER=custom\nOPENAI_API_KEY=ollama  # Can be any value for local models\nOPENAI_BASE_URL=http://localhost:11434/v1\nDEFAULT_MODEL=llama3.1:8b\nExample 5: Azure OpenAI\nLLM_PROVIDER=custom\nOPENAI_API_KEY=your-azure-key\nOPENAI_BASE_URL=https://your-resource.openai.azure.com/\nDEFAULT_MODEL=gpt-4  # Your Azure deployment name\n\nFor more advanced configuration scenarios, see the Architecture Guide.",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "configuration.html#configuration-overview",
    "href": "configuration.html#configuration-overview",
    "title": "Configuration Reference",
    "section": "",
    "text": "Configuration is managed through:\n\nEnvironment variables (highest priority)\n.env file (for local development)\nDefault values (built into the application)",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "configuration.html#llm-provider-configuration",
    "href": "configuration.html#llm-provider-configuration",
    "title": "Configuration Reference",
    "section": "",
    "text": "VeritaScribe supports multiple LLM providers for flexibility, cost optimization, and access to different models.\n\n\n# Choose your LLM provider (default: openai)\nLLM_PROVIDER=openai  # or: openrouter, anthropic, custom\nAvailable Providers: - openai: Direct OpenAI API access - openrouter: Access to 100+ models through OpenRouter - anthropic: Direct Anthropic Claude API access\n- custom: OpenAI-compatible endpoints (Ollama, Azure, etc.)\n\n\n\nFor LLM_PROVIDER=openai:\nOPENAI_API_KEY=your_openai_api_key_here\nGetting an OpenAI API Key: 1. Visit OpenAI Platform 2. Sign in or create an account 3. Click “Create new secret key” 4. Copy the key and add it to your .env file\n\n\n\nFor LLM_PROVIDER=openrouter (access to 100+ models):\nOPENROUTER_API_KEY=sk-or-your_openrouter_api_key_here\nGetting an OpenRouter API Key: 1. Visit OpenRouter 2. Sign up and verify your account 3. Create a new API key 4. Add credits or set up billing\n\n\n\nFor LLM_PROVIDER=anthropic (direct Claude access):\nANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key_here\nGetting an Anthropic API Key: 1. Visit Anthropic Console 2. Sign up and verify your account 3. Navigate to API Keys section 4. Create a new key and add credits\n\n\n\nFor LLM_PROVIDER=custom (Ollama, Azure OpenAI, etc.):\nOPENAI_API_KEY=your_custom_api_key\nOPENAI_BASE_URL=https://your-endpoint.com/v1\nCommon Custom Endpoints: - Ollama: http://localhost:11434/v1 - Azure OpenAI: https://your-resource.openai.azure.com/ - Other providers: Check provider documentation\n\n\n\n\n\n\nAPI Key Security\n\n\n\n\nNever commit API keys to version control\nUse environment variables in production\nThe .env file is already in .gitignore\nRotate keys regularly for security\nDifferent providers have different key formats",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "configuration.html#model-configuration",
    "href": "configuration.html#model-configuration",
    "title": "Configuration Reference",
    "section": "",
    "text": "Each provider uses different model naming conventions:\nOpenAI Provider Models:\nLLM_PROVIDER=openai\nDEFAULT_MODEL=gpt-4  # or: gpt-4-turbo, gpt-4o, gpt-3.5-turbo\nOpenRouter Provider Models:\nLLM_PROVIDER=openrouter\n# Note: OpenRouter models are automatically prefixed with 'openrouter/'\nDEFAULT_MODEL=anthropic/claude-3.5-sonnet    # Claude models\n# DEFAULT_MODEL=openai/gpt-4                 # OpenAI via OpenRouter\n# DEFAULT_MODEL=meta-llama/llama-3.1-70b-instruct  # Open source\n# DEFAULT_MODEL=z-ai/glm-4.5-air:free       # Free models\nAnthropic Provider Models:\nLLM_PROVIDER=anthropic\nDEFAULT_MODEL=claude-3-5-sonnet-20241022  # Latest Sonnet\n# DEFAULT_MODEL=claude-3-5-haiku-20241022  # Fast and cost-effective\n# DEFAULT_MODEL=claude-3-opus-20240229     # Highest quality\nCustom Provider Models:\nLLM_PROVIDER=custom\nDEFAULT_MODEL=llama3.1:8b  # Ollama format\n# DEFAULT_MODEL=gpt-4       # Azure OpenAI deployment name\n\n\n\nOpenAI: - Quality: gpt-4 - Best analysis quality - Speed: gpt-4o-mini - Fast and cost-effective - Cost: gpt-3.5-turbo - Most economical\nOpenRouter: - Quality: anthropic/claude-3-opus - Highest quality - Speed: anthropic/claude-3-haiku - Fast Claude model - Cost: z-ai/glm-4.5-air:free - Free model\nAnthropic: - Quality: claude-3-opus-20240229 - Best Claude model - Speed: claude-3-5-haiku-20241022 - Fast and efficient - Cost: claude-3-haiku-20240307 - Most economical\n\n\n\n\n\n\nProvider Comparison\n\n\n\n\nOpenAI: Most mature, reliable API, extensive model selection\nOpenRouter: Access to 100+ models, competitive pricing, free options\nAnthropic: Excellent reasoning, safety-focused, direct API access\nCustom: Use local models (Ollama), private deployments, cost control\n\n\n\n\n\n\n# Maximum tokens per LLM request (default: 2000)\nMAX_TOKENS=2000\n\n# LLM temperature for consistency (default: 0.1)\n# Range: 0.0 (deterministic) to 1.0 (creative)\nTEMPERATURE=0.1\n\n\n\n\n\n\nOptimizing Token Usage\n\n\n\n\nLower MAX_TOKENS reduces costs but may truncate analysis\nHigher values allow more detailed analysis\nMonitor usage with uv run python -m veritascribe config",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "configuration.html#analysis-feature-configuration",
    "href": "configuration.html#analysis-feature-configuration",
    "title": "Configuration Reference",
    "section": "",
    "text": "# Grammar and linguistic analysis (default: true)\nGRAMMAR_ANALYSIS_ENABLED=true\n\n# Content plausibility checking (default: true)\nCONTENT_ANALYSIS_ENABLED=true\n\n# Citation format validation (default: true)\nCITATION_ANALYSIS_ENABLED=true\nUse Cases: - Disable expensive analysis types for cost optimization - Focus on specific error types during review phases - Customize analysis for different document types\n\n\n\n# Threshold for high severity classification (default: 0.8)\nHIGH_SEVERITY_THRESHOLD=0.8\n\n# Threshold for medium severity classification (default: 0.5)\nMEDIUM_SEVERITY_THRESHOLD=0.5\nErrors are classified as: - High: Score ≥ HIGH_SEVERITY_THRESHOLD - Medium: Score ≥ MEDIUM_SEVERITY_THRESHOLD\n- Low: Score &lt; MEDIUM_SEVERITY_THRESHOLD",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "configuration.html#processing-configuration",
    "href": "configuration.html#processing-configuration",
    "title": "Configuration Reference",
    "section": "",
    "text": "# Maximum characters per analysis block (default: 2000)\nMAX_TEXT_BLOCK_SIZE=2000\n\n# Minimum characters for analysis (default: 50)\nMIN_TEXT_BLOCK_SIZE=50\nOptimization Guidelines:\n\n\n\nDocument Size\nRecommended MAX_TEXT_BLOCK_SIZE\n\n\n\n\nSmall (&lt; 50 pages)\n2000-3000\n\n\nMedium (50-100 pages)\n1500-2000\n\n\nLarge (&gt; 100 pages)\n1000-1500\n\n\n\n\n\n\n# Enable parallel LLM requests (default: true)\nPARALLEL_PROCESSING=true\n\n# Maximum concurrent requests (default: 5)\nMAX_CONCURRENT_REQUESTS=5\n\n\n\n\n\n\nRate Limiting\n\n\n\nSetting MAX_CONCURRENT_REQUESTS too high may trigger API rate limits. Start with 3-5 and increase gradually based on your API tier.\n\n\n\n\n\n# Maximum retry attempts for failed requests (default: 3)\nMAX_RETRIES=3\n\n# Delay between retries in seconds (default: 1.0)\nRETRY_DELAY=1.0",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "configuration.html#output-configuration",
    "href": "configuration.html#output-configuration",
    "title": "Configuration Reference",
    "section": "",
    "text": "# Default output directory (default: ./analysis_output)\nOUTPUT_DIRECTORY=./analysis_output\n\n# Generate error visualization charts (default: true)\nGENERATE_VISUALIZATIONS=true\n\n# Save detailed text reports (default: true)\nSAVE_DETAILED_REPORTS=true",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "configuration.html#environment-specific-configuration",
    "href": "configuration.html#environment-specific-configuration",
    "title": "Configuration Reference",
    "section": "",
    "text": "Create a .env.dev file for development settings:\n# Development-specific settings\nDEFAULT_MODEL=gpt-3.5-turbo\nMAX_TOKENS=1500\nPARALLEL_PROCESSING=false\nMAX_CONCURRENT_REQUESTS=2\nGENERATE_VISUALIZATIONS=true\n\n\n\nSet environment variables directly:\nexport OPENAI_API_KEY=\"your-production-key\"\nexport DEFAULT_MODEL=\"gpt-4\"\nexport MAX_TOKENS=2000\nexport PARALLEL_PROCESSING=true\nexport MAX_CONCURRENT_REQUESTS=10\nexport OUTPUT_DIRECTORY=\"/app/analysis_output\"\n\n\n\nExample docker-compose.yml:\nversion: '3.8'\nservices:\n  veritascribe:\n    build: .\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n      - DEFAULT_MODEL=gpt-4-turbo\n      - MAX_TOKENS=2000\n      - PARALLEL_PROCESSING=true\n      - MAX_CONCURRENT_REQUESTS=5\n    volumes:\n      - ./analysis_output:/app/analysis_output",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "configuration.html#configuration-validation",
    "href": "configuration.html#configuration-validation",
    "title": "Configuration Reference",
    "section": "",
    "text": "Check your current settings:\nuv run python -m veritascribe config\n\n\n\nSee all supported providers and their models:\nuv run python -m veritascribe providers\n\n\n\nValidate your configuration with system tests:\nuv run python -m veritascribe test",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "configuration.html#advanced-configuration",
    "href": "configuration.html#advanced-configuration",
    "title": "Configuration Reference",
    "section": "",
    "text": "Example 1: Standard OpenAI\nLLM_PROVIDER=openai\nOPENAI_API_KEY=sk-your-key-here\nDEFAULT_MODEL=gpt-4\nExample 2: OpenRouter with Claude\nLLM_PROVIDER=openrouter\nOPENROUTER_API_KEY=sk-or-your-key-here\nDEFAULT_MODEL=anthropic/claude-3.5-sonnet\nExample 3: Direct Anthropic Claude\nLLM_PROVIDER=anthropic\nANTHROPIC_API_KEY=sk-ant-your-key-here\nDEFAULT_MODEL=claude-3-5-sonnet-20241022\nExample 4: Local Ollama\nLLM_PROVIDER=custom\nOPENAI_API_KEY=ollama  # Can be any value for local models\nOPENAI_BASE_URL=http://localhost:11434/v1\nDEFAULT_MODEL=llama3.1:8b\nExample 5: Azure OpenAI\nLLM_PROVIDER=custom\nOPENAI_API_KEY=your-azure-key\nOPENAI_BASE_URL=https://your-resource.openai.azure.com/\nDEFAULT_MODEL=gpt-4  # Your Azure deployment name\n\nFor more advanced configuration scenarios, see the Architecture Guide.",
    "crumbs": [
      "Home",
      "Configuration Reference"
    ]
  },
  {
    "objectID": "api-reference.html",
    "href": "api-reference.html",
    "title": "API Reference",
    "section": "",
    "text": "This reference covers VeritaScribe’s programmatic interfaces, data models, and internal APIs for developers and advanced users.\n\n\n\n\n\n\nPerform comprehensive thesis analysis.\nuv run python -m veritascribe analyze [OPTIONS] PDF_PATH\nArguments: - PDF_PATH (required): Path to the PDF thesis file\nOptions: - --output, -o TEXT: Output directory for reports - --citation-style, -c TEXT: Expected citation style (APA, MLA, Chicago, IEEE, Harvard) - --quick, -q: Perform quick analysis (first 10 blocks only) - --no-viz: Skip generating visualization charts - --annotate: Generate an annotated PDF with highlighted errors - --verbose, -v: Enable verbose logging\nExit Codes: - 0: Success - 1: Error (file not found, analysis failed, etc.)\n\n\n\nFast analysis of document subset.\nuv run python -m veritascribe quick [OPTIONS] PDF_PATH\nArguments: - PDF_PATH (required): Path to the PDF thesis file\nOptions: - --blocks, -b INTEGER: Number of text blocks to analyze (default: 5)\n\n\n\nCreate and analyze sample document.\nuv run python -m veritascribe demo\nNo arguments or options. Creates demo_thesis.pdf in current directory.\n\n\n\nDisplay current configuration.\nuv run python -m veritascribe config\nOutputs configuration table and API key status.\n\n\n\nList available LLM providers and models.\nuv run python -m veritascribe providers\n\n\n\nFine-tune analysis prompts using a few-shot learning dataset.\nuv run python -m veritascribe optimize-prompts\n\n\n\nRun system diagnostics.\nuv run python -m veritascribe test\nTests configuration loading, PDF processing, and LLM connectivity.\n\n\n\n\n\n\n\n\n\nMain configuration class using Pydantic Settings.\nfrom veritascribe.config import VeritaScribeSettings\n\nsettings = VeritaScribeSettings(\n    openai_api_key=\"your-key-here\",\n    default_model=\"gpt-4\",\n    max_tokens=2000,\n    temperature=0.1\n)\nKey Fields:\n\n\n\n\n\n\n\n\n\nField\nType\nDefault\nDescription\n\n\n\n\nllm_provider\nstr\n\"openai\"\nLLM provider (openai, openrouter, anthropic, custom)\n\n\nopenai_api_key\nOptional[str]\nNone\nOpenAI API key\n\n\nopenrouter_api_key\nOptional[str]\nNone\nOpenRouter API key\n\n\nanthropic_api_key\nOptional[str]\nNone\nAnthropic API key\n\n\ndefault_model\nstr\n\"gpt-4\"\nLLM model name\n\n\nmax_tokens\nint\n2000\nMax tokens per request\n\n\ntemperature\nfloat\n0.1\nLLM temperature\n\n\n\n\n\n\n\nAll data models use Pydantic for validation and serialization.\n\n\nComplete analysis report containing all results.\nKey Fields: - document_name: str - analysis_timestamp: datetime - total_pages: int - total_words: int - total_text_blocks: int - analysis_results: List[AnalysisResult] - total_processing_time_seconds: float - token_usage: Optional[Dict[str, int]] - estimated_cost: Optional[float]\n\nThis API reference covers the main interfaces. For implementation details, see the Architecture Guide."
  },
  {
    "objectID": "api-reference.html#command-line-interface",
    "href": "api-reference.html#command-line-interface",
    "title": "API Reference",
    "section": "",
    "text": "Perform comprehensive thesis analysis.\nuv run python -m veritascribe analyze [OPTIONS] PDF_PATH\nArguments: - PDF_PATH (required): Path to the PDF thesis file\nOptions: - --output, -o TEXT: Output directory for reports - --citation-style, -c TEXT: Expected citation style (APA, MLA, Chicago, IEEE, Harvard) - --quick, -q: Perform quick analysis (first 10 blocks only) - --no-viz: Skip generating visualization charts - --annotate: Generate an annotated PDF with highlighted errors - --verbose, -v: Enable verbose logging\nExit Codes: - 0: Success - 1: Error (file not found, analysis failed, etc.)\n\n\n\nFast analysis of document subset.\nuv run python -m veritascribe quick [OPTIONS] PDF_PATH\nArguments: - PDF_PATH (required): Path to the PDF thesis file\nOptions: - --blocks, -b INTEGER: Number of text blocks to analyze (default: 5)\n\n\n\nCreate and analyze sample document.\nuv run python -m veritascribe demo\nNo arguments or options. Creates demo_thesis.pdf in current directory.\n\n\n\nDisplay current configuration.\nuv run python -m veritascribe config\nOutputs configuration table and API key status.\n\n\n\nList available LLM providers and models.\nuv run python -m veritascribe providers\n\n\n\nFine-tune analysis prompts using a few-shot learning dataset.\nuv run python -m veritascribe optimize-prompts\n\n\n\nRun system diagnostics.\nuv run python -m veritascribe test\nTests configuration loading, PDF processing, and LLM connectivity."
  },
  {
    "objectID": "api-reference.html#python-api",
    "href": "api-reference.html#python-api",
    "title": "API Reference",
    "section": "",
    "text": "Main configuration class using Pydantic Settings.\nfrom veritascribe.config import VeritaScribeSettings\n\nsettings = VeritaScribeSettings(\n    openai_api_key=\"your-key-here\",\n    default_model=\"gpt-4\",\n    max_tokens=2000,\n    temperature=0.1\n)\nKey Fields:\n\n\n\n\n\n\n\n\n\nField\nType\nDefault\nDescription\n\n\n\n\nllm_provider\nstr\n\"openai\"\nLLM provider (openai, openrouter, anthropic, custom)\n\n\nopenai_api_key\nOptional[str]\nNone\nOpenAI API key\n\n\nopenrouter_api_key\nOptional[str]\nNone\nOpenRouter API key\n\n\nanthropic_api_key\nOptional[str]\nNone\nAnthropic API key\n\n\ndefault_model\nstr\n\"gpt-4\"\nLLM model name\n\n\nmax_tokens\nint\n2000\nMax tokens per request\n\n\ntemperature\nfloat\n0.1\nLLM temperature\n\n\n\n\n\n\n\nAll data models use Pydantic for validation and serialization.\n\n\nComplete analysis report containing all results.\nKey Fields: - document_name: str - analysis_timestamp: datetime - total_pages: int - total_words: int - total_text_blocks: int - analysis_results: List[AnalysisResult] - total_processing_time_seconds: float - token_usage: Optional[Dict[str, int]] - estimated_cost: Optional[float]\n\nThis API reference covers the main interfaces. For implementation details, see the Architecture Guide."
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "Architecture Guide",
    "section": "",
    "text": "VeritaScribe is built on a modular and extensible pipeline architecture, designed to process PDF documents, analyze their content using Large Language Models (LLMs), and generate comprehensive reports. The system leverages modern Python libraries like DSPy for LLM orchestration, Pydantic for data integrity, and PyMuPDF for efficient PDF handling.\n\n\nThe system is composed of several key components that work together in a coordinated workflow.\n\n\n\nCLI (Command Line Interface) (main.py):\n\nBuilt with Typer, providing a user-friendly command-line interface.\nHandles user commands (analyze, quick, demo, etc.), parses arguments, and initiates the analysis pipeline.\n\nConfiguration Management (config.py):\n\nUses Pydantic-Settings to manage configuration from environment variables and .env files.\nProvides type-safe, centralized settings for LLM providers, API keys, analysis parameters, and processing options.\nDynamically configures the DSPy environment based on the selected LLM provider.\n\nPDF Processor (pdf_processor.py):\n\nUtilizes PyMuPDF (fitz) for high-performance PDF parsing.\nExtracts text content along with its layout and location information (bounding boxes), which is crucial for accurate error reporting and annotation.\nCleans and preprocesses text to handle common PDF artifacts and formatting issues.\n\nLLM Analysis Modules (llm_modules.py):\n\nThe core of the analysis engine, built with DSPy (Declarative Self-improving Language Programs).\nConsists of specialized modules for different analysis types:\n\nLinguisticAnalyzer: Checks for grammar, spelling, and style errors.\nContentValidator: Assesses logical consistency and content plausibility.\nCitationChecker: Verifies citation formats against specified styles (e.g., APA, MLA).\n\nEach module uses strongly-typed DSPy Signatures to ensure structured and predictable interactions with LLMs.\nSupports multi-language analysis by leveraging language detection and language-specific prompts and training data.\n\nData Models (data_models.py):\n\nEmploys Pydantic models to define clear, validated data structures for the entire application.\nKey models include TextBlock, BaseError (with subclasses for different error types), and ThesisAnalysisReport.\nEnsures data integrity and provides a consistent data flow between components.\n\nAnalysis Pipeline (pipeline.py):\n\nOrchestrates the end-to-end analysis workflow.\nCoordinates the PDF processor, analysis modules, and report generator.\nManages the flow of data from raw PDF to the final analysis report.\nSupports both sequential and parallel processing of text blocks for performance optimization, using Python’s concurrent.futures.\n\nReport Generator (report_generator.py):\n\nGenerates multiple output formats from the final ThesisAnalysisReport.\nCreates detailed Markdown reports for human-readable summaries.\nExports structured JSON data for programmatic use.\nProduces visualizations (e.g., error distribution charts) using Matplotlib.\nGenerates annotated PDFs with highlighted errors and comments.\n\n\n\n\n\nThe typical workflow is as follows:\n\n\n\n\n\ngraph TD\n    A[User runs CLI command] --&gt; B{Analysis Pipeline};\n    B --&gt; C[PDF Processor: Extract TextBlocks];\n    C --&gt; D{Analysis Orchestrator};\n    D --&gt; E[Linguistic Analyzer];\n    D --&gt; F[Content Validator];\n    D --&gt; G[Citation Checker];\n    E --&gt; H[LLM API Call];\n    F --&gt; H;\n    G --&gt; H;\n    H --&gt; I[Parse & Validate LLM Response];\n    I --&gt; J(AnalysisResult);\n    J --&gt; K[Aggregate Results];\n    K --&gt; L{ThesisAnalysisReport};\n    L --&gt; M[Report Generator];\n    M --&gt; N[Markdown Report];\n    M --&gt; O[JSON Data];\n    M --&gt; P[Visualizations];\n    M --&gt; Q[Annotated PDF];\n\n\n\n\n\n\nThis modular design allows for easy extension, such as adding new analysis modules, supporting more output formats, or integrating different LLM providers."
  },
  {
    "objectID": "architecture.html#system-overview",
    "href": "architecture.html#system-overview",
    "title": "Architecture Guide",
    "section": "",
    "text": "The system is composed of several key components that work together in a coordinated workflow.\n\n\n\nCLI (Command Line Interface) (main.py):\n\nBuilt with Typer, providing a user-friendly command-line interface.\nHandles user commands (analyze, quick, demo, etc.), parses arguments, and initiates the analysis pipeline.\n\nConfiguration Management (config.py):\n\nUses Pydantic-Settings to manage configuration from environment variables and .env files.\nProvides type-safe, centralized settings for LLM providers, API keys, analysis parameters, and processing options.\nDynamically configures the DSPy environment based on the selected LLM provider.\n\nPDF Processor (pdf_processor.py):\n\nUtilizes PyMuPDF (fitz) for high-performance PDF parsing.\nExtracts text content along with its layout and location information (bounding boxes), which is crucial for accurate error reporting and annotation.\nCleans and preprocesses text to handle common PDF artifacts and formatting issues.\n\nLLM Analysis Modules (llm_modules.py):\n\nThe core of the analysis engine, built with DSPy (Declarative Self-improving Language Programs).\nConsists of specialized modules for different analysis types:\n\nLinguisticAnalyzer: Checks for grammar, spelling, and style errors.\nContentValidator: Assesses logical consistency and content plausibility.\nCitationChecker: Verifies citation formats against specified styles (e.g., APA, MLA).\n\nEach module uses strongly-typed DSPy Signatures to ensure structured and predictable interactions with LLMs.\nSupports multi-language analysis by leveraging language detection and language-specific prompts and training data.\n\nData Models (data_models.py):\n\nEmploys Pydantic models to define clear, validated data structures for the entire application.\nKey models include TextBlock, BaseError (with subclasses for different error types), and ThesisAnalysisReport.\nEnsures data integrity and provides a consistent data flow between components.\n\nAnalysis Pipeline (pipeline.py):\n\nOrchestrates the end-to-end analysis workflow.\nCoordinates the PDF processor, analysis modules, and report generator.\nManages the flow of data from raw PDF to the final analysis report.\nSupports both sequential and parallel processing of text blocks for performance optimization, using Python’s concurrent.futures.\n\nReport Generator (report_generator.py):\n\nGenerates multiple output formats from the final ThesisAnalysisReport.\nCreates detailed Markdown reports for human-readable summaries.\nExports structured JSON data for programmatic use.\nProduces visualizations (e.g., error distribution charts) using Matplotlib.\nGenerates annotated PDFs with highlighted errors and comments.\n\n\n\n\n\nThe typical workflow is as follows:\n\n\n\n\n\ngraph TD\n    A[User runs CLI command] --&gt; B{Analysis Pipeline};\n    B --&gt; C[PDF Processor: Extract TextBlocks];\n    C --&gt; D{Analysis Orchestrator};\n    D --&gt; E[Linguistic Analyzer];\n    D --&gt; F[Content Validator];\n    D --&gt; G[Citation Checker];\n    E --&gt; H[LLM API Call];\n    F --&gt; H;\n    G --&gt; H;\n    H --&gt; I[Parse & Validate LLM Response];\n    I --&gt; J(AnalysisResult);\n    J --&gt; K[Aggregate Results];\n    K --&gt; L{ThesisAnalysisReport};\n    L --&gt; M[Report Generator];\n    M --&gt; N[Markdown Report];\n    M --&gt; O[JSON Data];\n    M --&gt; P[Visualizations];\n    M --&gt; Q[Annotated PDF];\n\n\n\n\n\n\nThis modular design allows for easy extension, such as adding new analysis modules, supporting more output formats, or integrating different LLM providers."
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation Guide",
    "section": "",
    "text": "This guide walks you through installing and setting up VeritaScribe on your system.\n\n\nBefore installing VeritaScribe, ensure you have:\n\nPython 3.13 or higher: VeritaScribe requires modern Python features\nOpenAI API Key: Required for LLM-based analysis\nuv: Modern Python package manager (recommended)\n\n\n\n\nVerify you have Python 3.13 or higher:\npython --version\n# Should show Python 3.13.x or higher\nIf you need to install or upgrade Python:\n\nmacOSUbuntu/DebianWindows\n\n\n# Using Homebrew\nbrew install python@3.13\n\n# Using pyenv\npyenv install 3.13.0\npyenv global 3.13.0\n\n\n# Add deadsnakes PPA for latest Python versions\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\nsudo apt install python3.13 python3.13-venv python3.13-pip\n\n\nDownload Python 3.13 from python.org or use:\n# Using Chocolatey\nchoco install python --version=3.13.0\n\n# Using winget\nwinget install Python.Python.3.13\n\n\n\n\n\n\nuv is a fast Python package manager that VeritaScribe uses for dependency management:\n\nmacOS/LinuxWindowsAlternative (pip)\n\n\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n\npip install uv\n\n\n\n\n\n\nClone the VeritaScribe repository:\ngit clone &lt;repository-url&gt;\ncd VeritaScribe\n\n\n\nInstall all required dependencies using uv:\nuv sync\nThis will: - Create a virtual environment automatically - Install all dependencies specified in pyproject.toml - Set up the project for development\n\n\n\n\n\nCopy the example environment configuration:\ncp .env.example .env\n\n\n\nOpen .env in your preferred text editor and add your OpenAI API key:\n# Required: OpenAI API Configuration\nOPENAI_API_KEY=your_openai_api_key_here\n\n# Optional: Customize other settings as needed\nDEFAULT_MODEL=gpt-4\nMAX_TOKENS=2000\nTEMPERATURE=0.1\n\n\n\n\n\n\nOpenAI API Key Required\n\n\n\nVeritaScribe requires an OpenAI API key to function. You can obtain one from the OpenAI Platform.\nSecurity Note: Never commit your API key to version control. The .env file is already included in .gitignore.\n\n\n\n\n\n\nTest your installation with the built-in system test:\nuv run python -m veritascribe test\nThis will verify: - ✅ Configuration loading - ✅ PDF processing capabilities - ✅ LLM connectivity (if API key is configured)\nYou should see output similar to:\nRunning VeritaScribe system tests...\n✓ Configuration loading works\n✓ PDF processing works\n✓ Analysis modules work\n\nTest Results: 3/3 passed\n🎉 All tests passed! VeritaScribe is ready to use.\n\n\n\nRun the demo to see VeritaScribe in action:\nuv run python -m veritascribe demo\nThis will: 1. Create a sample thesis PDF 2. Perform a quick analysis 3. Display results and save example reports\n\n\n\n\n\nIf you prefer to use pip directly:\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -e .\n\n\n\nFor development work, install with additional dev dependencies:\nuv sync --dev\n\n\n\n\n\n\n“uv not found” - Ensure uv is installed and in your PATH - Restart your terminal after installation - Try the alternative pip installation method\n“Python version not supported” - Verify Python 3.13+ is installed: python --version - You may need to use python3.13 explicitly - Consider using pyenv to manage Python versions\n“OpenAI API key not configured” - Ensure .env file exists in the project root - Verify your API key is correct and has credits - Check for extra spaces or characters in the key\n“Permission denied” errors - On macOS/Linux, you may need to use chmod +x on scripts - Ensure you have write permissions in the installation directory\n“SSL Certificate” errors - Update certificates: pip install --upgrade certifi - Check corporate firewall/proxy settings\n\n\n\nIf you continue to experience issues:\n\nCheck system compatibility:\nuv run python -m veritascribe config\nEnable verbose logging:\nuv run python -m veritascribe test --verbose\nVerify environment:\nuv run python -c \"import sys; print(sys.version)\"\nuv run python -c \"from veritascribe import config; print('Import successful')\"\n\n\n\n\n\nNow that VeritaScribe is installed:\n\nConfigure your settings for optimal performance\nLearn the basic usage with examples\nReview the API reference for advanced usage\n\n\nInstallation complete! You’re ready to start analyzing thesis documents with VeritaScribe.",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#prerequisites",
    "href": "installation.html#prerequisites",
    "title": "Installation Guide",
    "section": "",
    "text": "Before installing VeritaScribe, ensure you have:\n\nPython 3.13 or higher: VeritaScribe requires modern Python features\nOpenAI API Key: Required for LLM-based analysis\nuv: Modern Python package manager (recommended)",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#step-1-check-python-version",
    "href": "installation.html#step-1-check-python-version",
    "title": "Installation Guide",
    "section": "",
    "text": "Verify you have Python 3.13 or higher:\npython --version\n# Should show Python 3.13.x or higher\nIf you need to install or upgrade Python:\n\nmacOSUbuntu/DebianWindows\n\n\n# Using Homebrew\nbrew install python@3.13\n\n# Using pyenv\npyenv install 3.13.0\npyenv global 3.13.0\n\n\n# Add deadsnakes PPA for latest Python versions\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\nsudo apt install python3.13 python3.13-venv python3.13-pip\n\n\nDownload Python 3.13 from python.org or use:\n# Using Chocolatey\nchoco install python --version=3.13.0\n\n# Using winget\nwinget install Python.Python.3.13",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#step-2-install-uv-recommended",
    "href": "installation.html#step-2-install-uv-recommended",
    "title": "Installation Guide",
    "section": "",
    "text": "uv is a fast Python package manager that VeritaScribe uses for dependency management:\n\nmacOS/LinuxWindowsAlternative (pip)\n\n\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n\npip install uv",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#step-3-clone-repository",
    "href": "installation.html#step-3-clone-repository",
    "title": "Installation Guide",
    "section": "",
    "text": "Clone the VeritaScribe repository:\ngit clone &lt;repository-url&gt;\ncd VeritaScribe",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#step-4-install-dependencies",
    "href": "installation.html#step-4-install-dependencies",
    "title": "Installation Guide",
    "section": "",
    "text": "Install all required dependencies using uv:\nuv sync\nThis will: - Create a virtual environment automatically - Install all dependencies specified in pyproject.toml - Set up the project for development",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#step-5-configure-environment",
    "href": "installation.html#step-5-configure-environment",
    "title": "Installation Guide",
    "section": "",
    "text": "Copy the example environment configuration:\ncp .env.example .env\n\n\n\nOpen .env in your preferred text editor and add your OpenAI API key:\n# Required: OpenAI API Configuration\nOPENAI_API_KEY=your_openai_api_key_here\n\n# Optional: Customize other settings as needed\nDEFAULT_MODEL=gpt-4\nMAX_TOKENS=2000\nTEMPERATURE=0.1\n\n\n\n\n\n\nOpenAI API Key Required\n\n\n\nVeritaScribe requires an OpenAI API key to function. You can obtain one from the OpenAI Platform.\nSecurity Note: Never commit your API key to version control. The .env file is already included in .gitignore.",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#step-6-verify-installation",
    "href": "installation.html#step-6-verify-installation",
    "title": "Installation Guide",
    "section": "",
    "text": "Test your installation with the built-in system test:\nuv run python -m veritascribe test\nThis will verify: - ✅ Configuration loading - ✅ PDF processing capabilities - ✅ LLM connectivity (if API key is configured)\nYou should see output similar to:\nRunning VeritaScribe system tests...\n✓ Configuration loading works\n✓ PDF processing works\n✓ Analysis modules work\n\nTest Results: 3/3 passed\n🎉 All tests passed! VeritaScribe is ready to use.",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#step-7-try-the-demo",
    "href": "installation.html#step-7-try-the-demo",
    "title": "Installation Guide",
    "section": "",
    "text": "Run the demo to see VeritaScribe in action:\nuv run python -m veritascribe demo\nThis will: 1. Create a sample thesis PDF 2. Perform a quick analysis 3. Display results and save example reports",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#alternative-installation-methods",
    "href": "installation.html#alternative-installation-methods",
    "title": "Installation Guide",
    "section": "",
    "text": "If you prefer to use pip directly:\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -e .\n\n\n\nFor development work, install with additional dev dependencies:\nuv sync --dev",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#troubleshooting-installation",
    "href": "installation.html#troubleshooting-installation",
    "title": "Installation Guide",
    "section": "",
    "text": "“uv not found” - Ensure uv is installed and in your PATH - Restart your terminal after installation - Try the alternative pip installation method\n“Python version not supported” - Verify Python 3.13+ is installed: python --version - You may need to use python3.13 explicitly - Consider using pyenv to manage Python versions\n“OpenAI API key not configured” - Ensure .env file exists in the project root - Verify your API key is correct and has credits - Check for extra spaces or characters in the key\n“Permission denied” errors - On macOS/Linux, you may need to use chmod +x on scripts - Ensure you have write permissions in the installation directory\n“SSL Certificate” errors - Update certificates: pip install --upgrade certifi - Check corporate firewall/proxy settings\n\n\n\nIf you continue to experience issues:\n\nCheck system compatibility:\nuv run python -m veritascribe config\nEnable verbose logging:\nuv run python -m veritascribe test --verbose\nVerify environment:\nuv run python -c \"import sys; print(sys.version)\"\nuv run python -c \"from veritascribe import config; print('Import successful')\"",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  },
  {
    "objectID": "installation.html#next-steps",
    "href": "installation.html#next-steps",
    "title": "Installation Guide",
    "section": "",
    "text": "Now that VeritaScribe is installed:\n\nConfigure your settings for optimal performance\nLearn the basic usage with examples\nReview the API reference for advanced usage\n\n\nInstallation complete! You’re ready to start analyzing thesis documents with VeritaScribe.",
    "crumbs": [
      "Home",
      "Installation Guide"
    ]
  }
]