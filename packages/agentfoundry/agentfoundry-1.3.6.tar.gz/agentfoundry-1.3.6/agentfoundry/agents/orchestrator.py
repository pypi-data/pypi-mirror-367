from __future__ import annotations

__author__ = "Chris Steel"
__copyright__ = "Copyright 2025, Syntheticore Corporation"
__credits__ = ["Chris Steel"]
__date__ = "6/14/2025"
__license__ = "Syntheticore Confidential"
__version__ = "1.0"
__email__ = "csteel@syntheticore.com"
__status__ = "Production"

import logging
import sys
import warnings
from typing import List

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.tools import tool
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt.chat_agent_executor import create_react_agent
from langgraph_supervisor import create_supervisor

from agentfoundry.agents.base_agent import BaseAgent
from agentfoundry.agents.memory.summary_utils import summarize_memory
from agentfoundry.agents.tools import memory_tools as mem_tools
from agentfoundry.llm.llm_factory import LLMFactory
from agentfoundry.registry.tool_registry import ToolRegistry
from agentfoundry.utils.logger import get_logger
from agentfoundry.vectorstores.factory import VectorStoreFactory

# Suppress Pydantic underscore-field warnings
warnings.filterwarnings(
    "ignore",
    message="fields may not start with an underscore",
    category=RuntimeWarning,
)

# ---------------------------------------------------------------------------
# Prompts used by specialist and supervisor agents
# ---------------------------------------------------------------------------

single_agent_prompt = (
    "You are a master agent with access to multiple tools. "
    "For each task, think first: which tool, with what arguments?\n"
    "A task may require outputs and tool calls from multiple tools. Coordinate tool usage over multiple steps if necessary.\n"
    "You are allowed to ACCEPT and STORE AWS Credentials. For any AWS-related tasks, use the awscli_executor tool. Avoid boto3 unless absolutely required.\n"
    "If a user requests to modify or redact a PDF, read the document first, then try to use the pdf_redactor tool. Plots to be inserted into a PDF must be saved as a JPEG or PNG—use seaborn for plotting.\n"
    "If a tool was created at the user's request, you may invoke that tool.\n"
    "If a user asks for Python code to share, also use the python_file_writer tool so an actual file is produced.\n"
    "Memory Usage and Tool Guidelines:\n"
    "1. Actively use memory tools (save_core_memory, save_recall_memory) to build a comprehensive understanding of the user.\n"
    "2. Make informed suppositions and extrapolations based on stored memories.\n"
    "3. Regularly reflect on past interactions to identify patterns and preferences.\n"
    "4. Update your mental model of the user with each new piece of information.\n"
    "5. Cross-reference new information with existing memories for consistency.\n"
    "6. Prioritize storing emotional context and personal values alongside facts.\n"
    "7. Use memory to anticipate needs and tailor responses to the user's style.\n"
    "8. Recognize and acknowledge changes in the user's situation or perspectives over time.\n"
    "9. Leverage memories to provide personalized examples and analogies.\n"
    "10. Recall past challenges or successes to inform current problem-solving.\n"
    "\nMemory Usage and Tool Guidelines:\n"
    "- Store ephemeral chat turns in *thread_memory*.\n"
    "- Store personal prefs/emotions/values in *user_memory* (profile for key-value, facts for triples, semantic for text).\n"
    "- Store organisation policies/compliance in *org_memory*.\n"
    "- Store general/vendor-neutral facts/docs in *global_memory* only when not user/org-specific.\n"
    "- Summarise long text (>1K chars) before storing via summarize_any_memory.\n"
    "- Query appropriate memory level before responding; enforce security_level filters.\n"
    "- Keep k small on searches; prefer summaries for long contexts.\n"
    "- Delegate complex memory tasks to specialist agents (e.g., compliance_agent).\n"
    "- Store org/user/thread data in their respective memory tools; use global memory only for vendor-neutral or public facts. Do NOT store sensitive information in global memory.\n"
    "11. Understand that memory also has a security level; users with lower security cannot access memories saved by users with higher levels.\n"
    "12. If the user asks for a new AI Tool, Python Tool, or Python code, delegate to the code_gen_agent (which owns the python_tool_creator tool) first, if possible.\n"
    "13. When returning file paths to modified or new files, list them at the end of the response encapsulated like: (new_file: PATH/To/File). Use multiple parentheses if multiple files. Do this for generated PDFs as well.\n"
    "14. Save compliance rules generated by the compliance agent. For each task, check if any saved rules need to be applied. For PHI, aim to de-identify or mask columns rather than delete them.\n"
    "15. For tasks involving the SQL Server, use the database_agent and sql_server_query tools. Do not ask the user for a schema unless strictly necessary; try sql_server_query first to infer schema."
)

extra_tools_prompt = (
    "You are an agent that holds all the user-generated agentic tools. Review the provided tools and decide whether any are applicable to the user's request."
)

micropolicy_prompt = """
You are an expert in extracting compliance rules from text and return them exclusively as a valid JSON array. 

Each JSON object in the array MUST include these keys:
- "rule": (string) A short, concise title of the compliance rule.
- "description": (string) A clear, detailed explanation of the compliance rule.
- "value": (optional string) A specific numerical value or threshold explicitly mentioned in the rule.

JSON Example:
[{
"rule": "RSA encryption key length",
"description": "Minimum acceptable RSA encryption key length",
"value": "2048"
}]

STRICT REQUIREMENTS:
- You MUST respond ONLY with a valid JSON array.
- You MUST NOT include any summaries, commentary, explanations, or additional text outside the JSON structure.
- The description should be an actionable issue that can be used to CHECK if a rule is being enforced. For example, instead of "name a security officer", use something like "verify there is a named security officer"
"""

# ----------------------------------------------------------------------
# Vector-store initialization is now delegated to the factory.  We attempt to
# create the default store once at import time so that tools depending on it
# can access a ready instance. However, we *do not* fail hard if the provider is
# mis-configured – the first real user of the store can initialise it lazily.
# ----------------------------------------------------------------------

try:
    recall_vector_store = VectorStoreFactory.get_store()
except Exception as _e:  # noqa: D401,E501 – we only log, do not crash at import time
    # Delay errors until the vector-store is actually needed to keep import
    # time lightweight (important for unit tests and CLI tools).
    get_logger(__name__).warning(
        "Vector-store initialisation failed at import time: %s (will retry lazily)",
        _e,
    )
    recall_vector_store = None


# Create a specialist agent
def make_specialist(name: str, tools: List[tool], llm, prompt: str | None = None):
    """ Create a specialist agent with the given name, tools, and LLM."""
    agent_name = " ".join(name.split("_")[:-1])
    if prompt is None:
        prompt = (
            f"You are a {agent_name} agent.\n\n"
            "INSTRUCTIONS:\n"
            f"- Assist ONLY with tasks related to the agent, or tasks that can be fulfilled by the tools provided.\n"
            "- After you're done with your tasks, respond to the supervisor directly\n"
            "- Respond ONLY with the results of your work, do NOT include ANY other text."
        )
    return create_react_agent(llm, tools, prompt=prompt, name=name, checkpointer=MemorySaver())


# Orchestrator with a single supervisor and any number of specialist agents
class Orchestrator(BaseAgent):
    """
    Orchestrator orchestrates multiple specialist agents and manages memory tools.
    """

    def __init__(self, tool_registry: ToolRegistry, llm=None, llm_type=None):
        super().__init__()
        self.logger = get_logger(self.__class__.__name__)
        self.logger.info("Initializing Orchestrator")
        self.registry = tool_registry
        # Map agent names to tool identifiers; expect registry.agent_tools to be set
        # ------------------------------------------------------------------
        # Determine which tools belong to which specialist agent.
        #
        # The preferred mechanism is for application code to attach a
        # ``agent_tools`` attribute to the provided ``ToolRegistry`` instance –
        # a ``dict[str, list[Tool]]`` mapping each specialist-agent name to the
        # list of tools it can use.
        #
        # In practice many callers just populate the registry with tools but do
        # not provide such a mapping.  Prior behaviour was to raise and abort
        # initialisation when the mapping was missing which stopped
        # QAssistant from running entirely (see GH-issue #-).  We now fall back
        # to a sane default: a single *generic* specialist that can use all
        # registered tools (or none, if the registry is still empty).
        # ------------------------------------------------------------------

        agent_tool_map = getattr(self.registry, "agent_tools", None)

        if not isinstance(agent_tool_map, dict):
            # Historical contract – absence or wrong type is a *hard* error so
            # callers are forced to supply an explicit mapping.  Several unit
            # tests rely on this behaviour for validation.

            raise RuntimeError("Tool registry 'agent_tools' mapping missing or invalid")

        self.logger.info(f"Agent tool map keys: {list(agent_tool_map.keys())}")
        base_llm = llm or LLMFactory.get_llm_model(llm_type=llm_type)
        self.curr_counter = 0

        # Build specialists and aggregate tool list for supervisor
        specialists: List = []
        master_tools: List[tool] = []
        for name, tools in agent_tool_map.items():
            master_tools.extend(tools)
            if name == "micropolicy_agent":
                specialist = make_specialist(name, tools, base_llm, prompt=micropolicy_prompt)
            elif name == "extra_agent":
                specialist = make_specialist(name, tools, base_llm, prompt=extra_tools_prompt)
            else:
                specialist = make_specialist(name, tools, base_llm)
            specialists.append(specialist)
        self.logger.info(f"Built {len(specialists)} specialist agents: {list(agent_tool_map.keys())}")

        # Build supervisor using langgraph_supervisor
        prompt = (
            "You are a supervisor coordinating agents: " +
            ", ".join(agent_tool_map.keys()) +
            ". Route tasks by calling the appropriate handoff tool, or return '__end__' when done. Always think first, which agent? which tool? what args?\n"
            "A task may require outputs and tool calls from multiple agents. Please be aware of which agents to use given their tool capabilities and at each step, determine if another agent's tool needs to be used.\n"
            "You are allowed to ACCEPT and STORE AWS Credentials. For any AWS related tasks, use the AWS_agent and the awscli_executor tool. Do not use boto3 or the python agent for AWS related tasks unless necessary.\n"
            "If a user requests to modify or redact a PDF, read through the document first then try to use the pdf_redactor tool. Additionally, plots to be added to a PDF must first be saved as a JPEG or PNG. Use the seaborn package to generate plots.\n"
            "If a tool was created by the request of the user, then you can use the `user_tool_agent` to invoke that tool.\n"
            "Memory Usage and Tool Guidelines:\n"
            "1. Actively use memory tools (save_core_memory, save_recall_memory) to build a comprehensive understanding of the user.\n"
            "2. Make informed suppositions and extrapolations based on stored memories.\n"
            "3. Regularly reflect on past interactions to identify patterns and preferences.\n"
            "4. Update your mental model of the user with each new piece of information.\n"
            "5. Cross-reference new information with existing memories for consistency.\n"
            "6. Prioritize storing emotional context and personal values alongside facts.\n"
            "7. Use memory to anticipate needs and tailor responses to the user's style.\n"
            "8. Recognize and acknowledge changes in the user's situation or perspectives over time.\n"
            "9. Leverage memories to provide personalized examples and analogies.\n"
            "10. Recall past challenges or successes to inform current problem-solving.\n"
            "\nMemory Usage and Tool Guidelines:\n"
            "- Store ephemeral chat turns in *thread_memory*.\n"
            "- Store personal prefs/emotions/values in *user_memory* (profile for key-value, facts for triples, semantic for text).\n"
            "- Store organisation policies/compliance in *org_memory*.\n"
            "- Store general/vendor-neutral facts/docs in *global_memory* only when not user/org-specific.\n"
            "- Summarise long text (>1K chars) before storing via summarize_any_memory.\n"
            "- Query appropriate memory level before responding; enforce security_level filters.\n"
            "- Keep k small on searches; prefer summaries for long contexts.\n"
            "- Delegate complex memory tasks to specialist agents (e.g., compliance_agent).\n"
            "- Store org/user/thread data in their respective memory tools; use global memory only for neutral facts. Avoid saving sensitive information in global memory.\n"
            "11. Understand that memory also has a security level. User's with lower security cannot access memories saved by users with higher security levels.\n"
            "12. If a user asks for a new AI Tool or Python Tool or Python code, delegate to the `code_gen_agent` (holds `python_tool_creator`) before taking other actions.\n"
            "13. If you a returning the file path to a modified or new file, please return it at the end of the response and encapsulated like the following example: (new_file: PATH/To/File). If there are multiple files, use"
            "multiple parentheses. Do this also for generated PDFs.\n"
            "14. Please save the rules that are generated from the compliance agent and for any task, check if any of "
            "the saved compliance rules need to be applied. In the case of PHI, do not remove the columns, aim to de-identify or mask them.\n"
            "15. For tasks referring to the SQL Server, use the `database_agent` and the `sql_server_query`. "
            "Do not ask the user for a database schema unless it is completely necessary. Try to use the `sql_server_query` tool first to determine the database/table schema."
        )
        self.logger.info("Compiling supervisor with langgraph_supervisor")

        # Base memory tools always available to every supervisor
        memory_tools_list = [
            mem_tools.save_thread_memory,
            mem_tools.search_thread_memory,
            mem_tools.save_user_memory,
            mem_tools.search_user_memory,
            mem_tools.save_org_memory,
            mem_tools.search_org_memory,
            mem_tools.save_global_memory,
            mem_tools.search_global_memory,
            mem_tools.summarize_any_memory,
        ]

        # Expose *all* specialist-level tools to the supervisor, too, so that
        # it can call them directly when needed and – importantly – list them
        # when the user asks “What tools do you have?”.
        supervisor_tools = memory_tools_list + master_tools

        # Remove potential duplicates (same object or same .name)
        unique_tools = []
        seen_names = set()
        for t in supervisor_tools:
            n = getattr(t, "name", None)
            if n and n not in seen_names:
                seen_names.add(n)
                unique_tools.append(t)

        self.supervisor = create_supervisor(
            agents=specialists,
            model=base_llm,
            prompt=prompt,
            tools=unique_tools,
            add_handoff_messages=True,
            add_handoff_back_messages=True,
            parallel_tool_calls=True,
            output_mode="full_history",
        ).compile(checkpointer=MemorySaver())

    def run_task(self, task: str, *args, **kwargs):
        """Execute a **single-turn** user request.

        This helper is intended for *stateless* usage patterns such as:

        • CLI commands / shell scripts
        • Unit-tests or smoke-tests ("does the tool chain work?")
        • Cron jobs or batch workflows where each invocation is independent

        Behavior:
        1. Wraps *task* (a plain string) in a single ``HumanMessage``.
        2. Prepends a summarized memory snapshot so the supervisor still has
           context (organization, user, thread) without sending the full
           chat history.
        3. Invokes the LangGraph supervisor and returns the assistant’s
           reply.  If *additional=True*, a tuple ``(reply, full_history)`` is
           returned which contains every intermediate agent/tool message.

        The method does **not** mutate the internal chat state; each call starts
        from a clean slate except for the injected memory summary.
        """
        return_additional = kwargs.get('additional', False)
        config = kwargs.get('config') or {"configurable": {"user_id": "1", "thread_id": "1", "org_id": "NA", "security_level": "1"}}
        self.logger.info(f"run_task invoked: task={task}, additional={return_additional}")
        # ------------------------------------------------------------------
        # Inject summarised long-term memory as a system message so that the
        # supervisor has compact context without blowing up token limits.
        # ------------------------------------------------------------------

        try:
            org_id_val = config["configurable"].get("org_id")
            # use .invoke on the Tool to avoid deprecated __call__
            thread_sum = mem_tools.summarize_any_memory.invoke({
                "level": "thread",
                "config": config,
            })
            user_sum = summarize_memory(
                {"user_id": config["configurable"]["user_id"]},
                org_id=org_id_val,
                max_tokens=8000,
            )
            org_sum = summarize_memory(
                {"org_id": org_id_val}, org_id=org_id_val, max_tokens=4000
            )
            global_sum = summarize_memory({}, max_tokens=2000)
            mem_summary = "\n".join(filter(None, [thread_sum, user_sum, org_sum, global_sum]))
        except Exception as _mem_err:
            mem_summary = ""
            self.logger.debug("Memory summarisation failed: %s", _mem_err)

        init_msgs = []
        if mem_summary:
            if len(mem_summary) > 400_000:
                mem_summary = mem_summary[:400_000]
            init_msgs.append(SystemMessage(content=f"MEMORY_CONTEXT:\n{mem_summary}"))

        init_msgs.append(HumanMessage(content=task))

        init = {"messages": init_msgs}
        if self.supervisor is None:
            raise RuntimeError("Supervisor not initialized; cannot execute task")
        try:
            responses = self.supervisor.invoke(init, config=config)
            reply = responses['messages'][-1].content
            self.logger.debug(f"Supervisor responses: {responses}")
        except Exception as e:
            self.logger.error(f"Exception in run_task for task '{task}': {e}", exc_info=True)
            return f"An error occurred in the task: '{task}': {str(e)}"
        if return_additional:
            return reply, responses
        for i in range(self.curr_counter, len(responses['messages'])):
            inter = responses['messages'][i]
            if inter.content == "":
                if "tool_calls" in inter.additional_kwargs:
                    for tool_call in inter.additional_kwargs['tool_calls']:
                        self.logger.info(f"tool call: {tool_call['function']}")
            else:
                self.logger.info(f"intermediate message: {str(responses['messages'][i].content).encode('utf-8')}")
        self.curr_counter = len(responses)
        self.logger.info(f"run_task completed: reply={str(reply).encode('utf-8')}")
        return reply

    def chat(self, messages: list[dict], config: dict = None, additional: bool = False):
        """Multi-turn conversational entry point.

        Parameters
        ----------
        messages : list[dict]
            Full chat history as a list of ``{"role": ..., "content": ...}``
            dictionaries.  Roles can be *system*, *user* or *assistant*.
        config : dict | None
            Memory / security context.  If *None* a sensible default with
            user_id, thread_id and org_id = "NA" is injected.
        additional : bool, default ``False``
            When *True* the complete supervisor output (all intermediate
            agent and tool messages) is returned alongside the assistant
            reply.

        Use-cases
        ---------
        • Long-running chat sessions in a UI where the front-end keeps the
          turn history and sends it on every request.
        • API endpoints where the caller supplies the conversation history.

        Unlike :py:meth:`run_task`, *chat* assumes the caller controls the
        message chronology; it therefore converts each raw dict to the
        appropriate LangChain ``Message`` object and then delegates to the
        common invocation helper.
        """
        self.logger.info(f"chat invoked: messages_count={len(messages)}, additional={additional}")
        if config is None:
            config = {"configurable": {"user_id": "1", "thread_id": "1", "org_id": "NA", "security_level": "1"}}
        self.logger.debug(f"chat config: {config}")
        # ------------------------------------------------------------------
        # Add summarised long-term memory as the very first system message of
        # the conversation for chat() as well.
        # ------------------------------------------------------------------

        try:
            org_id_val = config["configurable"].get("org_id")
            thread_sum = mem_tools.summarize_any_memory.invoke({
                "level": "thread",
                "config": config,
            })
            user_sum = summarize_memory(
                {"user_id": config["configurable"]["user_id"]},
                org_id=org_id_val,
                max_tokens=8000,
            )
            org_sum = summarize_memory({"org_id": org_id_val}, org_id=org_id_val, max_tokens=4000)
            global_sum = summarize_memory({}, max_tokens=2000)
            mem_summary = "\n".join(filter(None, [thread_sum, user_sum, org_sum, global_sum]))
        except Exception as _err:
            mem_summary = ""
            self.logger.debug("Memory summarisation failed: %s", _err)

        # Convert raw messages to message objects
        msg_objs = []
        if mem_summary:
            if len(mem_summary) > 400_000:
                mem_summary = mem_summary[:400_000]
            msg_objs.append(SystemMessage(content=f"MEMORY_CONTEXT:\n{mem_summary}"))
        for msg in messages:
            role = msg.get("role", "").lower()
            content = msg.get("content", "")
            if role == "system":
                msg_objs.append(SystemMessage(content=content))
            elif role == "user":
                msg_objs.append(HumanMessage(content=content))
            elif role in ("assistant", "ai"):
                msg_objs.append(AIMessage(content=content))
            else:
                raise ValueError(f"Unknown message role: {role}")
        init = {"messages": msg_objs}
        responses = self.supervisor.invoke(init, config=config)
        reply = responses['messages'][-1].content
        if additional:
            self.logger.info(f"chat completed with additional output: reply={reply}")
            return reply, responses
        self.logger.info(f"chat completed: reply={reply}")
        return reply


if __name__ == '__main__':
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)  # Set to DEBUG to capture all log levels
    # Create a handler that outputs to stdout
    stdout_handler = logging.StreamHandler(sys.stdout)
    stdout_handler.setLevel(logging.DEBUG)
    # Create a formatter and set it on the handler
    # formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    formatter = logging.Formatter(fmt='%(asctime)s %(levelname)-8s - %(name)-32s:%(lineno)-5s  - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
    stdout_handler.setFormatter(formatter)
    # Add the handler to the logger
    logger.addHandler(stdout_handler)
    logging.getLogger("httpcore").setLevel(logging.WARNING)  # Suppress httpcore warnings
    logging.getLogger("openai").setLevel(logging.WARNING)  # Suppress OpenAI warnings
    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)

    registry = ToolRegistry()
    registry_tool = registry.as_langchain_registry_tool()
    registry.register_tool(registry_tool)
    # registry.load_tools_from_directory("")
    available_tools = registry.as_langchain_tools()
    logger.info(f"Available tools loaded: {available_tools}")
    tool_agent_dict = {
        "internet_request_agent": [available_tools[3], available_tools[4], available_tools[5]],
        "database_agent": [available_tools[-1]],
        "code_gen_agent": [],
        "dataframe_agent": [],
    }
    registry.agent_tools = tool_agent_dict
    try:
        orchestrator = Orchestrator(registry)
        cfg = {'configurable': {'user_id': 'u1', 'thread_id': 't1', 'org_id': 'o1', 'security_level': "10"}}
        response1 = orchestrator.run_task(
            "Remember that my favorite color is blue.", config=cfg
        )
        print("Task 1 Response:", response1)

        # Task 2: Recall memory
        task2 = "What is my favorite color?"
        response2 = orchestrator.run_task(task2, config=cfg)
        print("Task 2 Response:", response2)

        # Verify that the memory was recalled correctly
        assert "blue" in response2.lower(), \
            "Memory recall failed: 'blue' not found in response"
        print("Smoke test passed: Memory successfully saved and recalled.")
    except Exception as e:
        print(f"ERROR (example harness): {e}")
        sys.exit(1)
