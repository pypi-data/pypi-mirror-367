"""
Interactive CLI for Smart Research Assistant.

This provides a user-friendly command-line interface for interacting with
the multi-agent research system.
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../../'))

import asyncio
from typing import Dict, Any, Optional
from datetime import datetime
import argparse

from simple_workflow import SimpleResearchWorkflow, run_research_query


class ResearchAssistantCLI:
    """Interactive CLI for the Smart Research Assistant."""
    
    def __init__(self):
        self.workflow = SimpleResearchWorkflow()
        self.session_history: Dict[str, Dict[str, Any]] = {}
        self.current_user = "cli_user"
        
    def print_banner(self):
        """Print the application banner."""
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        ğŸ§  Smart Research Assistant ğŸ§                         â•‘
â•‘                                                                               â•‘
â•‘  Multi-Agent AI Research System powered by DSPy and Gemini LLM               â•‘
â•‘  Features: Research â€¢ Analysis â€¢ Calculations â€¢ Interactive Clarification    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
        
    def print_help(self):
        """Print available commands."""
        print("""
ğŸ“‹ Available Commands:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  research <question>     - Ask a research question
  history                 - Show session history  
  clear                   - Clear screen
  help                    - Show this help message
  quit/exit              - Exit the application
  
ğŸ’¡ Example Questions:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  
  â€¢ What's the ROI of investing $10,000 in renewable energy stocks for 5 years?
  â€¢ Analyze the growth trends in solar energy investments
  â€¢ Calculate compound interest on $5,000 at 7% for 3 years
  â€¢ Compare Tesla vs NIO stock performance
  â€¢ What are the best ESG investment opportunities in 2024?
""")
    
    def format_response_for_cli(self, response: Dict[str, Any]) -> str:
        """Format the agent response for CLI display."""
        if not response or "response" not in response:
            return "âŒ No response received"
        
        agent_response = response["response"]
        
        # Check if this is a conversational response
        if response.get("is_conversational", False):
            return self.format_conversational_response(response)
        
        formatted_response = agent_response.get("formatted_response", "")
        executive_summary = agent_response.get("executive_summary", "")
        
        # Build CLI-friendly output
        output = []
        
        # Executive Summary
        if executive_summary:
            output.append("ğŸ“‹ Executive Summary:")
            output.append("â”€" * 50)
            output.append(executive_summary)
            output.append("")
        
        # Full Response (truncated for CLI)
        if formatted_response:
            output.append("ğŸ“„ Detailed Analysis:")
            output.append("â”€" * 50)
            
            # Split response into sections
            lines = formatted_response.split('\n')
            current_section = []
            
            for line in lines:
                if line.startswith('##'):
                    # New section
                    if current_section:
                        output.extend(current_section[:15])  # Limit lines per section
                        if len(current_section) > 15:
                            output.append(f"   ... ({len(current_section) - 15} more lines)")
                        output.append("")
                        current_section = []
                    
                    # Section header
                    section_title = line.replace('##', '').strip()
                    output.append(f"â–¶ {section_title}")
                    output.append("")
                else:
                    current_section.append(line)
            
            # Add last section
            if current_section:
                output.extend(current_section[:15])
                if len(current_section) > 15:
                    output.append(f"   ... ({len(current_section) - 15} more lines)")
        
        # Metadata
        metadata = response.get("metadata", {})
        if metadata and metadata.get("interaction_type") != "conversational":
            output.append("")
            output.append("ğŸ“Š Processing Details:")
            output.append("â”€" * 30)
            output.append(f"  â€¢ Processing Steps: {metadata.get('processing_steps', 'Unknown')}")
            output.append(f"  â€¢ Had Clarification: {'âœ“' if metadata.get('had_clarification') else 'âœ—'}")
            output.append(f"  â€¢ Had Analysis: {'âœ“' if metadata.get('had_analysis') else 'âœ—'}")
            output.append(f"  â€¢ Completed: {metadata.get('completed_at', 'Unknown')}")
            output.append(f"  â€¢ Session ID: {response.get('session_id', 'Unknown')}")
        
        return '\n'.join(output)
    
    def format_conversational_response(self, response: Dict[str, Any]) -> str:
        """Format conversational responses for CLI display."""
        agent_response = response["response"]
        formatted_response = agent_response.get("formatted_response", "")
        suggested_actions = agent_response.get("suggested_actions", [])
        suggested_topics = agent_response.get("suggested_research_topics", [])
        
        output = []
        
        # Main conversational response
        if formatted_response:
            output.append(formatted_response)
            
        # Suggested actions
        if suggested_actions:
            output.append("")
            output.append("ğŸ’¡ What you can do next:")
            output.append("â”€" * 30)
            for i, action in enumerate(suggested_actions[:4], 1):
                output.append(f"  {i}. {action}")
        
        # Suggested research topics
        if suggested_topics:
            output.append("")
            output.append("ğŸ” Try researching:")
            output.append("â”€" * 20)
            for i, topic in enumerate(suggested_topics[:3], 1):
                output.append(f"  â€¢ {topic}")
        
        return '\n'.join(output)
    
    def print_session_history(self):
        """Print session history."""
        if not self.session_history:
            print("ğŸ“š No research sessions yet. Ask a question to get started!")
            return
        
        print("\nğŸ“š Research Session History:")
        print("â•" * 70)
        
        for i, (session_id, session_data) in enumerate(self.session_history.items(), 1):
            question = session_data.get("question", "Unknown question")
            timestamp = session_data.get("timestamp", "Unknown time")
            
            # Truncate long questions
            if len(question) > 50:
                question = question[:47] + "..."
            
            print(f"{i:2d}. [{timestamp}] {question}")
            print(f"    Session: {session_id}")
        
        print("\nğŸ’¡ Use 'research <question>' to start a new research session")
    
    async def process_research_command(self, question: str) -> bool:
        """Process a research command."""
        if not question.strip():
            print("âŒ Please provide a research question.")
            print("   Example: research What's the ROI of renewable energy investments?")
            return False
        
        print(f"\nğŸ” Researching: {question}")
        print("â•" * (15 + len(question)))
        print("â³ Processing your request... (this may take 30-60 seconds)")
        
        try:
            # Run the research workflow
            result = await run_research_query(question, self.current_user)
            
            if "error" in result:
                print(f"\nâŒ Research failed: {result['error']}")
                return False
            
            # Store in history
            session_id = result.get("session_id", "unknown")
            self.session_history[session_id] = {
                "question": question,
                "result": result,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # Format and display result
            formatted_output = self.format_response_for_cli(result)
            print(f"\nâœ… Research Complete!")
            print("â•" * 70)
            print(formatted_output)
            
            return True
            
        except Exception as e:
            print(f"\nâŒ Unexpected error: {e}")
            return False
    
    def process_command(self, command: str) -> bool:
        """Process a user command. Returns False if should exit."""
        command = command.strip()
        
        if not command:
            return True
        
        # Parse command
        parts = command.split(' ', 1)
        cmd = parts[0].lower()
        args = parts[1] if len(parts) > 1 else ""
        
        if cmd in ['quit', 'exit', 'q']:
            print("\nğŸ‘‹ Thank you for using Smart Research Assistant!")
            return False
        
        elif cmd in ['help', 'h', '?']:
            self.print_help()
        
        elif cmd == 'clear':
            os.system('clear' if os.name == 'posix' else 'cls')
            self.print_banner()
        
        elif cmd == 'history':
            self.print_session_history()
        
        elif cmd == 'research':
            # Run async research command
            asyncio.create_task(self.handle_research_async(args))
        
        else:
            # Treat the entire input as a research question
            asyncio.create_task(self.handle_research_async(command))
        
        return True
    
    async def handle_research_async(self, question: str):
        """Handle research command asynchronously."""
        await self.process_research_command(question)
    
    def run_interactive(self):
        """Run the interactive CLI."""
        self.print_banner()
        print("ğŸš€ Welcome! Type 'help' for commands or just ask a research question.")
        print("ğŸ’¡ Pro tip: You can ask questions directly without typing 'research' first.")
        
        try:
            while True:
                try:
                    # Get user input
                    user_input = input("\nğŸ§  Research Assistant > ").strip()
                    
                    if not user_input:
                        continue
                    
                    # Process command
                    if not self.process_command(user_input):
                        break
                    
                except KeyboardInterrupt:
                    print("\n\nğŸ‘‹ Goodbye! Thanks for using Smart Research Assistant!")
                    break
                except EOFError:
                    print("\n\nğŸ‘‹ Goodbye! Thanks for using Smart Research Assistant!")
                    break
        except Exception as e:
            print(f"\nâŒ CLI Error: {e}")


async def run_single_query(question: str, verbose: bool = False) -> None:
    """Run a single research query (non-interactive mode)."""
    print("ğŸ§  Smart Research Assistant - Single Query Mode")
    print("=" * 60)
    
    if verbose:
        print(f"ğŸ“ Question: {question}")
        print("â³ Processing...")
    
    try:
        result = await run_research_query(question, "single_query_user")
        
        if "error" in result:
            print(f"âŒ Error: {result['error']}")
            return
        
        # Extract and display response
        response = result.get("response", {})
        executive_summary = response.get("executive_summary", "")
        formatted_response = response.get("formatted_response", "")
        
        if executive_summary:
            print(f"\nğŸ“‹ Summary: {executive_summary}")
        
        if formatted_response and verbose:
            print(f"\nğŸ“„ Full Response:\n{formatted_response}")
        
        # Show metadata
        metadata = result.get("metadata", {})
        if verbose and metadata:
            print(f"\nğŸ“Š Metadata:")
            print(f"  Steps: {metadata.get('processing_steps', 0)}")
            print(f"  Had Analysis: {metadata.get('had_analysis', False)}")
            print(f"  Session: {result.get('session_id', 'Unknown')}")
    
    except Exception as e:
        print(f"âŒ Error: {e}")


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Smart Research Assistant - Multi-Agent AI Research System",
        formatter_class=argparse.RawTextHelpFormatter
    )
    
    parser.add_argument(
        '--query', '-q',
        type=str,
        help='Run a single research query (non-interactive mode)'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Show detailed output (only in single query mode)'
    )
    
    parser.add_argument(
        '--examples',
        action='store_true',
        help='Show example research questions'
    )
    
    args = parser.parse_args()
    
    if args.examples:
        print("""
ğŸ§  Smart Research Assistant - Example Questions
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’° Financial Analysis:
  â€¢ What's the ROI of investing $10,000 in renewable energy stocks for 5 years?
  â€¢ Calculate compound interest on $5,000 at 7% annually for 3 years
  â€¢ Compare the risk-return profile of Tesla vs Apple stock
  
ğŸ“ˆ Market Research:
  â€¢ Analyze growth trends in solar energy investments
  â€¢ What are the best ESG investment opportunities in 2024?
  â€¢ Research the impact of AI on healthcare stock valuations
  
ğŸ”¢ Calculations:
  â€¢ Calculate the break-even point for a $50,000 business investment
  â€¢ What's the present value of $100,000 received in 10 years at 5% discount rate?
  â€¢ Analyze loan payment options for $250,000 at different interest rates
  
ğŸŒ General Research:
  â€¢ Research the latest developments in quantum computing
  â€¢ Analyze the environmental impact of cryptocurrency mining
  â€¢ What are the emerging trends in sustainable agriculture?
        """)
        return
    
    if args.query:
        # Single query mode
        asyncio.run(run_single_query(args.query, args.verbose))
    else:
        # Interactive mode
        cli = ResearchAssistantCLI()
        # Need to run async methods in the event loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # Monkey patch to handle async research
        original_process_command = cli.process_command
        
        def sync_process_command(command: str) -> bool:
            parts = command.strip().split(' ', 1)
            cmd = parts[0].lower()
            args = parts[1] if len(parts) > 1 else ""
            
            if cmd == 'research' or (cmd not in ['quit', 'exit', 'q', 'help', 'h', '?', 'clear', 'history']):
                # Handle research command synchronously
                question = args if cmd == 'research' else command
                if question.strip():
                    loop.run_until_complete(cli.process_research_command(question))
                return True
            else:
                return original_process_command(command)
        
        cli.process_command = sync_process_command
        cli.run_interactive()


if __name__ == "__main__":
    main()