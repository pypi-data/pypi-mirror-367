# MX-RMQ ä½¿ç”¨æŒ‡å—

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Redis](https://img.shields.io/badge/redis-5.0+-red.svg)](https://redis.io/)

MX-RMQ æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€å¯é çš„åŸºäºRedisçš„åˆ†å¸ƒå¼æ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿï¼Œæ”¯æŒæ™®é€šæ¶ˆæ¯ã€å»¶æ—¶æ¶ˆæ¯ã€ä¼˜å…ˆçº§æ¶ˆæ¯ï¼Œå…·å¤‡å®Œå–„çš„ç›‘æ§å’Œé‡è¯•æœºåˆ¶ã€‚

> ç›®å‰å·²åŸºæœ¬ç”Ÿäº§å¯ç”¨ã€‚

## ç›®å½•

- [ç‰¹æ€§æ¦‚è§ˆ](#ç‰¹æ€§æ¦‚è§ˆ)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [å®‰è£…](#å®‰è£…)
- [åŸºæœ¬ä½¿ç”¨](#åŸºæœ¬ä½¿ç”¨)
- [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
- [é…ç½®å‚è€ƒ](#é…ç½®å‚è€ƒ)
- [API å‚è€ƒ](#api-å‚è€ƒ)
- [ç›‘æ§å’Œç®¡ç†](#ç›‘æ§å’Œç®¡ç†)
- [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ç‰¹æ€§æ¦‚è§ˆ

- ğŸš€ **é«˜æ€§èƒ½**: åŸºäºRedisçš„å†…å­˜å­˜å‚¨ï¼Œæ”¯æŒ10,000+æ¶ˆæ¯/ç§’çš„ååé‡
- ğŸ”„ **å¯é æ€§**: åŸå­æ€§Luaè„šæœ¬æ“ä½œï¼Œä¿è¯æ¶ˆæ¯ä¸ä¸¢å¤±
- â° **å»¶æ—¶æ¶ˆæ¯**: æ”¯æŒä»»æ„æ—¶é—´å»¶è¿Ÿçš„æ¶ˆæ¯è°ƒåº¦
- ğŸ·ï¸ **ä¼˜å…ˆçº§**: æ”¯æŒé«˜ã€ä¸­ã€ä½ä¼˜å…ˆçº§æ¶ˆæ¯å¤„ç†
- ğŸ” **è‡ªåŠ¨é‡è¯•**: å¯é…ç½®çš„é‡è¯•æœºåˆ¶å’ŒæŒ‡æ•°é€€é¿
- ğŸ’€ **æ­»ä¿¡é˜Ÿåˆ—**: å¤±è´¥æ¶ˆæ¯è‡ªåŠ¨è¿›å…¥æ­»ä¿¡é˜Ÿåˆ—ï¼Œæ”¯æŒäººå·¥å¹²é¢„
- ğŸ“Š **ç›‘æ§æŒ‡æ ‡**: å®æ—¶ç›‘æ§é˜Ÿåˆ—çŠ¶æ€ã€å¤„ç†æ—¶é—´ã€ååç‡ç­‰
- ğŸ›‘ **ä¼˜é›…åœæœº**: æ”¯æŒä¼˜é›…åœæœºï¼Œç¡®ä¿æ¶ˆæ¯å¤„ç†å®Œæˆ
- ğŸ”§ **æ˜“äºä½¿ç”¨**: ç®€æ´çš„APIè®¾è®¡ï¼Œå¼€ç®±å³ç”¨

## è®¾è®¡é™åˆ¶

- âŒ **ä¸æ”¯æŒæ¶ˆè´¹è€…ç»„**: æ¯ä¸ªtopicåªèƒ½è¢«å•ä¸€æ¶ˆè´¹è€…ç»„è´Ÿè½½å‡è¡¡æ¶ˆè´¹ï¼Œå¦‚éœ€å¤šç»„æ¶ˆè´¹åŒä¸€æ¶ˆæ¯ï¼Œè¯·åˆ›å»ºå¤šä¸ªtopicå¹¶æŠ•é€’å¤šæ¬¡æ¶ˆæ¯

## å¿«é€Ÿå¼€å§‹

å¯åŠ¨ redis
```shell
docker run -d --name redis8 -p 6379:6379 redis:8 redis-server
```
### 30ç§’å¿«é€Ÿä½“éªŒ

```python
import asyncio
from mx_rmq import MQConfig, RedisMessageQueue

async def handle_order(payload: dict) -> None:
    """å¤„ç†è®¢å•æ¶ˆæ¯"""
    print(f"å¤„ç†è®¢å•: {payload['order_id']}")
    # ä½ çš„ä¸šåŠ¡é€»è¾‘
    await asyncio.sleep(1)

async def main():
    # åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—
    mq = RedisMessageQueue()
    
    # æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
    mq.register_handler("order_created", handle_order)
    
    # ç”Ÿäº§æ¶ˆæ¯
    await mq.produce("order_created", {
        "order_id": "ORD_123",
        "user_id": 456,
        "amount": 99.99
    })
    
    # éé˜»å¡å¯åŠ¨ï¼ˆæ¨èï¼‰
    await mq.start_background()
    
    # ç­‰å¾…æ¶ˆæ¯å¤„ç†
    await asyncio.sleep(2)
    
    # ä¼˜é›…åœæ­¢
    await mq.stop()
if __name__ == "__main__":
    asyncio.run(main())
```

## å®‰è£…

### ä½¿ç”¨ uv (æ¨è)

```bash
# æ·»åŠ åˆ°ç°æœ‰é¡¹ç›®
uv add mx-rmq

# æˆ–è€…ä»æºç å®‰è£…
git clone https://github.com/CodingOX/mx-rmq.git
cd mx-rmq
uv sync
```

### ä½¿ç”¨ pip

```bash
pip install mx-rmq

# æˆ–ä»æºç å®‰è£…
pip install git+https://github.com/CodingOX/mx-rmq.git
```

### ç³»ç»Ÿè¦æ±‚

- Python 3.12+
- Redis 5.0+ ã€æ¨è Redis 7.4+ã€‘

## åŸºæœ¬ä½¿ç”¨

### 1. åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—

```python
from mx_rmq import MQConfig, RedisMessageQueue

# ä½¿ç”¨é»˜è®¤é…ç½®
mq = RedisMessageQueue()

# æˆ–è‡ªå®šä¹‰é…ç½®
config = MQConfig(
    redis_host="redis://localhost:6379",
    max_workers=10,
    task_queue_size=20
)
mq = RedisMessageQueue(config)
```

### 2. æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨

```python
# æ–¹å¼1: ä½¿ç”¨è£…é¥°å™¨
@mq.register_handler("user_registration")
async def handle_user_registration(payload: dict) -> None:
    user_id = payload['user_id']
    email = payload['email']
    print(f"æ¬¢è¿æ–°ç”¨æˆ·: {user_id} ({email})")

# æ–¹å¼2: ç›´æ¥æ³¨å†Œ
async def handle_payment(payload: dict) -> None:
    print(f"å¤„ç†æ”¯ä»˜: {payload}")

mq.register_handler("payment_completed", handle_payment)
```

### 3. ç”Ÿäº§æ¶ˆæ¯

```python
# ç”Ÿäº§æ™®é€šæ¶ˆæ¯
message_id = await mq.produce("user_registration", {
    "user_id": 12345,
    "email": "user@example.com",
    "timestamp": "2024-01-01T00:00:00Z"
})

print(f"æ¶ˆæ¯å·²å‘é€: {message_id}")
```

### 4. å¯åŠ¨æ¶ˆè´¹è€…

MX-RMQ æä¾›å¤šç§æ–¹å¼å¯åŠ¨æ¶ˆè´¹è€…ï¼Œä»¥é€‚åº”ä¸åŒä½¿ç”¨åœºæ™¯ï¼š

#### æ–¹å¼1: éé˜»å¡å¯åŠ¨ï¼ˆæ¨èï¼‰

```python
# éé˜»å¡å¯åŠ¨ï¼Œç«‹å³è¿”å›æ§åˆ¶æƒ
background_task = await mq.start_background()

# å¯ä»¥ç»§ç»­æ‰§è¡Œå…¶ä»–æ“ä½œ
await mq.produce("test_topic", {"message": "Hello World"})

# ç­‰å¾…ä¸€æ®µæ—¶é—´æˆ–æ‰§è¡Œå…¶ä»–ä»»åŠ¡
await asyncio.sleep(10)

# ä¼˜é›…åœæ­¢
await mq.stop()
```

#### æ–¹å¼2: é˜»å¡å¼å¯åŠ¨ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰

```python
# å¯åŠ¨æ¶ˆè´¹è€…ï¼ˆä¼šé˜»å¡ï¼Œç›´åˆ°æ”¶åˆ°åœæœºä¿¡å·ï¼‰
await mq.start()
```

#### æ–¹å¼3: å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨

```
# ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨ç®¡ç†èµ„æº
async with RedisMessageQueue() as mq:
    mq.register_handler("test_topic", handle_message)
    await mq.start_background()
    await mq.produce("test_topic", {"message": "Hello World"})
    await asyncio.sleep(5)
    # è‡ªåŠ¨åœæ­¢å’Œæ¸…ç†èµ„æº
```

#### æ–¹å¼4: åŒæ­¥è¿è¡Œï¼ˆç®€å•åœºæ™¯ï¼‰

```
# åŒæ­¥è¿è¡ŒæŒ‡å®šæ—¶é•¿
mq = RedisMessageQueue()
mq.register_handler("test_topic", handle_message)
mq.run(duration=10.0)  # è¿è¡Œ10ç§’åè‡ªåŠ¨åœæ­¢
```

## é«˜çº§åŠŸèƒ½

### å»¶æ—¶æ¶ˆæ¯

```python
# 5åˆ†é’Ÿåå‘é€æé†’
await mq.produce(
    topic="send_reminder",
    payload={"user_id": 123, "type": "payment_due"},
    delay=300  # 300ç§’åæ‰§è¡Œ
)

# 1å°æ—¶åå‘é€é‚®ä»¶
await mq.produce(
    topic="send_email",
    payload={
        "to": "user@example.com",
        "subject": "è®¢å•ç¡®è®¤",
        "body": "æ„Ÿè°¢æ‚¨çš„è®¢å•..."
    },
    delay=3600  # 1å°æ—¶åæ‰§è¡Œ
)
```

### ä¼˜å…ˆçº§æ¶ˆæ¯

```python
from mx_rmq import MessagePriority

# é«˜ä¼˜å…ˆçº§æ¶ˆæ¯ï¼ˆä¼˜å…ˆå¤„ç†ï¼‰
await mq.produce(
    topic="system_alert",
    payload={"level": "critical", "message": "ç³»ç»Ÿå‘Šè­¦"},
    priority=MessagePriority.HIGH
)

# æ™®é€šä¼˜å…ˆçº§ï¼ˆé»˜è®¤ï¼‰
await mq.produce(
    topic="user_activity",
    payload={"user_id": 123, "action": "login"},
    priority=MessagePriority.NORMAL
)

# ä½ä¼˜å…ˆçº§æ¶ˆæ¯ï¼ˆæœ€åå¤„ç†ï¼‰
await mq.produce(
    topic="analytics_data",
    payload={"event": "page_view", "page": "/home"},
    priority=MessagePriority.LOW
)
```

### è‡ªå®šä¹‰é‡è¯•é…ç½®

```python
config = MQConfig(
    redis_url="redis://localhost:6379",
    max_retries=5,  # æœ€å¤§é‡è¯•5æ¬¡
    retry_delays=[30, 60, 300, 900, 1800],  # é‡è¯•é—´éš”ï¼š30s, 1m, 5m, 15m, 30m
    processing_timeout=300,  # 5åˆ†é’Ÿå¤„ç†è¶…æ—¶
)

mq = RedisMessageQueue(config)
```

### æ¶ˆæ¯ç”Ÿå­˜æ—¶é—´(TTL)

```python
# è®¾ç½®æ¶ˆæ¯1å°æ—¶åè¿‡æœŸ
await mq.produce(
    topic="temp_notification",
    payload={"message": "ä¸´æ—¶é€šçŸ¥"},
    ttl=3600  # 1å°æ—¶åè¿‡æœŸ
)
```

### æ‰¹é‡ç”Ÿäº§æ¶ˆæ¯

```
# æ‰¹é‡å‘é€å¤šä¸ªæ¶ˆæ¯
messages = [
    {"topic": "order_created", "payload": {"order_id": f"ORD_{i}"}}
    for i in range(100)
]

for msg in messages:
    await mq.produce(msg["topic"], msg["payload"])
```

## é…ç½®å‚è€ƒ

### MQConfig å®Œæ•´å‚æ•°

```
from mx_rmq import MQConfig

config = MQConfig(
    # Redis è¿æ¥é…ç½®
    redis_host="redis://localhost:6379",      # Redisè¿æ¥URL
    redis_db=0,                              # Redisæ•°æ®åº“ç¼–å· (0-15)
    redis_password=None,                     # Rediså¯†ç 
    queue_prefix="",                         # é˜Ÿåˆ—å‰ç¼€ï¼Œç”¨äºå¤šç¯å¢ƒéš”ç¦»
    connection_pool_size=20,                 # è¿æ¥æ± å¤§å°
    
    # æ¶ˆè´¹è€…é…ç½®
    max_workers=5,                           # æœ€å¤§å·¥ä½œåç¨‹æ•°
    task_queue_size=8,                       # æœ¬åœ°ä»»åŠ¡é˜Ÿåˆ—å¤§å°
    
    # æ¶ˆæ¯ç”Ÿå‘½å‘¨æœŸé…ç½®
    message_ttl=86400,                       # æ¶ˆæ¯TTLï¼ˆç§’ï¼‰ï¼Œé»˜è®¤24å°æ—¶
    processing_timeout=180,                  # æ¶ˆæ¯å¤„ç†è¶…æ—¶ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3åˆ†é’Ÿ
    
    # é‡è¯•é…ç½®
    max_retries=3,                           # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delays=[60, 300, 1800],           # é‡è¯•å»¶è¿Ÿé—´éš”ï¼ˆç§’ï¼‰
    
    # æ­»ä¿¡é˜Ÿåˆ—é…ç½®
    enable_dead_letter=True,                 # æ˜¯å¦å¯ç”¨æ­»ä¿¡é˜Ÿåˆ—
    
    # ç›‘æ§é…ç½®
    monitor_interval=30,                     # ç›‘æ§æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    expired_check_interval=10,               # è¿‡æœŸæ¶ˆæ¯æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    processing_monitor_interval=30,          # Processingé˜Ÿåˆ—ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
    batch_size=100,                          # æ‰¹å¤„ç†å¤§å°
)
```

### ç¯å¢ƒå˜é‡é…ç½®

æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼š

```bash
export REDIS_URL="redis://localhost:6379"
export REDIS_PASSWORD="your_password"
export MQ_MAX_WORKERS=10
export MQ_TASK_QUEUE_SIZE=20
export MQ_MESSAGE_TTL=86400
```

```python
import os
from mx_rmq import MQConfig

config = MQConfig(
    redis_host=os.getenv("REDIS_URL", "localhost"),
    redis_port=os.getenv("REDIS_PORT","6379"),
    redis_password=os.getenv("REDIS_PASSWORD"),
    max_workers=int(os.getenv("MQ_MAX_WORKERS", "5")),
    task_queue_size=int(os.getenv("MQ_TASK_QUEUE_SIZE", "8")),
    message_ttl=int(os.getenv("MQ_MESSAGE_TTL", "86400")),
)
```

## API å‚è€ƒ

### RedisMessageQueue ç±»

#### åˆå§‹åŒ–

```python
def __init__(self, config: MQConfig | None = None) -> None:
    """
    åˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—
    
    Args:
        config: æ¶ˆæ¯é˜Ÿåˆ—é…ç½®ï¼Œå¦‚ä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    """
```

#### æ ¸å¿ƒæ–¹æ³•

```python
async def produce(
    self,
    topic: str,
    payload: dict[str, Any],
    delay: int = 0,
    priority: MessagePriority = MessagePriority.NORMAL,
    ttl: int | None = None,
    message_id: str | None = None,
) -> str:
    """
    ç”Ÿäº§æ¶ˆæ¯
    
    Args:
        topic: ä¸»é¢˜åç§°
        payload: æ¶ˆæ¯è´Ÿè½½ï¼ˆå¿…é¡»æ˜¯å¯JSONåºåˆ—åŒ–çš„å­—å…¸ï¼‰
        delay: å»¶è¿Ÿæ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºç«‹å³æ‰§è¡Œ
        priority: æ¶ˆæ¯ä¼˜å…ˆçº§
        ttl: æ¶ˆæ¯ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneä½¿ç”¨é…ç½®é»˜è®¤å€¼
        message_id: æ¶ˆæ¯IDï¼ŒNoneåˆ™è‡ªåŠ¨ç”ŸæˆUUID
        
    Returns:
        æ¶ˆæ¯IDï¼ˆå­—ç¬¦ä¸²ï¼‰
        
    Raises:
        ValueError: å‚æ•°éªŒè¯å¤±è´¥
        RedisError: Redisæ“ä½œå¤±è´¥
    """

def register_handler(self, topic: str, handler: Callable) -> None:
    """
    æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
    
    Args:
        topic: ä¸»é¢˜åç§°
        handler: å¤„ç†å‡½æ•°ï¼Œå¿…é¡»æ˜¯asyncå‡½æ•°ï¼Œæ¥å—ä¸€ä¸ªdictå‚æ•°
        
    Raises:
        ValueError: å¤„ç†å™¨ä¸æ˜¯å¯è°ƒç”¨å¯¹è±¡
    """

async def start(self) -> None:
    """
    å¯åŠ¨æ¶ˆæ¯åˆ†å‘å’Œæ¶ˆè´¹ï¼ˆé˜»å¡å¼ï¼‰
    
    æ­¤æ–¹æ³•ä¼šé˜»å¡ï¼Œç›´åˆ°æ”¶åˆ°åœæœºä¿¡å·(SIGINT/SIGTERM)
    
    Raises:
        RuntimeError: ç³»ç»Ÿæœªæ­£ç¡®åˆå§‹åŒ–
        RedisError: Redisè¿æ¥é”™è¯¯
    """

async def start_background(self) -> Task:
    """
    å¯åŠ¨æ¶ˆæ¯åˆ†å‘å’Œæ¶ˆè´¹ï¼ˆéé˜»å¡å¼ï¼‰
    
    æ­¤æ–¹æ³•ä¸ä¼šé˜»å¡ï¼Œç«‹å³è¿”å›ä¸€ä¸ªTaskå¯¹è±¡
    
    Returns:
        Task: åå°ä»»åŠ¡å¯¹è±¡
        
    Raises:
        RuntimeError: ç³»ç»Ÿæœªæ­£ç¡®åˆå§‹åŒ–
        RedisError: Redisè¿æ¥é”™è¯¯
    """

async def stop(self) -> None:
    """
    åœæ­¢æ¶ˆæ¯é˜Ÿåˆ—å¤„ç†
    
    ä¼˜é›…åœ°åœæ­¢æ‰€æœ‰åå°ä»»åŠ¡å¹¶æ¸…ç†èµ„æº
    """

async def initialize(self) -> None:
    """
    æ‰‹åŠ¨åˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—
    
    é€šå¸¸åœ¨start/start_backgroundä¹‹å‰è‡ªåŠ¨è°ƒç”¨
    """

async def cleanup(self) -> None:
    """
    æ¸…ç†èµ„æºï¼Œå…³é—­Redisè¿æ¥æ± 
    """

def run(self, duration: float | None = None) -> None:
    """
    åŒæ­¥è¿è¡Œæ¶ˆæ¯é˜Ÿåˆ—
    
    Args:
        duration: è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºæ— é™è¿è¡Œç›´åˆ°æ”¶åˆ°ä¿¡å·
    """

async def health_check(self) -> dict[str, Any]:
    """
    æ‰§è¡Œå¥åº·æ£€æŸ¥
    
    Returns:
        dict: åŒ…å«å¥åº·çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
    """
```

#### å±æ€§

```python
@property
def status(self) -> dict[str, Any]:
    """
    è·å–é˜Ÿåˆ—çŠ¶æ€ä¿¡æ¯
    
    Returns:
        dict: åŒ…å«è¿è¡ŒçŠ¶æ€ã€åˆå§‹åŒ–çŠ¶æ€ã€æ´»è·ƒä»»åŠ¡æ•°ç­‰ä¿¡æ¯
    """

@property
def is_running(self) -> bool:
    """
    æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦æ­£åœ¨è¿è¡Œ
    
    Returns:
        bool: é˜Ÿåˆ—è¿è¡ŒçŠ¶æ€
    """
```

### Message ç±»

```python
@dataclass
class Message:
    """æ¶ˆæ¯æ•°æ®ç±»"""
    id: str                    # æ¶ˆæ¯å”¯ä¸€ID
    version: str               # æ¶ˆæ¯æ ¼å¼ç‰ˆæœ¬
    topic: str                 # ä¸»é¢˜åç§°  
    payload: dict[str, Any]    # æ¶ˆæ¯è´Ÿè½½
    priority: MessagePriority  # æ¶ˆæ¯ä¼˜å…ˆçº§
    created_at: int           # åˆ›å»ºæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
    meta: MessageMeta         # æ¶ˆæ¯å…ƒæ•°æ®

@dataclass  
class MessageMeta:
    """æ¶ˆæ¯å…ƒæ•°æ®"""
    status: MessageStatus      # æ¶ˆæ¯çŠ¶æ€
    retry_count: int          # é‡è¯•æ¬¡æ•°
    max_retries: int          # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delays: list[int]   # é‡è¯•å»¶è¿Ÿé…ç½®
    last_error: str | None    # æœ€åä¸€æ¬¡é”™è¯¯ä¿¡æ¯
    expire_at: int            # è¿‡æœŸæ—¶é—´æˆ³
    # ... å…¶ä»–å…ƒæ•°æ®å­—æ®µ
```

### æšä¸¾ç±»å‹

```python
class MessagePriority(str, Enum):
    """æ¶ˆæ¯ä¼˜å…ˆçº§"""
    HIGH = "high"      # é«˜ä¼˜å…ˆçº§
    NORMAL = "normal"  # æ™®é€šä¼˜å…ˆçº§
    LOW = "low"        # ä½ä¼˜å…ˆçº§

class MessageStatus(str, Enum):
    """æ¶ˆæ¯çŠ¶æ€"""
    PENDING = "pending"        # å¾…å¤„ç†
    PROCESSING = "processing"  # å¤„ç†ä¸­
    COMPLETED = "completed"    # å·²å®Œæˆ
    RETRYING = "retrying"      # é‡è¯•ä¸­
    DEAD_LETTER = "dead_letter" # æ­»ä¿¡
```

## ç›‘æ§å’Œç®¡ç†

### æŒ‡æ ‡æ”¶é›†

```python
from mx_rmq import MetricsCollector

# åˆ›å»ºæŒ‡æ ‡æ”¶é›†å™¨
collector = MetricsCollector(redis=mq.redis, queue_prefix=config.queue_prefix)

# æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
metrics = await collector.collect_all_metrics(["order_created", "user_registration"])

# æ‰“å°å…³é”®æŒ‡æ ‡
print(f"å¾…å¤„ç†æ¶ˆæ¯: {metrics['queue.order_created.pending']}")
print(f"å¤„ç†ä¸­æ¶ˆæ¯: {metrics['queue.order_created.processing']}")
print(f"æ€»ååé‡: {metrics['throughput.messages_per_minute']}")
print(f"æ­»ä¿¡é˜Ÿåˆ—: {metrics['queue.dlq.count']}")
```

### é˜Ÿåˆ—ç›‘æ§

```python
# ç›‘æ§å•ä¸ªé˜Ÿåˆ—
queue_metrics = await collector.collect_queue_metrics(["order_created"])
print(f"è®¢å•é˜Ÿåˆ—çŠ¶æ€: {queue_metrics}")

# ç›‘æ§å¤„ç†æ€§èƒ½
processing_metrics = await collector.collect_processing_metrics(["order_created"])
print(f"å¹³å‡å¤„ç†æ—¶é—´: {processing_metrics['order_created.avg_processing_time']}ms")
```

### æ­»ä¿¡é˜Ÿåˆ—ç®¡ç†

```python
# æŸ¥çœ‹æ­»ä¿¡é˜Ÿåˆ—
dlq_count = await mq.redis.llen("dlq:queue")
print(f"æ­»ä¿¡é˜Ÿåˆ—æ¶ˆæ¯æ•°: {dlq_count}")

# è·å–æ­»ä¿¡æ¶ˆæ¯åˆ—è¡¨
dlq_messages = await mq.redis.lrange("dlq:queue", 0, 9)  # è·å–å‰10æ¡
for msg_id in dlq_messages:
    payload = await mq.redis.hget("dlq:payload:map", msg_id)
    print(f"æ­»ä¿¡æ¶ˆæ¯: {msg_id} - {payload}")

# æ‰‹åŠ¨é‡è¯•æ­»ä¿¡æ¶ˆæ¯ï¼ˆéœ€è¦è‡ªå®šä¹‰å®ç°ï¼‰
async def retry_dead_message(message_id: str):
    # ä»æ­»ä¿¡é˜Ÿåˆ—è·å–æ¶ˆæ¯
    payload_json = await mq.redis.hget("dlq:payload:map", message_id)
    if payload_json:
        # è§£ææ¶ˆæ¯å¹¶é‡æ–°ç”Ÿäº§
        message = json.loads(payload_json)
        await mq.produce(message["topic"], message["payload"])
        # ä»æ­»ä¿¡é˜Ÿåˆ—ç§»é™¤
        await mq.redis.lrem("dlq:queue", 1, message_id)
        await mq.redis.hdel("dlq:payload:map", message_id)
```

### å®æ—¶ç›‘æ§è„šæœ¬

```python
import asyncio
import time

async def monitor_loop():
    """å®æ—¶ç›‘æ§å¾ªç¯"""
    collector = MetricsCollector(redis=mq.redis)
    
    while True:
        try:
            # æ”¶é›†æŒ‡æ ‡
            metrics = await collector.collect_all_metrics(["order_created"])
            
            # è¾“å‡ºå…³é”®æŒ‡æ ‡
            print(f"[{time.strftime('%H:%M:%S')}] é˜Ÿåˆ—çŠ¶æ€:")
            print(f"  å¾…å¤„ç†: {metrics.get('queue.order_created.pending', 0)}")
            print(f"  å¤„ç†ä¸­: {metrics.get('queue.order_created.processing', 0)}")
            print(f"  æ­»ä¿¡é˜Ÿåˆ—: {metrics.get('queue.dlq.count', 0)}")
            
            # æ£€æŸ¥å‘Šè­¦æ¡ä»¶
            pending = metrics.get('queue.order_created.pending', 0)
            if pending > 100:
                print(f"âš ï¸  å‘Šè­¦: å¾…å¤„ç†æ¶ˆæ¯ç§¯å‹ ({pending})")
                
            dlq_count = metrics.get('queue.dlq.count', 0)
            if dlq_count > 10:
                print(f"ğŸš¨ å‘Šè­¦: æ­»ä¿¡é˜Ÿåˆ—æ¶ˆæ¯è¿‡å¤š ({dlq_count})")
                
        except Exception as e:
            print(f"ç›‘æ§é”™è¯¯: {e}")
            
        await asyncio.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡

# å¯åŠ¨ç›‘æ§
asyncio.create_task(monitor_loop())
```

## éƒ¨ç½²æŒ‡å—

### é«˜å¯ç”¨éƒ¨ç½²

**Redis Sentinel é…ç½®:**
```python
import redis.sentinel

# é…ç½®Sentinel
sentinels = [
    ('sentinel1', 26379),
    ('sentinel2', 26379), 
    ('sentinel3', 26379),
]

sentinel = redis.sentinel.Sentinel(sentinels, socket_timeout=0.1)

# å‘ç°ä¸»èŠ‚ç‚¹
redis_master = sentinel.master_for('mymaster', socket_timeout=0.1)

# è‡ªå®šä¹‰Redisè¿æ¥
config = MQConfig(redis_url="")  # ç•™ç©ºï¼Œä½¿ç”¨è‡ªå®šä¹‰è¿æ¥
mq = RedisMessageQueue(config)
mq.redis = redis_master  # ä½¿ç”¨Sentinelç®¡ç†çš„è¿æ¥
```

### ç›‘æ§å’Œå‘Šè­¦

**Prometheus æŒ‡æ ‡æš´éœ²:**
```python
from prometheus_client import start_http_server, Gauge, Counter

# å®šä¹‰æŒ‡æ ‡
queue_size = Gauge('mq_queue_size', 'Queue size', ['topic', 'status'])
messages_processed = Counter('mq_messages_processed_total', 'Messages processed', ['topic', 'status'])

async def export_metrics():
    """å¯¼å‡ºPrometheusæŒ‡æ ‡"""
    collector = MetricsCollector(redis=mq.redis)
    
    while True:
        metrics = await collector.collect_all_metrics(['order_created'])
        
        # æ›´æ–°PrometheusæŒ‡æ ‡
        queue_size.labels(topic='order_created', status='pending').set(
            metrics.get('queue.order_created.pending', 0)
        )
        queue_size.labels(topic='order_created', status='processing').set(
            metrics.get('queue.order_created.processing', 0)
        )
        
        await asyncio.sleep(30)

# å¯åŠ¨Prometheus HTTPæœåŠ¡å™¨
start_http_server(8000)
asyncio.create_task(export_metrics())
```

## æœ€ä½³å®è·µ

### 1. æ¶ˆæ¯è®¾è®¡

**âœ… æ¨èåšæ³•:**
```python
# æ¶ˆæ¯ç»“æ„æ¸…æ™°ï¼ŒåŒ…å«å¿…è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
await mq.produce("order_created", {
    "order_id": "ORD_123456",
    "user_id": 789,
    "total_amount": 99.99,
    "currency": "USD",
    "timestamp": "2024-01-01T12:00:00Z",
    "metadata": {
        "source": "web",
        "version": "v1.0"
    }
})
```

**âŒ é¿å…åšæ³•:**
```python
# æ¶ˆæ¯è¿‡äºç®€å•ï¼Œç¼ºå°‘ä¸Šä¸‹æ–‡
await mq.produce("process", {"id": 123})

# æ¶ˆæ¯è¿‡äºå¤æ‚ï¼ŒåŒ…å«å¤§é‡æ•°æ®
await mq.produce("user_update", {
    "user": {...},  # åŒ…å«ç”¨æˆ·çš„æ‰€æœ‰ä¿¡æ¯
    "history": [...],  # åŒ…å«å®Œæ•´å†å²è®°å½•
    "related_data": {...}  # åŒ…å«å¤§é‡å…³è”æ•°æ®
})
```

### 2. é”™è¯¯å¤„ç†

**âœ… æ¨èåšæ³•:**
```python
async def handle_payment(payload: dict) -> None:
    try:
        order_id = payload["order_id"]
        amount = payload["amount"]
        
        # å‚æ•°éªŒè¯
        if not order_id or amount <= 0:
            raise ValueError(f"æ— æ•ˆçš„è®¢å•å‚æ•°: {payload}")
            
        # ä¸šåŠ¡é€»è¾‘
        result = await process_payment(order_id, amount)
        
        # è®°å½•æˆåŠŸæ—¥å¿—
        logger.info("æ”¯ä»˜å¤„ç†æˆåŠŸ", order_id=order_id, amount=amount)
        
    except ValueError as e:
        # å‚æ•°é”™è¯¯ï¼Œä¸é‡è¯•
        logger.error("æ”¯ä»˜å‚æ•°é”™è¯¯", error=str(e), payload=payload)
        raise  # é‡æ–°æŠ›å‡ºï¼Œè¿›å…¥æ­»ä¿¡é˜Ÿåˆ—
        
    except PaymentGatewayError as e:
        # å¤–éƒ¨æœåŠ¡é”™è¯¯ï¼Œå¯é‡è¯•
        logger.warning("æ”¯ä»˜ç½‘å…³é”™è¯¯", error=str(e), order_id=order_id)
        raise  # é‡æ–°æŠ›å‡ºï¼Œè§¦å‘é‡è¯•
        
    except Exception as e:
        # æœªçŸ¥é”™è¯¯
        logger.error("æ”¯ä»˜å¤„ç†å¤±è´¥", error=str(e), order_id=order_id)
        raise
```

### 3. å¹‚ç­‰æ€§å¤„ç†

```python
async def handle_order_created(payload: dict) -> None:
    order_id = payload["order_id"]
    
    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†ï¼ˆå¹‚ç­‰æ€§ä¿æŠ¤ï¼‰
    if await is_order_processed(order_id):
        logger.info("è®¢å•å·²å¤„ç†ï¼Œè·³è¿‡", order_id=order_id)
        return
        
    try:
        # å¤„ç†è®¢å•
        await process_order(order_id)
        
        # æ ‡è®°ä¸ºå·²å¤„ç†
        await mark_order_processed(order_id)
        
    except Exception as e:
        logger.error("è®¢å•å¤„ç†å¤±è´¥", order_id=order_id, error=str(e))
        raise
```

### 4. æ€§èƒ½ä¼˜åŒ–

**å·¥ä½œåç¨‹æ•°è°ƒä¼˜:**
```python
import os
import multiprocessing

# æ ¹æ®CPUæ ¸å¿ƒæ•°å’ŒIOç‰¹æ€§è°ƒæ•´å·¥ä½œåç¨‹æ•°
cpu_count = multiprocessing.cpu_count()

config = MQConfig(
    # CPUå¯†é›†å‹ä»»åŠ¡ï¼šå·¥ä½œåç¨‹æ•° = CPUæ ¸å¿ƒæ•°
    max_workers=cpu_count if is_cpu_intensive else cpu_count * 2,
    
    # IOå¯†é›†å‹ä»»åŠ¡ï¼šå·¥ä½œåç¨‹æ•° = CPUæ ¸å¿ƒæ•° * 2-4
    # max_workers=cpu_count * 3,
    
    # ä»»åŠ¡é˜Ÿåˆ—å¤§å°åº”è¯¥å¤§äºå·¥ä½œåç¨‹æ•°
    task_queue_size=max_workers * 2,
)
```

**æ‰¹é‡å¤„ç†ä¼˜åŒ–:**
```python
async def handle_batch_emails(payload: dict) -> None:
    """æ‰¹é‡å¤„ç†é‚®ä»¶å‘é€"""
    email_list = payload["emails"]
    
    # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜å ç”¨è¿‡å¤§
    batch_size = 10
    for i in range(0, len(email_list), batch_size):
        batch = email_list[i:i + batch_size]
        
        # å¹¶å‘å‘é€é‚®ä»¶
        tasks = [send_email(email) for email in batch]
        await asyncio.gather(*tasks, return_exceptions=True)
        
        # é¿å…è¿‡å¿«çš„è¯·æ±‚
        await asyncio.sleep(0.1)
```

### 5. APIä½¿ç”¨å»ºè®®

#### æ¨èä½¿ç”¨éé˜»å¡API

```python
# æ¨èï¼šä½¿ç”¨éé˜»å¡å¯åŠ¨
async def recommended_usage():
    mq = RedisMessageQueue()
    mq.register_handler("topic", message_handler)
    
    # éé˜»å¡å¯åŠ¨
    task = await mq.start_background()
    
    # å¯ä»¥ç»§ç»­æ‰§è¡Œå…¶ä»–æ“ä½œ
    await do_other_work()
    
    # ä¼˜é›…åœæ­¢
    await mq.stop()

# ä¸æ¨èï¼šä½¿ç”¨é˜»å¡å¼å¯åŠ¨ï¼ˆé™¤éæœ‰ç‰¹æ®Šéœ€æ±‚ï¼‰
async def legacy_usage():
    mq = RedisMessageQueue()
    mq.register_handler("topic", message_handler)
    
    # ä¼šé˜»å¡ç›´åˆ°æ”¶åˆ°ä¿¡å·
    await mq.start()
```

#### ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨ç®¡ç†èµ„æº

```
# æ¨èï¼šä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
async def context_manager_usage():
    async with RedisMessageQueue() as mq:
        mq.register_handler("topic", message_handler)
        await mq.start_background()
        await mq.produce("topic", {"data": "example"})
        await asyncio.sleep(5)
        # è‡ªåŠ¨æ¸…ç†èµ„æº
```

#### åˆç†ä½¿ç”¨åŒæ­¥API

```
# é€‚ç”¨äºç®€å•åœºæ™¯çš„åŒæ­¥API
def simple_usage():
    mq = RedisMessageQueue()
    mq.register_handler("topic", message_handler)
    # è¿è¡Œ10ç§’åè‡ªåŠ¨åœæ­¢
    mq.run(duration=10.0)
```

### 6. å¤šç»„æ¶ˆè´¹çš„å®ç°æ–¹æ¡ˆ

ç”±äºç³»ç»Ÿä¸æ”¯æŒæ¶ˆè´¹è€…ç»„åŠŸèƒ½ï¼Œå¦‚éœ€å®ç°å¤šç»„æ¶ˆè´¹åŒä¸€æ¶ˆæ¯ï¼Œå»ºè®®é‡‡ç”¨ä»¥ä¸‹æ–¹æ¡ˆï¼š

**âœ… æ¨èåšæ³•:**
```python
# æ–¹æ¡ˆ1ï¼šåˆ›å»ºå¤šä¸ªtopicï¼Œå‘é€å¤šæ¬¡æ¶ˆæ¯
async def send_order_created(order_data: dict):
    """å‘é€è®¢å•åˆ›å»ºæ¶ˆæ¯åˆ°å¤šä¸ªå¤„ç†ç»„"""
    # å‘é€åˆ°ä¸åŒçš„å¤„ç†ç»„
    await mq.produce("order_created_payment", order_data)    # æ”¯ä»˜å¤„ç†ç»„
    await mq.produce("order_created_inventory", order_data)  # åº“å­˜å¤„ç†ç»„
    await mq.produce("order_created_analytics", order_data)  # åˆ†æå¤„ç†ç»„
    await mq.produce("order_created_notification", order_data) # é€šçŸ¥å¤„ç†ç»„

# æ³¨å†Œä¸åŒçš„å¤„ç†å™¨
@mq.register_handler("order_created_payment")
async def handle_payment_processing(payload: dict):
    """å¤„ç†æ”¯ä»˜ç›¸å…³é€»è¾‘"""
    await process_payment(payload)

@mq.register_handler("order_created_inventory")
async def handle_inventory_processing(payload: dict):
    """å¤„ç†åº“å­˜ç›¸å…³é€»è¾‘"""
    await update_inventory(payload)

@mq.register_handler("order_created_analytics")
async def handle_analytics_processing(payload: dict):
    """å¤„ç†åˆ†æç›¸å…³é€»è¾‘"""
    await update_analytics(payload)

@mq.register_handler("order_created_notification")
async def handle_notification_processing(payload: dict):
    """å¤„ç†é€šçŸ¥ç›¸å…³é€»è¾‘"""
    await send_notifications(payload)
```

**æ–¹æ¡ˆ2ï¼šä½¿ç”¨ç»Ÿä¸€çš„åˆ†å‘å™¨**
```python
# åˆ›å»ºä¸€ä¸ªåˆ†å‘å™¨topic
@mq.register_handler("order_created")
async def order_dispatcher(payload: dict):
    """è®¢å•æ¶ˆæ¯åˆ†å‘å™¨"""
    order_id = payload["order_id"]
    
    # å¹¶å‘åˆ†å‘åˆ°å„ä¸ªå¤„ç†ç»„
    tasks = [
        mq.produce("order_payment", payload),
        mq.produce("order_inventory", payload),
        mq.produce("order_analytics", payload),
        mq.produce("order_notification", payload),
    ]
    
    try:
        await asyncio.gather(*tasks)
        logger.info("è®¢å•æ¶ˆæ¯åˆ†å‘æˆåŠŸ", order_id=order_id)
    except Exception as e:
        logger.error("è®¢å•æ¶ˆæ¯åˆ†å‘å¤±è´¥", order_id=order_id, error=str(e))
        raise
```

**æ–¹æ¡ˆ3ï¼šä½¿ç”¨topicå‘½åè§„èŒƒ**
```python
# ä½¿ç”¨ç»Ÿä¸€çš„å‘½åè§„èŒƒ
TOPIC_PATTERNS = {
    "order_created": [
        "order_created.payment",
        "order_created.inventory", 
        "order_created.analytics",
        "order_created.notification"
    ]
}

async def broadcast_message(base_topic: str, payload: dict):
    """å¹¿æ’­æ¶ˆæ¯åˆ°å¤šä¸ªç›¸å…³topic"""
    topics = TOPIC_PATTERNS.get(base_topic, [base_topic])
    
    tasks = [mq.produce(topic, payload) for topic in topics]
    await asyncio.gather(*tasks)
    
    logger.info("æ¶ˆæ¯å¹¿æ’­å®Œæˆ", base_topic=base_topic, target_topics=topics)

# ä½¿ç”¨ç¤ºä¾‹
await broadcast_message("order_created", order_data)
```

### 6. ç›‘æ§å’Œå‘Šè­¦

```python
async def setup_monitoring():
    """è®¾ç½®ç›‘æ§å’Œå‘Šè­¦"""
    collector = MetricsCollector(redis=mq.redis)
    
    while True:
        try:
            metrics = await collector.collect_all_metrics(["order_created"])
            
            # é˜Ÿåˆ—ç§¯å‹å‘Šè­¦
            pending = metrics.get('queue.order_created.pending', 0)
            if pending > 1000:
                await send_alert(f"é˜Ÿåˆ—ç§¯å‹ä¸¥é‡: {pending} æ¡æ¶ˆæ¯å¾…å¤„ç†")
                
            # æ­»ä¿¡é˜Ÿåˆ—å‘Šè­¦  
            dlq_count = metrics.get('queue.dlq.count', 0)
            if dlq_count > 50:
                await send_alert(f"æ­»ä¿¡é˜Ÿåˆ—æ¶ˆæ¯è¿‡å¤š: {dlq_count} æ¡")
                
            # å¤„ç†æ—¶é—´å‘Šè­¦
            avg_time = metrics.get('processing.order_created.avg_time', 0)
            if avg_time > 30000:  # 30ç§’
                await send_alert(f"æ¶ˆæ¯å¤„ç†æ—¶é—´è¿‡é•¿: {avg_time}ms")
                
        except Exception as e:
            logger.error("ç›‘æ§æ£€æŸ¥å¤±è´¥", error=str(e))
            
        await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### Q1: æ¶ˆæ¯ä¸¢å¤±æ€ä¹ˆåŠï¼Ÿ

**ç—‡çŠ¶:** å‘é€çš„æ¶ˆæ¯æ²¡æœ‰è¢«å¤„ç†

**å¯èƒ½åŸå› :**
1. Redis è¿æ¥ä¸­æ–­
2. æ¶ˆè´¹è€…æ²¡æœ‰æ­£ç¡®å¯åŠ¨
3. æ¶ˆæ¯å¤„ç†å™¨æŠ›å‡ºå¼‚å¸¸ä½†æ²¡æœ‰æ­£ç¡®å¤„ç†

**è§£å†³æ–¹æ¡ˆ:**
```python
# 1. æ£€æŸ¥Redisè¿æ¥
try:
    await mq.redis.ping()
    print("Redisè¿æ¥æ­£å¸¸")
except Exception as e:
    print(f"Redisè¿æ¥å¤±è´¥: {e}")

# 2. æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åœ¨é˜Ÿåˆ—ä¸­
pending_count = await mq.redis.llen("order_created:pending")
processing_count = await mq.redis.llen("order_created:processing")
print(f"å¾…å¤„ç†: {pending_count}, å¤„ç†ä¸­: {processing_count}")

# 3. æ£€æŸ¥æ­»ä¿¡é˜Ÿåˆ—
dlq_count = await mq.redis.llen("dlq:queue")
print(f"æ­»ä¿¡é˜Ÿåˆ—: {dlq_count}")
```

#### Q2: æ¶ˆæ¯å¤„ç†è¿‡æ…¢

**ç—‡çŠ¶:** é˜Ÿåˆ—ç§¯å‹ï¼Œæ¶ˆæ¯å¤„ç†ä¸åŠæ—¶

**å¯èƒ½åŸå› :**
1. å·¥ä½œåç¨‹æ•°ä¸è¶³
2. å¤„ç†å‡½æ•°æ‰§è¡Œæ—¶é—´è¿‡é•¿
3. Redisæ€§èƒ½ç“¶é¢ˆ

**è§£å†³æ–¹æ¡ˆ:**
```python
# 1. å¢åŠ å·¥ä½œåç¨‹æ•°
config = MQConfig(max_workers=20)  # å¢åŠ åˆ°20ä¸ª

# 2. ä¼˜åŒ–å¤„ç†å‡½æ•°
async def optimized_handler(payload: dict) -> None:
    # ä½¿ç”¨å¼‚æ­¥IO
    async with aiohttp.ClientSession() as session:
        response = await session.post(url, json=payload)
    
    # é¿å…é˜»å¡æ“ä½œ
    await asyncio.to_thread(blocking_operation, payload)

# 3. ç›‘æ§å¤„ç†æ—¶é—´
import time

async def timed_handler(payload: dict) -> None:
    start_time = time.time()
    try:
        await actual_handler(payload)
    finally:
        processing_time = time.time() - start_time
        if processing_time > 5:  # å¤„ç†æ—¶é—´è¶…è¿‡5ç§’
            logger.warning("å¤„ç†æ—¶é—´è¿‡é•¿", time=processing_time, payload=payload)
```

#### Q3: å†…å­˜ä½¿ç”¨è¿‡é«˜

**ç—‡çŠ¶:** åº”ç”¨å†…å­˜æŒç»­å¢é•¿

**å¯èƒ½åŸå› :**
1. æœ¬åœ°é˜Ÿåˆ—ç§¯å‹
2. æ¶ˆæ¯å¯¹è±¡æ²¡æœ‰æ­£ç¡®é‡Šæ”¾
3. Redisè¿æ¥æ± è¿‡å¤§

**è§£å†³æ–¹æ¡ˆ:**
```python
# 1. è°ƒæ•´é˜Ÿåˆ—å¤§å°
config = MQConfig(
    task_queue_size=10,  # å‡å°‘æœ¬åœ°é˜Ÿåˆ—å¤§å°
    connection_pool_size=10,  # å‡å°‘è¿æ¥æ± å¤§å°
)

# 2. ç›‘æ§å†…å­˜ä½¿ç”¨
import psutil
import gc

async def memory_monitor():
    while True:
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        
        if memory_mb > 500:  # å†…å­˜è¶…è¿‡500MB
            logger.warning("å†…å­˜ä½¿ç”¨è¿‡é«˜", memory_mb=memory_mb)
            gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
            
        await asyncio.sleep(60)
```


### æ€§èƒ½è¯Šæ–­

#### å»¶è¿Ÿåˆ†æ

```python
import time
from collections import defaultdict

class PerformanceAnalyzer:
    def __init__(self):
        self.metrics = defaultdict(list)
    
    async def analyze_handler(self, handler_name: str, handler_func):
        """åˆ†æå¤„ç†å™¨æ€§èƒ½"""
        async def wrapped_handler(payload: dict):
            start_time = time.time()
            try:
                result = await handler_func(payload)
                return result
            finally:
                end_time = time.time()
                processing_time = (end_time - start_time) * 1000  # æ¯«ç§’
                self.metrics[handler_name].append(processing_time)
                
                # å®šæœŸè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                if len(self.metrics[handler_name]) % 100 == 0:
                    times = self.metrics[handler_name]
                    avg_time = sum(times) / len(times)
                    max_time = max(times)
                    min_time = min(times)
                    
                    print(f"{handler_name} æ€§èƒ½ç»Ÿè®¡ (æœ€è¿‘100æ¬¡):")
                    print(f"  å¹³å‡æ—¶é—´: {avg_time:.2f}ms")
                    print(f"  æœ€å¤§æ—¶é—´: {max_time:.2f}ms") 
                    print(f"  æœ€å°æ—¶é—´: {min_time:.2f}ms")
        
        return wrapped_handler

# ä½¿ç”¨ç¤ºä¾‹
analyzer = PerformanceAnalyzer()

@mq.register_handler("order_created")
async def handle_order(payload: dict):
    # å¤„ç†é€»è¾‘
    await process_order(payload)

# åŒ…è£…å¤„ç†å™¨è¿›è¡Œæ€§èƒ½åˆ†æ
mq.handlers["order_created"] = await analyzer.analyze_handler(
    "order_created", 
    handle_order
)
```

