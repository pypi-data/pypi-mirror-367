"""
è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸åœºæ™¯æµ‹è¯•
"""

import asyncio
import pytest
import time
from unittest.mock import patch, MagicMock, AsyncMock

from mx_rmq import RedisMessageQueue, MQConfig
from mx_rmq.message import Message, MessagePriority, MessageStatus
from mx_rmq.monitoring.metrics import MetricsCollector


class TestBoundaryConditions:
    """è¾¹ç•Œæ¡ä»¶æµ‹è¯•"""
    
    def test_empty_topic_handling(self):
        """æµ‹è¯•ç©ºä¸»é¢˜å¤„ç†"""
        with pytest.raises(ValueError):
            Message(topic="", payload={"test": "data"})
    
    def test_none_payload_handling(self):
        """æµ‹è¯•Noneè´Ÿè½½å¤„ç†"""
        with pytest.raises(ValueError):
            Message(topic="test", payload=None) # type: ignore
    
    def test_empty_payload_handling(self):
        """æµ‹è¯•ç©ºè´Ÿè½½å¤„ç†"""
        # ç©ºå­—å…¸åº”è¯¥æ˜¯å…è®¸çš„
        message = Message(topic="test", payload={})
        assert message.payload == {}
    
    def test_large_payload_handling(self):
        """æµ‹è¯•å¤§è´Ÿè½½å¤„ç†"""
        # åˆ›å»ºå¤§è´Ÿè½½
        large_data = "x" * 1000000  # 1MBæ•°æ®
        large_payload = {"large_data": large_data}
        
        message = Message(topic="large_test", payload=large_payload)
        assert len(message.payload["large_data"]) == 1000000
    
    def test_unicode_payload_handling(self):
        """æµ‹è¯•Unicodeè´Ÿè½½å¤„ç†"""
        unicode_payload = {
            "chinese": "ä½ å¥½ä¸–ç•Œ",
            "japanese": "ã“ã‚“ã«ã¡ã¯",
            "emoji": "ğŸš€ğŸ‰âœ¨",
            "special": "Ã¤Ã¶Ã¼ Ã±"
        }
        
        message = Message(topic="unicode_test", payload=unicode_payload)
        assert message.payload["chinese"] == "ä½ å¥½ä¸–ç•Œ"
        assert message.payload["emoji"] == "ğŸš€ğŸ‰âœ¨"
    
    def test_nested_payload_handling(self):
        """æµ‹è¯•åµŒå¥—è´Ÿè½½å¤„ç†"""
        nested_payload = {
            "level1": {
                "level2": {
                    "level3": {
                        "data": "deep_value",
                        "array": [1, 2, 3, {"nested_in_array": True}]
                    }
                }
            }
        }
        
        message = Message(topic="nested_test", payload=nested_payload)
        assert message.payload["level1"]["level2"]["level3"]["data"] == "deep_value"
    
    def test_zero_ttl_handling(self):
        """æµ‹è¯•é›¶TTLå¤„ç†"""
        with pytest.raises(ValueError):
            MQConfig(message_ttl=0)
    
    def test_negative_retry_count_handling(self):
        """æµ‹è¯•è´Ÿé‡è¯•æ¬¡æ•°å¤„ç†"""
        with pytest.raises(ValueError):
            MQConfig(max_retries=-1)
    
    def test_maximum_retry_count_handling(self):
        """æµ‹è¯•æœ€å¤§é‡è¯•æ¬¡æ•°å¤„ç†"""
        message = Message(topic="max_retry_test", payload={"test": "data"})
        
        # è®¾ç½®åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
        message.meta.max_retries = 10
        message.meta.retry_count = 10
        
        # ä¸åº”è¯¥èƒ½å¤Ÿå†é‡è¯•
        assert message.can_retry() is False
    
    def test_zero_delay_message_handling(self):
        """æµ‹è¯•é›¶å»¶è¿Ÿæ¶ˆæ¯å¤„ç†"""
        message = Message(
            topic="zero_delay_test",
            payload={"test": "data"}
        )
        
        # æ–°åˆ›å»ºçš„æ¶ˆæ¯åº”è¯¥æ˜¯å¾…å¤„ç†çŠ¶æ€
        assert message.meta.status == MessageStatus.PENDING
    
    def test_maximum_delay_message_handling(self):
        """æµ‹è¯•æœ€å¤§å»¶è¿Ÿæ¶ˆæ¯å¤„ç†"""
        # æµ‹è¯•éå¸¸å¤§çš„å»¶è¿Ÿå€¼
        large_delay = 365 * 24 * 3600  # ä¸€å¹´
        message = Message(
            topic="max_delay_test", 
            payload={"test": "data"}
        )
        
        # æµ‹è¯•æ¶ˆæ¯çš„è¿‡æœŸæ—¶é—´è®¾ç½®
        future_time = int((time.time() + large_delay) * 1000)
        message.meta.expire_at = future_time
        
        assert message.meta.expire_at > int(time.time() * 1000)
    
    def test_concurrent_message_processing(self):
        """æµ‹è¯•å¹¶å‘æ¶ˆæ¯å¤„ç†"""
        from mx_rmq.monitoring.metrics import MetricsCollector
        import threading
        
        collector = MetricsCollector()
        topic = "concurrent_boundary_test"
        thread_count = 50
        messages_per_thread = 20
        
        results = []
        
        def worker_thread():
            try:
                for i in range(messages_per_thread):
                    collector.record_message_produced(topic)
                    collector.record_message_consumed(topic)
                    collector.record_message_completed(topic, processing_time=0.001)
                results.append("success")
            except Exception as e:
                results.append(f"error: {e}")
        
        # å¯åŠ¨å¤§é‡å¹¶å‘çº¿ç¨‹
        threads = []
        for _ in range(thread_count):
            thread = threading.Thread(target=worker_thread)
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # éªŒè¯æ‰€æœ‰çº¿ç¨‹éƒ½æˆåŠŸ
        assert len(results) == thread_count
        assert all(result == "success" for result in results)
        
        # éªŒè¯æœ€ç»ˆè®¡æ•°æ­£ç¡®
        metrics = collector.get_processing_metrics(topic)
        expected_total = thread_count * messages_per_thread
        assert metrics.total_processed == expected_total


class TestExceptionScenarios:
    """å¼‚å¸¸åœºæ™¯æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_redis_connection_loss_during_operation(self):
        """æµ‹è¯•æ“ä½œè¿‡ç¨‹ä¸­Redisè¿æ¥ä¸¢å¤±"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # æ¨¡æ‹Ÿè¿æ¥ä¸¢å¤±
        with patch.object(queue, '_connection_manager') as mock_cm:
            mock_cm.cleanup.side_effect = ConnectionError("è¿æ¥ä¸¢å¤±")
            
            # åº”è¯¥å¤„ç†è¿æ¥é”™è¯¯è€Œä¸å´©æºƒ
            await queue.cleanup()
    
    def test_handler_registration_with_invalid_callable(self):
        """æµ‹è¯•æ³¨å†Œæ— æ•ˆå¤„ç†å™¨"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # å°è¯•æ³¨å†Œéå¯è°ƒç”¨å¯¹è±¡
        with pytest.raises(TypeError):
            queue.register_handler("test_topic", "not_callable") # type: ignore
    
    def test_message_status_invalid_transition(self):
        """æµ‹è¯•æ— æ•ˆçš„æ¶ˆæ¯çŠ¶æ€è½¬æ¢"""
        message = Message(topic="status_test", payload={"test": "data"})
        
        # æ¶ˆæ¯åº”è¯¥æŒ‰æ­£ç¡®é¡ºåºè½¬æ¢çŠ¶æ€
        assert message.meta.status == MessageStatus.PENDING
        
        # ç›´æ¥æ ‡è®°ä¸ºå®Œæˆï¼ˆè·³è¿‡å¤„ç†çŠ¶æ€ï¼‰åº”è¯¥å¯ä»¥
        message.mark_completed()
        assert message.meta.status == MessageStatus.COMPLETED
    
    def test_message_expiration_edge_cases(self):
        """æµ‹è¯•æ¶ˆæ¯è¿‡æœŸè¾¹ç•Œæƒ…å†µ"""
        message = Message(topic="expiry_test", payload={"test": "data"})
        
        # æµ‹è¯•åˆšå¥½è¿‡æœŸçš„æ¶ˆæ¯
        current_time_ms = int(time.time() * 1000)
        message.meta.expire_at = current_time_ms - 1  # 1mså‰è¿‡æœŸ
        
        assert message.is_expired() is True
        
        # æµ‹è¯•åˆšå¥½æœªè¿‡æœŸçš„æ¶ˆæ¯
        message.meta.expire_at = current_time_ms + 1  # 1msåè¿‡æœŸ
        assert message.is_expired() is False
    
    def test_metrics_overflow_handling(self):
        """æµ‹è¯•æŒ‡æ ‡æº¢å‡ºå¤„ç†"""
        collector = MetricsCollector()
        topic = "overflow_test"
        
        # æ·»åŠ å¤§é‡å¤„ç†æ—¶é—´è®°å½•
        large_count = 10000
        for i in range(large_count):
            collector.record_message_completed(topic, processing_time=float(i))
        
        # éªŒè¯å†…å­˜ä½¿ç”¨å—é™
        processing_times = collector._processing_times[topic]
        assert len(processing_times) <= 1000  # åº”è¯¥æœ‰ä¸Šé™
        
        # éªŒè¯ç»Ÿè®¡ä»ç„¶æ­£ç¡®
        metrics = collector.get_processing_metrics(topic)
        assert metrics.total_processed == large_count
    
    def test_queue_shutdown_during_message_processing(self):
        """æµ‹è¯•æ¶ˆæ¯å¤„ç†è¿‡ç¨‹ä¸­çš„é˜Ÿåˆ—å…³é—­"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ä¸­çš„å…³é—­
        with patch.object(queue, 'is_running', side_effect=[True, False]):
            # ç¬¬ä¸€æ¬¡è°ƒç”¨è¿”å›Trueï¼Œç¬¬äºŒæ¬¡è¿”å›Falseï¼ˆæ¨¡æ‹Ÿå…³é—­ï¼‰
            assert queue.is_running() is True
            assert queue.is_running() is False
    
    @pytest.mark.asyncio 
    async def test_async_handler_exception_propagation(self):
        """æµ‹è¯•å¼‚æ­¥å¤„ç†å™¨å¼‚å¸¸ä¼ æ’­"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        async def failing_async_handler(payload):
            raise RuntimeError("å¼‚æ­¥å¤„ç†å¤±è´¥")
        
        # æ³¨å†Œå¼‚æ­¥å¤„ç†å™¨
        queue.register_handler("async_error_topic", failing_async_handler)
        
        # éªŒè¯å¤„ç†å™¨å·²æ³¨å†Œï¼ˆå…·ä½“å¼‚å¸¸å¤„ç†åœ¨å®é™…è¿è¡Œæ—¶æµ‹è¯•ï¼‰
        if queue._context:
            assert "async_error_topic" in queue._context.handlers
    
    def test_memory_pressure_scenarios(self):
        """æµ‹è¯•å†…å­˜å‹åŠ›åœºæ™¯"""
        collector = MetricsCollector()
        
        # åˆ›å»ºå¤§é‡topicå’ŒæŒ‡æ ‡
        topic_count = 1000
        for i in range(topic_count):
            topic = f"memory_test_{i}"
            collector.record_message_produced(topic)
            collector.record_message_consumed(topic)
            collector.record_message_completed(topic, processing_time=0.1)
        
        # éªŒè¯æ‰€æœ‰topicéƒ½è¢«è®°å½•
        all_metrics = collector.get_all_processing_metrics()
        assert len(all_metrics) == topic_count
    
    def test_rapid_queue_start_stop_cycles(self):
        """æµ‹è¯•å¿«é€Ÿå¯åœå¾ªç¯"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # å¿«é€Ÿå¤šæ¬¡åœæ­¢ï¼ˆåº”è¯¥å®‰å…¨å¤„ç†ï¼‰
        async def rapid_stop_test():
            for _ in range(10):
                await queue.stop()
        
        # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
        asyncio.run(rapid_stop_test())
    
    def test_invalid_redis_configuration(self):
        """æµ‹è¯•æ— æ•ˆRedisé…ç½®"""
        # æµ‹è¯•æ— æ•ˆç«¯å£
        with pytest.raises(ValueError):
            MQConfig(redis_port=-1)
        
        with pytest.raises(ValueError):
            MQConfig(redis_port=100000)  # ç«¯å£è¶…å‡ºèŒƒå›´
    
    def test_topic_name_edge_cases(self):
        """æµ‹è¯•ä¸»é¢˜åè¾¹ç•Œæƒ…å†µ"""
        # æµ‹è¯•éå¸¸é•¿çš„ä¸»é¢˜å
        long_topic = "x" * 1000
        message = Message(topic=long_topic, payload={"test": "data"})
        assert message.topic == long_topic
        
        # æµ‹è¯•ç‰¹æ®Šå­—ç¬¦ä¸»é¢˜å
        special_topic = "test:topic.with-special_chars@123"
        message = Message(topic=special_topic, payload={"test": "data"})
        assert message.topic == special_topic
    
    def test_processing_time_edge_cases(self):
        """æµ‹è¯•å¤„ç†æ—¶é—´è¾¹ç•Œæƒ…å†µ"""
        collector = MetricsCollector()
        topic = "processing_time_test"
        
        # æµ‹è¯•é›¶å¤„ç†æ—¶é—´
        collector.record_message_completed(topic, processing_time=0.0)
        
        # æµ‹è¯•éå¸¸å°çš„å¤„ç†æ—¶é—´
        collector.record_message_completed(topic, processing_time=0.000001)
        
        # æµ‹è¯•å¾ˆå¤§çš„å¤„ç†æ—¶é—´
        collector.record_message_completed(topic, processing_time=3600.0)  # 1å°æ—¶
        
        metrics = collector.get_processing_metrics(topic)
        assert metrics.total_processed == 3
        assert metrics.min_processing_time == 0.0
        assert metrics.max_processing_time == 3600.0


class TestResourceExhaustion:
    """èµ„æºè€—å°½æµ‹è¯•"""
    
    def test_memory_limited_metrics_collection(self):
        """æµ‹è¯•å†…å­˜å—é™çš„æŒ‡æ ‡æ”¶é›†"""
        collector = MetricsCollector()
        topic = "memory_limit_test"
        
        # æ¨¡æ‹Ÿå¤§é‡æ•°æ®æ”¶é›†
        data_points = 50000
        for i in range(data_points):
            collector.record_message_completed(topic, processing_time=float(i % 100))
        
        # éªŒè¯å†…å­˜ä½¿ç”¨è¢«æ§åˆ¶
        processing_times = collector._processing_times[topic]
        assert len(processing_times) <= 1000
        
        # ä½†æ€»è®¡æ•°åº”è¯¥æ˜¯å‡†ç¡®çš„
        metrics = collector.get_processing_metrics(topic)
        assert metrics.total_processed == data_points
    
    def test_high_frequency_operations(self):
        """æµ‹è¯•é«˜é¢‘æ“ä½œ"""
        collector = MetricsCollector()
        topic = "high_freq_test"
        
        import time
        start_time = time.time()
        
        # é«˜é¢‘æ“ä½œ
        operation_count = 10000
        for i in range(operation_count):
            collector.record_message_produced(topic)
            collector.record_message_consumed(topic)
            collector.record_message_completed(topic, processing_time=0.001)
        
        elapsed_time = time.time() - start_time
        
        # éªŒè¯æ€§èƒ½ï¼ˆåº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆï¼‰
        assert elapsed_time < 5.0  # 5ç§’å†…å®Œæˆ
        
        # éªŒè¯ç»“æœæ­£ç¡®æ€§
        metrics = collector.get_processing_metrics(topic)
        assert metrics.total_processed == operation_count
    
    def test_queue_size_limits(self):
        """æµ‹è¯•é˜Ÿåˆ—å¤§å°é™åˆ¶"""
        config = MQConfig(task_queue_size=100)
        queue = RedisMessageQueue(config)
        
        # éªŒè¯é…ç½®è¢«æ­£ç¡®è®¾ç½®
        assert config.task_queue_size == 100
    
    def test_connection_pool_exhaustion(self):
        """æµ‹è¯•è¿æ¥æ± è€—å°½"""
        from mx_rmq.storage import RedisConnectionManager
        
        # è®¾ç½®è¾ƒå°çš„è¿æ¥æ± 
        config = MQConfig(redis_max_connections=5)
        manager = RedisConnectionManager(config)
        
        # éªŒè¯é…ç½®è¢«åº”ç”¨
        assert config.redis_max_connections == 5
    
    def test_message_retention_limits(self):
        """æµ‹è¯•æ¶ˆæ¯ä¿ç•™é™åˆ¶"""
        # æµ‹è¯•æ¶ˆæ¯TTLæœºåˆ¶
        message = Message(topic="retention_test", payload={"test": "data"})
        
        # è®¾ç½®å¾ˆçŸ­çš„TTL
        short_ttl_ms = int(time.time() * 1000) + 1000  # 1ç§’åè¿‡æœŸ
        message.meta.expire_at = short_ttl_ms
        
        # éªŒè¯æ¶ˆæ¯å°†ä¼šè¿‡æœŸ
        assert message.meta.expire_at > 0
        
        # æ¨¡æ‹Ÿæ—¶é—´æµé€
        future_time_ms = short_ttl_ms + 1000
        with patch('time.time', return_value=future_time_ms / 1000):
            assert message.is_expired() is True
    
    def test_error_accumulation_handling(self):
        """æµ‹è¯•é”™è¯¯ç´¯ç§¯å¤„ç†"""
        collector = MetricsCollector()
        topic = "error_accumulation_test"
        
        # è®°å½•å¤§é‡é”™è¯¯
        error_count = 1000
        for i in range(error_count):
            collector.record_message_failed(topic, f"é”™è¯¯_{i}", processing_time=0.1)
        
        # éªŒè¯é”™è¯¯è¢«æ­£ç¡®ç»Ÿè®¡
        metrics = collector.get_processing_metrics(topic)
        assert metrics.error_count == error_count
        assert metrics.total_processed == error_count
    
    def test_topic_proliferation_handling(self):
        """æµ‹è¯•ä¸»é¢˜æ¿€å¢å¤„ç†"""
        collector = MetricsCollector()
        
        # åˆ›å»ºå¤§é‡ä¸åŒçš„ä¸»é¢˜
        topic_count = 5000
        for i in range(topic_count):
            topic = f"proliferation_test_{i}"
            collector.record_message_produced(topic)
        
        # éªŒè¯æ‰€æœ‰ä¸»é¢˜éƒ½è¢«è·Ÿè¸ª
        all_queue_metrics = collector.get_all_queue_metrics()
        assert len(all_queue_metrics) == topic_count
        
        # éªŒè¯æ¯ä¸ªä¸»é¢˜çš„æŒ‡æ ‡
        for i in range(topic_count):
            topic = f"proliferation_test_{i}"
            assert topic in all_queue_metrics
            assert all_queue_metrics[topic].pending_count == 1


class TestSystemLimits:
    """ç³»ç»Ÿé™åˆ¶æµ‹è¯•"""
    
    def test_maximum_message_size_handling(self):
        """æµ‹è¯•æœ€å¤§æ¶ˆæ¯å¤§å°å¤„ç†"""
        # åˆ›å»ºæ¥è¿‘ç³»ç»Ÿé™åˆ¶çš„å¤§æ¶ˆæ¯
        large_payload = {
            "data": "x" * 1000000,  # 1MB
            "metadata": {"size": "large"},
            "array": list(range(10000))
        }
        
        message = Message(topic="large_message_test", payload=large_payload)
        
        # éªŒè¯å¤§æ¶ˆæ¯å¯ä»¥è¢«åˆ›å»º
        assert len(message.payload["data"]) == 1000000
        assert len(message.payload["array"]) == 10000
    
    def test_maximum_retry_attempts(self):
        """æµ‹è¯•æœ€å¤§é‡è¯•æ¬¡æ•°"""
        message = Message(topic="max_retry_test", payload={"test": "data"})
        
        # è®¾ç½®åˆç†çš„æœ€å¤§é‡è¯•æ¬¡æ•°
        message.meta.max_retries = 100
        
        # æ¨¡æ‹Ÿè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
        message.meta.retry_count = 100
        
        # éªŒè¯ä¸èƒ½å†é‡è¯•
        assert message.can_retry() is False
    
    def test_timestamp_precision_handling(self):
        """æµ‹è¯•æ—¶é—´æˆ³ç²¾åº¦å¤„ç†"""
        message = Message(topic="timestamp_test", payload={"test": "data"})
        
        # éªŒè¯æ—¶é—´æˆ³ç²¾åº¦ï¼ˆæ¯«ç§’çº§ï¼‰
        created_at = message.meta.created_at
        assert created_at > 0
        assert created_at > 1000000000000  # åº”è¯¥æ˜¯æ¯«ç§’æ—¶é—´æˆ³ï¼ˆ13ä½æ•°å­—ï¼‰
    
    def test_unicode_string_limits(self):
        """æµ‹è¯•Unicodeå­—ç¬¦ä¸²é™åˆ¶"""
        # åˆ›å»ºåŒ…å«å„ç§Unicodeå­—ç¬¦çš„è´Ÿè½½
        unicode_payload = {
            "emoji_string": "ğŸš€" * 1000,
            "chinese_string": "ä½ å¥½" * 1000,
            "mixed_string": "HelloğŸŒä¸–ç•Œ" * 500
        }
        
        message = Message(topic="unicode_limit_test", payload=unicode_payload)
        
        # éªŒè¯Unicodeå­—ç¬¦ä¸²è¢«æ­£ç¡®å¤„ç†
        assert len(message.payload["emoji_string"]) == 1000
        assert len(message.payload["chinese_string"]) == 2000  # ä¸­æ–‡å­—ç¬¦
        assert "Hello" in message.payload["mixed_string"]
        assert "ğŸŒ" in message.payload["mixed_string"]
        assert "ä¸–ç•Œ" in message.payload["mixed_string"]