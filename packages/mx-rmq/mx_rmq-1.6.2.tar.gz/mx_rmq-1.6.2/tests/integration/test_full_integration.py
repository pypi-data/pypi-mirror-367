"""
ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•
"""

import asyncio
import pytest
import time
import json
from unittest.mock import patch, MagicMock, AsyncMock

from mx_rmq import RedisMessageQueue, MQConfig
from mx_rmq.message import Message, MessagePriority, MessageStatus
from mx_rmq.monitoring.metrics import MetricsCollector


class TestEndToEndIntegration:
    """ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_complete_message_lifecycle(self):
        """æµ‹è¯•å®Œæ•´çš„æ¶ˆæ¯ç”Ÿå‘½å‘¨æœŸ"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # æ¨¡æ‹Ÿå®Œæ•´çš„æ¶ˆæ¯å¤„ç†æµç¨‹
        processed_messages = []
        
        def test_handler(payload):
            processed_messages.append(payload)
            return {"status": "processed", "data": payload}
        
        # æ³¨å†Œå¤„ç†å™¨
        queue.register_handler("integration_test", test_handler)
        
        # éªŒè¯å¤„ç†å™¨æ³¨å†Œ
        if queue._context:
            assert "integration_test" in queue._context.handlers
        
        # åˆ›å»ºæµ‹è¯•æ¶ˆæ¯
        test_payload = {"test_id": "integration_001", "data": "test_data"}
        message = Message(
            topic="integration_test",
            payload=test_payload,
            priority=MessagePriority.HIGH
        )
        
        # éªŒè¯æ¶ˆæ¯ç”Ÿå‘½å‘¨æœŸçŠ¶æ€
        assert message.meta.status == MessageStatus.PENDING
        
        # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹
        message.mark_processing()
        assert message.meta.status == MessageStatus.PROCESSING
        
        # æ¨¡æ‹Ÿå¤„ç†å®Œæˆ
        message.mark_completed()
        assert message.meta.status == MessageStatus.COMPLETED
        assert message.meta.completed_at is not None
    
    @pytest.mark.asyncio
    async def test_multi_topic_message_routing(self):
        """æµ‹è¯•å¤šä¸»é¢˜æ¶ˆæ¯è·¯ç”±"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # å®šä¹‰å¤šä¸ªå¤„ç†å™¨
        order_messages = []
        user_messages = []
        payment_messages = []
        
        def order_handler(payload):
            order_messages.append(payload)
        
        def user_handler(payload):
            user_messages.append(payload)
        
        def payment_handler(payload):
            payment_messages.append(payload)
        
        # æ³¨å†Œå¤šä¸ªä¸»é¢˜å¤„ç†å™¨
        queue.register_handler("orders", order_handler)
        queue.register_handler("users", user_handler)
        queue.register_handler("payments", payment_handler)
        
        # éªŒè¯æ‰€æœ‰å¤„ç†å™¨éƒ½å·²æ³¨å†Œ
        if queue._context:
            handlers = queue._context.handlers
            assert "orders" in handlers
            assert "users" in handlers
            assert "payments" in handlers
        
        # åˆ›å»ºä¸åŒä¸»é¢˜çš„æ¶ˆæ¯
        order_msg = Message(topic="orders", payload={"order_id": "ORD001"})
        user_msg = Message(topic="users", payload={"user_id": "USR001"})
        payment_msg = Message(topic="payments", payload={"payment_id": "PAY001"})
        
        # éªŒè¯æ¶ˆæ¯åˆ›å»ºæˆåŠŸ
        assert order_msg.topic == "orders"
        assert user_msg.topic == "users"
        assert payment_msg.topic == "payments"
    
    @pytest.mark.asyncio
    async def test_priority_queue_ordering(self):
        """æµ‹è¯•ä¼˜å…ˆçº§é˜Ÿåˆ—æ’åº"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # åˆ›å»ºä¸åŒä¼˜å…ˆçº§çš„æ¶ˆæ¯
        low_priority_msg = Message(
            topic="priority_test",
            payload={"priority": "low"},
            priority=MessagePriority.LOW
        )
        
        normal_priority_msg = Message(
            topic="priority_test", 
            payload={"priority": "normal"},
            priority=MessagePriority.NORMAL
        )
        
        high_priority_msg = Message(
            topic="priority_test",
            payload={"priority": "high"}, 
            priority=MessagePriority.HIGH
        )
        
        # éªŒè¯ä¼˜å…ˆçº§è®¾ç½®
        assert low_priority_msg.priority == MessagePriority.LOW
        assert normal_priority_msg.priority == MessagePriority.NORMAL
        assert high_priority_msg.priority == MessagePriority.HIGH
        
        # éªŒè¯ä¼˜å…ˆçº§å€¼çš„æ•°å€¼å…³ç³»
        assert MessagePriority.HIGH.value > MessagePriority.NORMAL.value
        assert MessagePriority.NORMAL.value > MessagePriority.LOW.value
    
    @pytest.mark.asyncio
    async def test_error_handling_and_retry_mechanism(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶"""
        config = MQConfig(max_retries=3)
        queue = RedisMessageQueue(config)
        
        # æ¨¡æ‹Ÿä¼šå¤±è´¥çš„å¤„ç†å™¨
        attempt_count = 0
        
        def failing_handler(payload):
            nonlocal attempt_count
            attempt_count += 1
            if attempt_count < 3:
                raise ValueError(f"å¤„ç†å¤±è´¥ - å°è¯• {attempt_count}")
            return {"status": "success", "attempts": attempt_count}
        
        queue.register_handler("retry_test", failing_handler)
        
        # åˆ›å»ºæ¶ˆæ¯å¹¶æ¨¡æ‹Ÿé‡è¯•è¿‡ç¨‹
        message = Message(
            topic="retry_test",
            payload={"test": "retry_scenario"}
        )
        
        # æ¨¡æ‹Ÿé‡è¯•è¿‡ç¨‹
        for retry in range(3):
            message.meta.retry_count = retry
            
            if retry < 2:
                # å‰ä¸¤æ¬¡å¤±è´¥
                message.mark_retry(f"å¤„ç†å¤±è´¥ - å°è¯• {retry + 1}")
                assert message.meta.status == MessageStatus.RETRYING
                assert message.can_retry() is True
            else:
                # ç¬¬ä¸‰æ¬¡æˆåŠŸ
                message.mark_completed()
                assert message.meta.status == MessageStatus.COMPLETED
    
    @pytest.mark.asyncio
    async def test_dead_letter_queue_flow(self):
        """æµ‹è¯•æ­»ä¿¡é˜Ÿåˆ—æµç¨‹"""
        config = MQConfig(max_retries=2)
        queue = RedisMessageQueue(config)
        
        # åˆ›å»ºæ€»æ˜¯å¤±è´¥çš„æ¶ˆæ¯
        message = Message(
            topic="dlq_test",
            payload={"test": "dead_letter"}
        )
        
        # æ¨¡æ‹Ÿé‡è¯•è€—å°½è¿‡ç¨‹
        message.meta.max_retries = 2
        
        # ç¬¬ä¸€æ¬¡é‡è¯•
        message.mark_retry("ç¬¬ä¸€æ¬¡å¤±è´¥")
        assert message.meta.retry_count == 1
        assert message.can_retry() is True
        
        # ç¬¬äºŒæ¬¡é‡è¯•
        message.mark_retry("ç¬¬äºŒæ¬¡å¤±è´¥")
        assert message.meta.retry_count == 2
        assert message.can_retry() is True
        
        # ç¬¬ä¸‰æ¬¡é‡è¯• - åº”è¯¥è¾¾åˆ°é™åˆ¶
        message.mark_retry("ç¬¬ä¸‰æ¬¡å¤±è´¥")
        assert message.meta.retry_count == 3
        assert message.can_retry() is False
        
        # ç§»å…¥æ­»ä¿¡é˜Ÿåˆ—
        message.mark_dead_letter("è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°")
        assert message.meta.status == MessageStatus.DEAD_LETTER
        assert message.meta.dead_letter_at is not None
    
    @pytest.mark.asyncio
    async def test_delayed_message_processing(self):
        """æµ‹è¯•å»¶è¿Ÿæ¶ˆæ¯å¤„ç†"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # æµ‹è¯•å»¶è¿Ÿæ¶ˆæ¯çš„åŸºæœ¬åˆ›å»º
        message = Message(
            topic="delay_test",
            payload={"test": "delayed_message"}
        )
        
        # éªŒè¯æ¶ˆæ¯çš„åŸºæœ¬å±æ€§
        current_time = int(time.time() * 1000)
        assert message.created_at <= current_time + 1000  # å…è®¸ä¸€äº›æ—¶é—´å·®
        assert message.meta.expire_at > current_time  # æ¶ˆæ¯åº”è¯¥åœ¨æœªæ¥æŸä¸ªæ—¶é—´è¿‡æœŸ
        
        # æµ‹è¯•æ¶ˆæ¯çš„åŸºæœ¬çŠ¶æ€
        assert message.meta.status == MessageStatus.PENDING
    
    @pytest.mark.asyncio
    async def test_metrics_collection_integration(self):
        """æµ‹è¯•æŒ‡æ ‡æ”¶é›†é›†æˆ"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        collector = MetricsCollector()
        
        topic = "metrics_integration_test"
        
        # æ¨¡æ‹Ÿå®Œæ•´çš„æ¶ˆæ¯å¤„ç†æµç¨‹å¹¶æ”¶é›†æŒ‡æ ‡
        message_count = 10
        
        for i in range(message_count):
            # ç”Ÿäº§æ¶ˆæ¯
            collector.record_message_produced(topic)
            
            # å¼€å§‹å¤„ç†
            message_id = f"msg_{i}"
            collector.start_processing(message_id)
            collector.record_message_consumed(topic)
            
            # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            processing_time = 0.1 + (i * 0.01)  # é€’å¢çš„å¤„ç†æ—¶é—´
            
            # å®Œæˆå¤„ç†
            collector.end_processing(message_id)
            collector.record_message_completed(topic, processing_time=processing_time)
        
        # éªŒè¯æŒ‡æ ‡ç»Ÿè®¡
        queue_metrics = collector.get_queue_metrics(topic)
        processing_metrics = collector.get_processing_metrics(topic)
        
        assert queue_metrics.completed_count == message_count
        assert processing_metrics.total_processed == message_count
        assert processing_metrics.success_count == message_count
        assert processing_metrics.avg_processing_time > 0
    
    @pytest.mark.asyncio
    async def test_concurrent_processing_integration(self):
        """æµ‹è¯•å¹¶å‘å¤„ç†é›†æˆ"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        collector = MetricsCollector()
        
        import threading
        import time
        
        topic = "concurrent_integration_test"
        thread_count = 10
        messages_per_thread = 5
        
        results = []
        
        def worker_thread(thread_id):
            try:
                for msg_id in range(messages_per_thread):
                    # ç”Ÿäº§æ¶ˆæ¯
                    collector.record_message_produced(topic)
                    
                    # å¤„ç†æ¶ˆæ¯
                    collector.record_message_consumed(topic)
                    
                    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                    time.sleep(0.001)
                    
                    # å®Œæˆå¤„ç†
                    collector.record_message_completed(
                        topic, 
                        processing_time=0.001
                    )
                
                results.append(f"thread_{thread_id}_success")
            except Exception as e:
                results.append(f"thread_{thread_id}_error_{e}")
        
        # å¯åŠ¨å¹¶å‘çº¿ç¨‹
        threads = []
        for i in range(thread_count):
            thread = threading.Thread(target=worker_thread, args=(i,))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # éªŒè¯æ‰€æœ‰çº¿ç¨‹éƒ½æˆåŠŸ
        success_count = len([r for r in results if "success" in r])
        assert success_count == thread_count
        
        # éªŒè¯æœ€ç»ˆæŒ‡æ ‡
        processing_metrics = collector.get_processing_metrics(topic)
        expected_total = thread_count * messages_per_thread
        assert processing_metrics.total_processed == expected_total
    
    @pytest.mark.asyncio
    async def test_queue_lifecycle_integration(self):
        """æµ‹è¯•é˜Ÿåˆ—ç”Ÿå‘½å‘¨æœŸé›†æˆ"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # åˆå§‹çŠ¶æ€
        assert queue.is_running() is False
        
        # æ³¨å†Œå¤„ç†å™¨
        test_results = []
        
        def lifecycle_handler(payload):
            test_results.append(payload)
            return "processed"
        
        queue.register_handler("lifecycle_test", lifecycle_handler)
        
        # éªŒè¯å¤„ç†å™¨æ³¨å†ŒæˆåŠŸ
        if queue._context:
            assert "lifecycle_test" in queue._context.handlers
        
        # æµ‹è¯•é˜Ÿåˆ—çŠ¶æ€
        status = queue.status
        assert "running" in status
        assert "initialized" in status
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await queue.health_check()
        assert "healthy" in health
        assert "timestamp" in health
        assert "checks" in health
        
        # æµ‹è¯•ä¼˜é›…åœæœº
        await queue.stop()
        
        # éªŒè¯åœæœºåçŠ¶æ€
        assert queue.is_running() is False
    
    @pytest.mark.asyncio
    async def test_configuration_integration(self):
        """æµ‹è¯•é…ç½®é›†æˆ"""
        # æµ‹è¯•ä¸åŒé…ç½®ç»„åˆ
        configs = [
            MQConfig(max_retries=1, message_ttl=3600),
            MQConfig(max_retries=5, message_ttl=7200, task_queue_size=200),
            MQConfig(redis_host="localhost", redis_port=6379, redis_db=1)
        ]
        
        for config in configs:
            queue = RedisMessageQueue(config)
            
            # éªŒè¯é…ç½®è¢«æ­£ç¡®åº”ç”¨
            assert queue.config.max_retries == config.max_retries
            assert queue.config.message_ttl == config.message_ttl
            assert queue.config.redis_host == config.redis_host
            assert queue.config.redis_port == config.redis_port
            
            # æµ‹è¯•é˜Ÿåˆ—åˆ›å»ºæˆåŠŸ
            assert queue is not None
    
    @pytest.mark.asyncio
    async def test_monitoring_integration(self):
        """æµ‹è¯•ç›‘æ§é›†æˆ"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        collector = MetricsCollector()
        
        # æ¨¡æ‹Ÿå„ç§æ¶ˆæ¯çŠ¶æ€
        topics = ["monitoring_test_1", "monitoring_test_2", "monitoring_test_3"]
        
        for topic in topics:
            # æˆåŠŸæ¶ˆæ¯
            collector.record_message_produced(topic)
            collector.record_message_consumed(topic)
            collector.record_message_completed(topic, processing_time=0.1)
            
            # å¤±è´¥æ¶ˆæ¯
            collector.record_message_produced(topic)
            collector.record_message_consumed(topic) 
            collector.record_message_failed(topic, "å¤„ç†é”™è¯¯", processing_time=0.05)
            
            # é‡è¯•æ¶ˆæ¯
            collector.record_message_retried(topic)
            
            # æ­»ä¿¡æ¶ˆæ¯
            collector.record_message_dead_letter(topic)
            
            # å»¶è¿Ÿæ¶ˆæ¯
            collector.record_delay_message(topic)
        
        # éªŒè¯æ‰€æœ‰ä¸»é¢˜çš„æŒ‡æ ‡
        all_queue_metrics = collector.get_all_queue_metrics()
        all_processing_metrics = collector.get_all_processing_metrics()
        
        assert len(all_queue_metrics) == len(topics)
        assert len(all_processing_metrics) == len(topics)
        
        for topic in topics:
            queue_metrics = all_queue_metrics[topic]
            processing_metrics = all_processing_metrics[topic]
            
            # éªŒè¯å„ç§çŠ¶æ€çš„è®¡æ•°
            assert queue_metrics.completed_count == 1
            assert queue_metrics.failed_count == 1
            assert queue_metrics.dead_letter_count == 1
            assert queue_metrics.delay_count == 1
            
            assert processing_metrics.success_count == 1
            assert processing_metrics.error_count == 1
            assert processing_metrics.retry_count == 1
            assert processing_metrics.total_processed == 2  # 1æˆåŠŸ + 1å¤±è´¥


class TestSystemIntegration:
    """ç³»ç»Ÿé›†æˆæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_redis_integration_simulation(self):
        """æµ‹è¯•Redisé›†æˆæ¨¡æ‹Ÿ"""
        from mx_rmq.storage import RedisConnectionManager
        
        config = MQConfig()
        manager = RedisConnectionManager(config)
        
        # éªŒè¯è¿æ¥ç®¡ç†å™¨é…ç½®
        assert manager.config.redis_host == config.redis_host
        assert manager.config.redis_port == config.redis_port
        assert manager.config.redis_db == config.redis_db
        
        # æµ‹è¯•æ¸…ç†æ“ä½œ
        await manager.cleanup()
    
    @pytest.mark.asyncio
    async def test_lua_scripts_integration(self):
        """æµ‹è¯•Luaè„šæœ¬é›†æˆ"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # éªŒè¯Luaè„šæœ¬ç»“æ„ï¼ˆå®é™…è„šæœ¬åœ¨çœŸå®Redisç¯å¢ƒä¸­åŠ è½½ï¼‰
        # è¿™é‡Œä¸»è¦æµ‹è¯•è„šæœ¬ç›¸å…³çš„ä»£ç ç»“æ„
        assert queue._context is None or hasattr(queue._context, 'lua_scripts')
    
    def test_message_serialization_integration(self):
        """æµ‹è¯•æ¶ˆæ¯åºåˆ—åŒ–é›†æˆ"""
        # æµ‹è¯•å„ç§ç±»å‹çš„æ¶ˆæ¯åºåˆ—åŒ–
        test_cases = [
            {
                "topic": "json_test",
                "payload": {"key": "value", "number": 123, "boolean": True}
            },
            {
                "topic": "unicode_test", 
                "payload": {"chinese": "ä½ å¥½", "emoji": "ğŸš€", "special": "Ã¤Ã¶Ã¼"}
            },
            {
                "topic": "nested_test",
                "payload": {
                    "level1": {
                        "level2": {"data": [1, 2, 3, {"nested": True}]}
                    }
                }
            }
        ]
        
        for case in test_cases:
            message = Message(topic=case["topic"], payload=case["payload"])
            
            # åºåˆ—åŒ–ä¸ºJSON
            serialized = json.dumps(message.model_dump())
            
            # éªŒè¯å¯ä»¥ååºåˆ—åŒ–
            deserialized_data = json.loads(serialized)
            assert deserialized_data["topic"] == case["topic"]
            assert deserialized_data["payload"] == case["payload"]
    
    @pytest.mark.asyncio
    async def test_context_management_integration(self):
        """æµ‹è¯•ä¸Šä¸‹æ–‡ç®¡ç†é›†æˆ"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # æµ‹è¯•ä¸Šä¸‹æ–‡è®¿é—®
        context = queue.context
        
        if context:
            # éªŒè¯ä¸Šä¸‹æ–‡ç»“æ„
            assert hasattr(context, 'config')
            assert hasattr(context, 'handlers')
            assert hasattr(context, 'running')
            assert hasattr(context, 'shutting_down')
        
        # æµ‹è¯•è¿æ¥ç®¡ç†å™¨è®¿é—®
        connection_manager = queue.connection_manager
        assert connection_manager is not None
        assert hasattr(connection_manager, 'config')
    
    def test_performance_integration(self):
        """æµ‹è¯•æ€§èƒ½é›†æˆ"""
        import time
        
        config = MQConfig()
        queue = RedisMessageQueue(config)
        collector = MetricsCollector()
        
        # æ€§èƒ½åŸºå‡†æµ‹è¯•
        topic = "performance_integration"
        operation_count = 1000
        
        start_time = time.time()
        
        # æ‰¹é‡æ“ä½œ
        for i in range(operation_count):
            collector.record_message_produced(topic)
            collector.record_message_consumed(topic)
            collector.record_message_completed(topic, processing_time=0.001)
        
        elapsed_time = time.time() - start_time
        
        # éªŒè¯æ€§èƒ½æŒ‡æ ‡
        assert elapsed_time < 2.0  # åº”è¯¥åœ¨2ç§’å†…å®Œæˆ
        
        # éªŒè¯æ“ä½œæ­£ç¡®æ€§
        metrics = collector.get_processing_metrics(topic)
        assert metrics.total_processed == operation_count
        
        # è®¡ç®—ååé‡
        throughput = operation_count / elapsed_time
        assert throughput > 500  # æ¯ç§’è‡³å°‘500ä¸ªæ“ä½œ
    
    @pytest.mark.asyncio
    async def test_error_recovery_integration(self):
        """æµ‹è¯•é”™è¯¯æ¢å¤é›†æˆ"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # æ¨¡æ‹Ÿå„ç§é”™è¯¯åœºæ™¯å¹¶éªŒè¯æ¢å¤
        test_scenarios = [
            {"error": "ConnectionError", "recovery": "é‡è¿"},
            {"error": "TimeoutError", "recovery": "é‡è¯•"},
            {"error": "ValidationError", "recovery": "ä¸¢å¼ƒæ¶ˆæ¯"},
            {"error": "SerializationError", "recovery": "é”™è¯¯å¤„ç†"}
        ]
        
        for scenario in test_scenarios:
            # åˆ›å»ºæµ‹è¯•æ¶ˆæ¯
            message = Message(
                topic="error_recovery",
                payload={"scenario": scenario["error"]}
            )
            
            # æ¨¡æ‹Ÿé”™è¯¯å’Œæ¢å¤è¿‡ç¨‹
            message.mark_processing()
            message.mark_retry(scenario["error"])
            
            # éªŒè¯é”™è¯¯è¢«è®°å½•
            assert scenario["error"] in message.meta.last_error # type: ignore
            assert message.meta.status == MessageStatus.RETRYING


class TestRealWorldScenarios:
    """çœŸå®ä¸–ç•Œåœºæ™¯æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_e_commerce_order_processing(self):
        """æµ‹è¯•ç”µå•†è®¢å•å¤„ç†åœºæ™¯"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        collector = MetricsCollector()
        
        # æ¨¡æ‹Ÿç”µå•†è®¢å•å¤„ç†æµç¨‹
        order_steps = ["payment", "inventory", "shipping", "notification"]
        
        # æ³¨å†Œå„ä¸ªæ­¥éª¤çš„å¤„ç†å™¨
        processed_steps = {}
        
        for step in order_steps:
            processed_steps[step] = []
            
            def create_handler(step_name):
                def handler(payload):
                    processed_steps[step_name].append(payload)
                    collector.record_message_completed(step_name, processing_time=0.1)
                    return {"status": "completed", "step": step_name}
                return handler
            
            queue.register_handler(step, create_handler(step))
        
        # æ¨¡æ‹Ÿè®¢å•å¤„ç†
        order_id = "ORDER_001"
        order_data = {
            "order_id": order_id,
            "customer_id": "CUST_001", 
            "items": [{"sku": "ITEM_001", "quantity": 2}],
            "total": 99.99
        }
        
        # åˆ›å»ºå„ä¸ªæ­¥éª¤çš„æ¶ˆæ¯
        for step in order_steps:
            message = Message(
                topic=step,
                payload={**order_data, "step": step},
                priority=MessagePriority.HIGH if step == "payment" else MessagePriority.NORMAL
            )
            
            # è®°å½•æ¶ˆæ¯ç”Ÿäº§
            collector.record_message_produced(step)
            
            # éªŒè¯æ¶ˆæ¯åˆ›å»º
            assert message.topic == step
            assert message.payload["order_id"] == order_id
        
        # éªŒè¯å¤„ç†å™¨æ³¨å†Œ
        if queue._context:
            for step in order_steps:
                assert step in queue._context.handlers
    
    @pytest.mark.asyncio
    async def test_notification_system_scenario(self):
        """æµ‹è¯•é€šçŸ¥ç³»ç»Ÿåœºæ™¯"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # ä¸åŒç±»å‹çš„é€šçŸ¥
        notification_types = ["email", "sms", "push", "webhook"]
        
        notifications_sent = {}
        
        for notif_type in notification_types:
            notifications_sent[notif_type] = []
            
            def create_notification_handler(notif_type):
                def handler(payload):
                    notifications_sent[notif_type].append(payload)
                    return {"sent": True, "type": notif_type}
                return handler
            
            queue.register_handler(
                f"notification_{notif_type}", 
                create_notification_handler(notif_type)
            )
        
        # åˆ›å»ºé€šçŸ¥æ¶ˆæ¯
        notification_data = {
            "user_id": "USER_001",
            "message": "æ‚¨çš„è®¢å•å·²ç¡®è®¤",
            "priority": "high"
        }
        
        for notif_type in notification_types:
            message = Message(
                topic=f"notification_{notif_type}",
                payload={**notification_data, "type": notif_type},
                priority=MessagePriority.HIGH
            )
            
            assert message.topic == f"notification_{notif_type}"
            assert message.payload["user_id"] == "USER_001"
    
    @pytest.mark.asyncio
    async def test_data_pipeline_scenario(self):
        """æµ‹è¯•æ•°æ®ç®¡é“åœºæ™¯"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        collector = MetricsCollector()
        
        # æ•°æ®å¤„ç†ç®¡é“æ­¥éª¤
        pipeline_steps = ["extract", "transform", "validate", "load"]
        
        pipeline_results = {}
        
        for step in pipeline_steps:
            pipeline_results[step] = []
            
            def create_pipeline_handler(step_name):
                def handler(payload):
                    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†æ—¶é—´
                    processing_time = {
                        "extract": 0.1,
                        "transform": 0.2, 
                        "validate": 0.05,
                        "load": 0.3
                    }.get(step_name, 0.1)
                    
                    pipeline_results[step_name].append(payload)
                    collector.record_message_completed(step_name, processing_time=processing_time)
                    
                    return {"processed": True, "step": step_name, "time": processing_time}
                return handler
            
            queue.register_handler(step, create_pipeline_handler(step))
        
        # åˆ›å»ºæ•°æ®æ‰¹æ¬¡
        batch_data = {
            "batch_id": "BATCH_001",
            "records": [
                {"id": 1, "name": "Record 1"},
                {"id": 2, "name": "Record 2"},
                {"id": 3, "name": "Record 3"}
            ]
        }
        
        # å¤„ç†æ•°æ®æ‰¹æ¬¡
        for step in pipeline_steps:
            message = Message(
                topic=step,
                payload={**batch_data, "step": step}
            )
            
            collector.record_message_produced(step)
            
            assert message.topic == step
            assert message.payload["batch_id"] == "BATCH_001"
            assert len(message.payload["records"]) == 3
    
    @pytest.mark.asyncio
    async def test_microservices_communication_scenario(self):
        """æµ‹è¯•å¾®æœåŠ¡é€šä¿¡åœºæ™¯"""
        config = MQConfig()
        queue = RedisMessageQueue(config)
        
        # å¾®æœåŠ¡åˆ—è¡¨
        services = ["user_service", "order_service", "payment_service", "inventory_service"]
        
        service_communications = {}
        
        for service in services:
            service_communications[service] = []
            
            def create_service_handler(service_name):
                def handler(payload):
                    service_communications[service_name].append(payload)
                    return {
                        "service": service_name,
                        "processed": True,
                        "timestamp": time.time()
                    }
                return handler
            
            queue.register_handler(service, create_service_handler(service))
        
        # æ¨¡æ‹ŸæœåŠ¡é—´é€šä¿¡
        communication_scenarios = [
            {
                "from": "user_service",
                "to": "order_service", 
                "event": "user_created",
                "data": {"user_id": "USER_001", "email": "user@example.com"}
            },
            {
                "from": "order_service",
                "to": "payment_service",
                "event": "payment_required", 
                "data": {"order_id": "ORDER_001", "amount": 99.99}
            },
            {
                "from": "order_service",
                "to": "inventory_service",
                "event": "inventory_check",
                "data": {"order_id": "ORDER_001", "items": [{"sku": "ITEM_001", "qty": 1}]}
            }
        ]
        
        for scenario in communication_scenarios:
            message = Message(
                topic=scenario["to"],
                payload={
                    "event": scenario["event"],
                    "from_service": scenario["from"],
                    "data": scenario["data"]
                }
            )
            
            assert message.topic == scenario["to"]
            assert message.payload["event"] == scenario["event"]
            assert message.payload["from_service"] == scenario["from"]