"""
è°ƒåº¦æœåŠ¡æ¨¡å—
è´Ÿè´£å»¶æ—¶æ¶ˆæ¯å¤„ç†ã€è¿‡æœŸæ¶ˆæ¯ç›‘æ§ã€processingé˜Ÿåˆ—ç›‘æ§å’Œç³»ç»Ÿç›‘æ§
"""

import asyncio
import json
import time
from typing import Any

from loguru import logger
from redis.commands.core import AsyncScript

from ..constants import GlobalKeys, TopicKeys
from ..message import Message
from .context import QueueContext
from .lifecycle import MessageLifecycleService


class ScheduleService:
    """ç»Ÿä¸€çš„è°ƒåº¦æœåŠ¡ç±»ï¼ˆå·²ä¼˜åŒ–å»¶æ—¶è°ƒåº¦éƒ¨åˆ†ï¼‰"""

    def __init__(self, context: QueueContext) -> None:
        self.context = context
        self.handler_service = MessageLifecycleService(context)

        # --- é‡æ„éƒ¨åˆ†ï¼šçŠ¶æ€ç®¡ç† ---
        self.is_running = False
        # å•ä¸€çš„è°ƒåº¦å¾ªç¯ä»»åŠ¡ï¼Œç”¨äºä¼˜é›…åœ°å¯åŠ¨å’Œåœæ­¢
        self.scheduler_task: asyncio.Task | None = None

        # ä½¿ç”¨Eventè¿›è¡Œé€šçŸ¥ï¼Œæ›¿ä»£Lock
        # ä¸€å¯¹å¤šé€šçŸ¥: ä¸€ä¸ª set() å¯ä»¥å”¤é†’å¤šä¸ªç­‰å¾…çš„åç¨‹
        # çŠ¶æ€æŒä¹…: äº‹ä»¶ä¸€æ—¦è®¾ç½®ï¼Œåç»­çš„ wait() ä¼šç«‹å³è¿”å›
        # å¯é‡ç½®: é€šè¿‡ clear() å¯ä»¥é‡æ–°ä½¿ç”¨åŒä¸€ä¸ªäº‹ä»¶å¯¹è±¡
        self.notification_event = asyncio.Event()

    async def process_delay_messages(self) -> None:
        """å»¶æ—¶æ¶ˆæ¯å¤„ç†åç¨‹"""
        if self.is_running:
            logger.debug("å»¶æ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœ¨è¿è¡Œ")
            return

        self.is_running = True
        logger.debug("å¯åŠ¨å»¶æ—¶ä»»åŠ¡è°ƒåº¦å™¨")

        # å°†ä¸»è°ƒåº¦é€»è¾‘å°è£…åœ¨ä¸€ä¸ªä»»åŠ¡ä¸­ï¼Œæ–¹ä¾¿ç®¡ç†
        self.scheduler_task = asyncio.create_task(self.delay_scheduler_loop())

        # å¯åŠ¨å…¶ä»–è¾…åŠ©ä»»åŠ¡
        await asyncio.gather(
            self.scheduler_task,
            self.pubsub_listener(),
            self.periodic_fallback(),
            return_exceptions=True,
        )

    async def stop_delay_processing(self) -> None:
        """ä¼˜é›…åœ°åœæ­¢å»¶æ—¶æ¶ˆæ¯å¤„ç†"""
        # è¿è¡ŒçŠ¶æ€æ£€æŸ¥ï¼Œå¦‚æœæœªè¿è¡Œåˆ™ç›´æ¥è¿”å›
        if not self.is_running:
            logger.debug("å»¶æ—¶ä»»åŠ¡è°ƒåº¦å™¨æœªè¿è¡Œï¼Œæ— éœ€åœæ­¢")
            return

        self.is_running = False
        logger.info("å¼€å§‹åœæ­¢å»¶æ—¶ä»»åŠ¡è°ƒåº¦å™¨...")

        try:
            # è®¾ç½®äº‹ä»¶ï¼Œç¡®ä¿å¦‚æœè°ƒåº¦å™¨æ­£åœ¨ç­‰å¾…ä¸­ï¼Œèƒ½è¢«ç«‹å³å”¤é†’å¹¶æ£€æŸ¥åˆ° is_running == False
            self.notification_event.set()

            # å–æ¶ˆä¸»è°ƒåº¦ä»»åŠ¡
            if self.scheduler_task and not self.scheduler_task.done():
                self.scheduler_task.cancel()

            # ç­‰å¾…ä»»åŠ¡å®Œæˆå–æ¶ˆï¼Œæ·»åŠ 5ç§’è¶…æ—¶ä¿æŠ¤
            if self.scheduler_task:
                try:
                    await asyncio.wait_for(self.scheduler_task, timeout=5.0)
                except asyncio.TimeoutError:
                    logger.error("åœæ­¢å»¶æ—¶ä»»åŠ¡è°ƒåº¦å™¨è¶…æ—¶ï¼Œå¼ºåˆ¶ç»“æŸ")
                    # å¦‚æœè¶…æ—¶ï¼Œç¡®ä¿ä»»åŠ¡è¢«å–æ¶ˆ
                    if not self.scheduler_task.done():
                        self.scheduler_task.cancel()
                except asyncio.CancelledError:
                    pass  # é¢„æœŸå†…çš„å¼‚å¸¸
                except Exception as e:
                    logger.exception(f"åœæ­¢å»¶æ—¶ä»»åŠ¡è°ƒåº¦å™¨æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

            logger.debug("å»¶æ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
        except Exception as e:
            logger.exception(f"åœæ­¢å»¶æ—¶ä»»åŠ¡è°ƒåº¦å™¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            # ç¡®ä¿ scheduler_task è¢«é‡ç½®ä¸º None
            self.scheduler_task = None

    async def delay_scheduler_loop(self) -> None:
        """
        æ ¸å¿ƒè°ƒåº¦å¾ªç¯ï¼ˆçŠ¶æ€æœºï¼‰ã€‚
        è¿™æ˜¯æ•´ä¸ªä¼˜åŒ–çš„æ ¸å¿ƒï¼Œå®ƒå–ä»£äº†æ—§çš„ timer_lock å’Œ current_timer_task ç®¡ç†ã€‚
        """
        logger.debug("å»¶æ—¶è°ƒåº¦ä¸»å¾ªç¯å·²å¯åŠ¨")

        # é¦–æ¬¡å¯åŠ¨æ—¶ï¼ŒçŸ­æš‚å»¶æ—¶åç«‹å³è§¦å‘ä¸€æ¬¡è°ƒåº¦æ£€æŸ¥
        await asyncio.sleep(0.2)
        logger.debug("è¿›ç¨‹å¯åŠ¨ï¼Œåˆå§‹åŒ–å»¶æ—¶ä»»åŠ¡è°ƒåº¦")

        while self.is_running:
            # åœ¨å¾ªç¯å¼€å§‹æ—¶æ·»åŠ  is_running çŠ¶æ€æ£€æŸ¥
            if not self.is_running:
                break

            try:
                # 1. ä»Redisè·å–ä¸‹ä¸€ä¸ªä»»åŠ¡ä¿¡æ¯å’Œç­‰å¾…æ—¶é—´
                start_time = time.time()
                lua_script: AsyncScript = self.context.lua_scripts[
                    "get_next_delay_task"
                ]
                delay_tasks_key = self.context.get_global_key(GlobalKeys.DELAY_TASKS)
                result = await lua_script(keys=[delay_tasks_key], args=[])
                status = result[0]
                end_time = time.time()
                # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šè°ƒè¯• Lua è„šæœ¬è¿”å›å€¼ ä¿ç•™ 3 ä½å°æ•°
                logger.debug(
                    f"get_next_delay_task æ‰«æå»¶æ—¶é˜Ÿåˆ—ã€{delay_tasks_key}ã€‘ è€—æ—¶: {end_time - start_time:.3f} ç§’,è¿”å›: {result}"
                )

                wait_milliseconds: float | None = None

                # 2. æ ¹æ®çŠ¶æ€å†³å®šä¸‹ä¸€æ­¥æ“ä½œ
                if status == "NO_TASK":
                    logger.debug("å½“å‰æ— å»¶æ—¶ä»»åŠ¡ï¼Œç­‰å¾…æ–°ä»»åŠ¡é€šçŸ¥...")
                    wait_milliseconds = None  # æ— é™æœŸç­‰å¾…
                elif status == "EXPIRED":
                    logger.info(f"å‘ç°è¿‡æœŸä»»åŠ¡ {result[2]}ï¼Œç«‹å³å¤„ç†")
                    await self.try_process_expired_tasks()
                    continue  # å¤„ç†å®Œåï¼Œç«‹å³å¼€å§‹ä¸‹ä¸€æ¬¡å¾ªç¯æ£€æŸ¥
                elif status == "WAITING":
                    wait_milliseconds = int(result[1])

                    # ğŸ›¡ï¸ è¾¹ç•Œä¿æŠ¤ï¼šå¦‚æœç­‰å¾…æ—¶é—´å¾ˆå°ï¼Œæ·»åŠ å°å»¶è¿Ÿé¿å…æ—¶é—´ç«äº‰
                    if wait_milliseconds < 10:  # å°äº10æ¯«ç§’
                        logger.debug(
                            f"ä»»åŠ¡ {result[3]} ç­‰å¾…æ—¶é—´å¾ˆçŸ­ ({wait_milliseconds}æ¯«ç§’)ï¼Œæ·»åŠ ç¼“å†²å»¶è¿Ÿé¿å…æ—¶é—´ç«äº‰"
                        )
                        await asyncio.sleep(0.01)  # ç­‰å¾…10æ¯«ç§’è®©æ—¶é—´å®Œå…¨è¿‡æœŸ
                        await self.try_process_expired_tasks()
                        continue

                    logger.debug(
                        f"ä¸‹ä¸€ä¸ªä»»åŠ¡ {result[3]}å°†åœ¨ {wait_milliseconds} æ¯«ç§’ååˆ°æœŸï¼Œå¼€å§‹ç­‰å¾…..."
                    )

                # 3. ç­‰å¾…ï¼šè¦ä¹ˆè¶…æ—¶ï¼Œè¦ä¹ˆè¢«å¤–éƒ¨äº‹ä»¶å”¤é†’
                try:
                    # æ¸…é™¤æ—§ä¿¡å·ï¼Œå‡†å¤‡æ¥æ”¶æ–°ä¿¡å·
                    self.notification_event.clear()
                    # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†æ¯«ç§’è½¬æ¢ä¸ºç§’æ•°
                    wait_seconds = (
                        wait_milliseconds / 1000.0
                        if wait_milliseconds is not None
                        else None
                    )

                    # ä¸ºé•¿æ—¶é—´ç­‰å¾…ï¼ˆ>5ç§’ï¼‰å®ç°åˆ†æ®µç­‰å¾…æœºåˆ¶
                    if wait_seconds is not None and wait_seconds > 5.0:
                        # åˆ†æ®µç­‰å¾…ï¼Œæ¯5ç§’æ£€æŸ¥ä¸€æ¬¡åœæ­¢çŠ¶æ€
                        remaining_time = wait_seconds
                        while remaining_time > 0 and self.is_running:
                            segment_wait = min(5.0, remaining_time)
                            try:
                                await asyncio.wait_for(
                                    self.notification_event.wait(), timeout=segment_wait
                                )
                                # å¦‚æœæ”¶åˆ°é€šçŸ¥ï¼Œè·³å‡ºåˆ†æ®µç­‰å¾…
                                break
                            except asyncio.TimeoutError:
                                # åˆ†æ®µè¶…æ—¶ï¼Œç»§ç»­ç­‰å¾…å‰©ä½™æ—¶é—´
                                remaining_time -= segment_wait
                                if not self.is_running:
                                    break

                        # å¦‚æœæ˜¯å› ä¸ºåœæ­¢çŠ¶æ€é€€å‡ºï¼ŒæŠ›å‡º CancelledError
                        if not self.is_running:
                            raise asyncio.CancelledError("è°ƒåº¦å™¨å·²åœæ­¢")
                    else:
                        # çŸ­æ—¶é—´ç­‰å¾…ï¼Œç›´æ¥ç­‰å¾…
                        # åœ¨è¿™é‡Œå¢åŠ å¯¹ is_running çš„æ£€æŸ¥ï¼Œç¡®ä¿åœ¨åœæ­¢æ—¶èƒ½å¿«é€Ÿé€€å‡º
                        if self.is_running:
                            await asyncio.wait_for(
                                self.notification_event.wait(), timeout=wait_seconds
                            )
                        else:
                            # å¦‚æœå·²ç»åœæ­¢è¿è¡Œï¼Œç›´æ¥æŠ›å‡º CancelledError
                            raise asyncio.CancelledError("è°ƒåº¦å™¨å·²åœæ­¢")

                    # å¦‚æœä»£ç æ‰§è¡Œåˆ°è¿™é‡Œï¼Œè¯´æ˜æ˜¯ notification_event è¢«è§¦å‘äº† ã€å…œåº• æˆ–è€… pub/sub é€šçŸ¥ã€‘
                    logger.debug("æ”¶åˆ°å¤–éƒ¨é€šçŸ¥ï¼Œé‡æ–°è¯„ä¼°è°ƒåº¦è®¡åˆ’...")
                    # ç›´æ¥è¿›å…¥ä¸‹ä¸€æ¬¡ while å¾ªç¯ï¼Œé‡æ–°ä» Redis è·å–æœ€æ–°ç­‰å¾…æ—¶é—´

                except asyncio.TimeoutError:
                    # å¦‚æœä»£ç æ‰§è¡Œåˆ°è¿™é‡Œï¼Œè¯´æ˜æ˜¯ wait_for è¶…æ—¶äº†ï¼Œå®šæ—¶å™¨è‡ªç„¶åˆ°æœŸ
                    logger.debug("å®šæ—¶å™¨åˆ°æœŸï¼Œå¼€å§‹å¤„ç†è¿‡æœŸä»»åŠ¡...")
                    await self.try_process_expired_tasks()
                    # å¤„ç†å®Œåï¼Œä¼šè‡ªåŠ¨è¿›å…¥ä¸‹ä¸€æ¬¡ while å¾ªç¯

            except asyncio.CancelledError:
                logger.warning("è°ƒåº¦ä¸»å¾ªç¯è¢«å–æ¶ˆï¼Œæ­£åœ¨é€€å‡º...")
                break  # é€€å‡ºå¾ªç¯
            except Exception as e:
                # åœ¨å¼‚å¸¸å¤„ç†ä¸­æ·»åŠ  is_running çŠ¶æ€æ£€æŸ¥
                if self.is_running:
                    logger.exception("è°ƒåº¦ä¸»å¾ªç¯å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œæš‚åœåé‡è¯•")
                    await asyncio.sleep(
                        1
                    )  # å‘ç”ŸæœªçŸ¥é”™è¯¯æ—¶ï¼ŒçŸ­æš‚ç­‰å¾…é˜²æ­¢CPUå ç”¨è¿‡é«˜ï¼ˆä¼˜åŒ–ï¼šå‡å°‘ç­‰å¾…æ—¶é—´ï¼‰
                else:
                    # å¦‚æœå·²ç»åœæ­¢ï¼Œä¸è®°å½•é”™è¯¯æ—¥å¿—ï¼Œç›´æ¥é€€å‡º
                    break

        logger.warning("å»¶æ—¶è°ƒåº¦ä¸»å¾ªç¯å·²é€€å‡º")

    async def pubsub_listener(self) -> None:
        """ç›‘å¬pubsubé€šé“"""
        retry_delay = 1
        pubsub = None
        consecutive_failures = 0
        max_consecutive_failures = 5

        while self.is_running:
            try:
                # åˆ›å»ºæ–°çš„pubsubè¿æ¥
                if pubsub is None:
                    pubsub = self.context.redis.pubsub()
                    channel = self.context.get_global_key(
                        GlobalKeys.DELAY_PUBSUB_CHANNEL
                    )
                    await pubsub.subscribe(channel)
                    logger.info(f"å¼€å§‹ç›‘å¬å»¶æ—¶ä»»åŠ¡é€šçŸ¥, channel={channel}")
                    retry_delay = 1  # é‡ç½®é‡è¯•å»¶è¿Ÿ
                    consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°

                # æ·»åŠ è¿æ¥çŠ¶æ€æ£€æŸ¥
                last_ping = asyncio.get_event_loop().time()
                ping_interval = 30  # 30ç§’pingä¸€æ¬¡æ£€æŸ¥è¿æ¥çŠ¶æ€

                async for message in pubsub.listen():
                    if not self.is_running:
                        break

                    # å®šæœŸpingæ£€æŸ¥è¿æ¥çŠ¶æ€
                    current_time = asyncio.get_event_loop().time()
                    if current_time - last_ping > ping_interval:
                        try:
                            await self.context.redis.ping()
                            last_ping = current_time
                        except Exception as ping_error:
                            logger.exception("Redisè¿æ¥æ£€æŸ¥å¤±è´¥")
                            raise ping_error

                    if message["type"] == "message":
                        try:
                            notified_time = int(message["data"])
                            logger.debug(f"æ”¶åˆ°å»¶æ—¶ä»»åŠ¡é€šçŸ¥: {notified_time}")

                            # --- æ ¸å¿ƒæ”¹å˜ï¼šåªè®¾ç½®äº‹ä»¶ï¼Œä¸å¤„ç†ä»»ä½•å¤æ‚é€»è¾‘ ---
                            self.notification_event.set()

                        except Exception as e:
                            logger.exception("å¤„ç†å»¶æ—¶é€šçŸ¥é”™è¯¯")

            except Exception as e:
                consecutive_failures += 1
                logger.exception(
                    f"Pubsubç›‘å¬å™¨é”™è¯¯, consecutive_failures={consecutive_failures}"
                )

                # æ¸…ç†æŸåçš„è¿æ¥
                if pubsub:
                    try:
                        await pubsub.close()
                    except Exception:
                        pass
                    pubsub = None

                # å¦‚æœç³»ç»Ÿæ­£åœ¨å…³é—­ï¼Œç›´æ¥é€€å‡º
                if not self.is_running:
                    break

                # å¦‚æœè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œå¢åŠ ç­‰å¾…æ—¶é—´
                if consecutive_failures >= max_consecutive_failures:
                    retry_delay = min(retry_delay * 2, 60)
                    logger.warning(
                        f"Pubsubè¿ç»­å¤±è´¥è¿‡å¤šï¼Œå»¶é•¿é‡è¿é—´éš”, consecutive_failures={consecutive_failures}, retry_delay={retry_delay}"
                    )
                else:
                    # å¿«é€Ÿé‡è¿
                    retry_delay = min(retry_delay * 1.5, 10)

                logger.warning(
                    f"Pubsubè¿æ¥æ–­å¼€ï¼Œç­‰å¾…é‡è¿, retry_delay={retry_delay}, consecutive_failures={consecutive_failures}"
                )

                # å°†é•¿æ—¶é—´ç­‰å¾…åˆ†è§£ä¸ºå°æ®µï¼Œæ¯0.1ç§’æ£€æŸ¥ä¸€æ¬¡åœæ­¢çŠ¶æ€
                remaining_delay = retry_delay
                while remaining_delay > 0 and self.is_running:
                    sleep_time = min(0.1, remaining_delay)
                    await asyncio.sleep(sleep_time)
                    remaining_delay -= sleep_time

        # ç¡®ä¿èµ„æºæ¸…ç†
        if pubsub:
            try:
                await pubsub.close()
                logger.info("Pubsubè¿æ¥å·²å…³é—­")
            except Exception as e:
                logger.exception("å…³é—­Pubsubè¿æ¥å¤±è´¥")

        logger.info("pubsub_listener close!")

    async def periodic_fallback(self) -> None:
        """å®šæœŸå…œåº•æ£€æŸ¥ï¼Œé˜²æ­¢pubsubæ¶ˆæ¯ä¸¢å¤±"""
        while self.is_running:
            await asyncio.sleep(self.context.config.delay_fallback_interval)
            try:
                logger.debug("æ‰§è¡Œå…œåº•æ£€æŸ¥ï¼Œè§¦å‘ä¸€æ¬¡è°ƒåº¦è¯„ä¼°")
                # åŒæ ·ï¼Œåªæ˜¯ç®€å•åœ°è®¾ç½®äº‹ä»¶
                self.notification_event.set()
            except Exception as e:
                logger.exception("å…œåº•æ£€æŸ¥æ‰§è¡Œå¤±è´¥")
        logger.info("periodic_fallback close!")

    async def try_process_expired_tasks(self) -> None:
        """å°è¯•å¤„ç†è¿‡æœŸä»»åŠ¡"""
        try:
            lua_script: AsyncScript = self.context.lua_scripts["process_delay"]
            delay_tasks_key = self.context.get_global_key(GlobalKeys.DELAY_TASKS)
            payload_map_key = self.context.get_global_key(GlobalKeys.PAYLOAD_MAP)
            batch_size = str(self.context.config.batch_size)  # Luaè„šæœ¬è¦æ±‚å­—ç¬¦ä¸²å‚æ•°
            result = await lua_script(
                keys=[delay_tasks_key, payload_map_key], args=[batch_size]
            )
            if result:
                logger.info(f"å¤„ç†å»¶æ—¶ä»»åŠ¡æˆåŠŸ, result={result}")
        except Exception as e:
            logger.exception("å¤„ç†å»¶æ—¶ä»»åŠ¡å¤±è´¥")

    async def monitor_expired_messages(self) -> None:
        """ç›‘æ§è¿‡æœŸæ¶ˆæ¯"""
        while self.context.is_running():
            try:
                current_time = int(time.time() * 1000)

                lua_script: AsyncScript = self.context.lua_scripts["handle_timeout"]
                expired_results = await lua_script(
                    # è¿™é‡Œ keys éƒ½æ˜¯ redis ä¸­çš„é”®åç§°
                    keys=[
                        self.context.get_global_key(GlobalKeys.EXPIRE_MONITOR),
                        self.context.get_global_key(GlobalKeys.PAYLOAD_MAP),
                    ],
                    args=[current_time, self.context.config.batch_size],
                )

                for msg_id, payload_json, queue_name in expired_results:
                    try:
                        message = Message.model_validate_json(payload_json)

                        await self.handler_service.handle_expired_message(
                            message, queue_name
                        )

                        logger.info(
                            f"è¿‡æœŸæ¶ˆæ¯å¤„ç†, message_id={msg_id}, queue_name={queue_name}, expire_reason=timeout"
                        )
                    except Exception as e:
                        logger.exception(f"å¤„ç†è¿‡æœŸæ¶ˆæ¯å¤±è´¥, message_id={msg_id}")

            except Exception as e:
                logger.exception("è¿‡æœŸæ¶ˆæ¯ç›‘æ§é”™è¯¯")

            await asyncio.sleep(self.context.config.expired_check_interval)

    async def monitor_processing_queues(self) -> None:
        """ç›‘æ§processingé˜Ÿåˆ—"""
        logger.info("Processingé˜Ÿåˆ—ç›‘æ§å¯åŠ¨")
        
        while self.context.is_running():
            try:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                if self.context.shutting_down or self.context.shutdown_event.is_set():
                    logger.info("æ£€æµ‹åˆ°åœæœºä¿¡å·ï¼Œåœæ­¢Processingé˜Ÿåˆ—ç›‘æ§")
                    break
                    
                # æ·»åŠ Redisè¿æ¥æ£€æŸ¥
                if not hasattr(self.context, 'redis') or self.context.redis is None:
                    logger.warning("Redisè¿æ¥ä¸å¯ç”¨ï¼Œåœæ­¢ç›‘æ§")
                    break
                
                for topic in self.context.handlers.keys():
                    # æ¯ä¸ªtopicå¤„ç†å‰å†æ¬¡æ£€æŸ¥åœæœºçŠ¶æ€
                    if self.context.shutting_down or self.context.shutdown_event.is_set():
                        logger.info("æ£€æµ‹åˆ°åœæœºä¿¡å·ï¼Œä¸­æ–­topicç›‘æ§å¾ªç¯")
                        break
                    
                    await self._monitor_single_topic(topic)
                    await asyncio.sleep(1)

                # ä¼‘æ¯ä¸€ç‚¹æ—¶é—´
                await asyncio.sleep(self.context.config.processing_monitor_interval)

            except Exception:
                # å¦‚æœæ˜¯è¿æ¥ç›¸å…³é”™è¯¯ä¸”æ­£åœ¨å…³é—­ï¼Œåˆ™ä¼˜é›…é€€å‡º
                if self.context.shutting_down or self.context.shutdown_event.is_set():
                    logger.info("åœæœºè¿‡ç¨‹ä¸­çš„ç›‘æ§é”™è¯¯ï¼Œåœæ­¢Processingé˜Ÿåˆ—ç›‘æ§")
                    break
                logger.exception("Processingé˜Ÿåˆ—ç›‘æ§é”™è¯¯")
                await asyncio.sleep(30)
        
        logger.info("Processingé˜Ÿåˆ—ç›‘æ§å·²åœæ­¢")

    ##### ç§æœ‰æ–¹æ³• #### 

    async def _monitor_single_topic(self, topic: str) -> None:
        """ç›‘æ§ã€æ£€æŸ¥ å•ä¸ªä¸»é¢˜çš„processingé˜Ÿåˆ—"""
        # æ·»åŠ è¿æ¥æ£€æŸ¥
        if self.context.shutting_down or self.context.shutdown_event.is_set():
            return
            
        if not self.context.redis:
            logger.warning(f"Redisè¿æ¥ä¸å¯ç”¨ï¼Œè·³è¿‡topicç›‘æ§: {topic}")
            return
        
        try:
            processing_key = self.context.get_global_topic_key(topic, TopicKeys.PROCESSING)

            # è·å–processingé˜Ÿåˆ—ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
            processing_ids = await self.context.redis.lrange(processing_key, 0, -1)  # type: ignore

            # åˆå§‹åŒ–è¯¥topicçš„è·Ÿè¸ªå™¨
            if topic not in self.context.stuck_messages_tracker:
                self.context.stuck_messages_tracker[topic] = {}

            current_tracker = self.context.stuck_messages_tracker[topic]
            
            # æ›´æ–°è·Ÿè¸ªçŠ¶æ€
            current_ids_set = set(processing_ids)
            self._update_message_tracking(current_tracker, processing_ids, current_ids_set)

            # æ£€æŸ¥å¹¶å¤„ç†å¡æ­»çš„æ¶ˆæ¯
            stuck_messages = self._identify_stuck_messages(current_tracker)
            if stuck_messages:
                await self._handle_stuck_messages(
                    stuck_messages, topic, processing_key, current_tracker
                )
        except (ConnectionError, TimeoutError):
            if self.context.shutting_down or self.context.shutdown_event.is_set():
                logger.debug(f"åœæœºè¿‡ç¨‹ä¸­çš„è¿æ¥é”™è¯¯ï¼Œè·³è¿‡topicç›‘æ§: {topic}")
                return
            raise
        except Exception:
            if self.context.shutting_down or self.context.shutdown_event.is_set():
                logger.debug(f"åœæœºè¿‡ç¨‹ä¸­çš„ç›‘æ§é”™è¯¯ï¼Œè·³è¿‡topicç›‘æ§: {topic}")
                return
            raise

    def _update_message_tracking(
        self, tracker: dict[str, int], processing_ids: list, current_ids_set: set
    ) -> None:
        """æ›´æ–°æ¶ˆæ¯è·Ÿè¸ªçŠ¶æ€"""
        # æ›´æ–°è¿ç»­æ£€æµ‹è®¡æ•°
        for msg_id in processing_ids:
            if msg_id in tracker:
                # tracker çš„æ•°æ®æ ¼å¼ä¸º keyä¸ºæ¶ˆæ¯ id -value ä¸ºtimes
                tracker[msg_id] += 1
            else:
                tracker[msg_id] = 1

        # æ¸…ç†å·²ç»ä¸åœ¨processingé˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯ID
        ids_to_remove = [
            msg_id for msg_id in tracker.keys() if msg_id not in current_ids_set
        ]
        for msg_id in ids_to_remove:
            del tracker[msg_id]

    def _identify_stuck_messages(self, tracker: dict[str, int]) -> list[str]:
        """è¯†åˆ«å¡æ­»çš„æ¶ˆæ¯"""
        return [msg_id for msg_id, count in tracker.items() if count >= 3]

    async def _handle_stuck_messages(
        self,
        stuck_messages: list[str],
        topic: str,
        processing_key: str,
        tracker: dict[str, int],
    ) -> None:
        """å¤„ç†å¡æ­»çš„æ¶ˆæ¯åˆ—è¡¨"""
        logger.warning(
            f"å‘ç°å¡æ­»æ¶ˆæ¯, topic={topic}, count={len(stuck_messages)}, stuck_messages={stuck_messages}"
        )

        for msg_id in stuck_messages:
            try:
                await self.handler_service.handle_stuck_message(
                    msg_id, topic, processing_key
                )
                if msg_id in tracker:
                    del tracker[msg_id]
            except Exception as e:
                logger.exception(
                    f"å¤„ç†å¡æ­»æ¶ˆæ¯å¤±è´¥, message_id={msg_id}, topic={topic}"
                )

    async def system_monitor(self) -> None:
        """ç³»ç»Ÿç›‘æ§åç¨‹"""
        while self.context.is_running():
            try:
                metrics = await self._collect_metrics()

                for metric_name, value in metrics.items():
                    logger.debug(f"metric: {metric_name}={value}")

                await self._check_alerts(metrics)

            except Exception as e:
                logger.exception("ç³»ç»Ÿç›‘æ§é”™è¯¯")

            await asyncio.sleep(self.context.config.monitor_interval)

    async def _collect_metrics(self) -> dict[str, Any]:
        """
            æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
            æ”¶é›†çš„ä»…ä»…æ—¶è‡ªå·±æ³¨å†Œçš„å¤„ç†å™¨ï¼Œä¸åŒ…å«æœªæ³¨å†Œçš„
        """
        metrics = {}

        try:
            pipe = self.context.redis.pipeline()  # type: ignore

            topic_pending = {}
            topic_processing = {}
            for topic in self.context.handlers.keys():
                topic_pending[topic] = pipe.llen(
                    self.context.get_global_topic_key(topic, TopicKeys.PENDING)
                )
                topic_processing[topic] = pipe.llen(
                    self.context.get_global_topic_key(topic, TopicKeys.PROCESSING)
                )

            pipe.zcard(self.context.get_global_key(GlobalKeys.DELAY_TASKS))
            pipe.zcard(self.context.get_global_key(GlobalKeys.EXPIRE_MONITOR))
            pipe.hlen(self.context.get_global_key(GlobalKeys.PAYLOAD_MAP))
            pipe.llen(self.context.get_global_key(GlobalKeys.DLQ_QUEUE))

            results = await pipe.execute()

            # Parse results
            result_idx = 0
            for topic in self.context.handlers.keys():
                metrics[f"{topic}.pending"] = results[result_idx]
                result_idx += 1
                metrics[f"{topic}.processing"] = results[result_idx]
                result_idx += 1

            metrics[f"{GlobalKeys.DELAY_TASKS.value}.count"] = results[result_idx]
            result_idx += 1
            metrics[f"{GlobalKeys.EXPIRE_MONITOR.value}.count"] = results[result_idx]
            result_idx += 1
            metrics[f"{GlobalKeys.PAYLOAD_MAP.value}.count"] = results[result_idx]
            result_idx += 1
            metrics[f"{GlobalKeys.DLQ_QUEUE.value}.count"] = results[result_idx]

        except Exception as e:
            logger.exception("æ”¶é›†æŒ‡æ ‡å¤±è´¥")

        return metrics

    async def _check_alerts(self, metrics: dict[str, Any]) -> None:
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        try:
            for topic in self.context.handlers.keys():
                processing_count = metrics.get(f"{topic}.processing", 0)
                if processing_count > self.context.config.max_workers * 2:
                    logger.warning(
                        f"Processingé˜Ÿåˆ—è¿‡é•¿, topic={topic}, count={processing_count}, threshold={self.context.config.max_workers * 2}"
                    )
        except Exception as e:
            logger.exception("å‘Šè­¦æ£€æŸ¥å¤±è´¥")
