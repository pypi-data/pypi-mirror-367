{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogStructor Performance Comparison\n",
    "\n",
    "Quick benchmarks showing LogStructor's performance characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import logstructor\n",
    "import io\n",
    "import sys\n",
    "\n",
    "def setup_standard_logger():\n",
    "    logger = logging.getLogger(\"standard_bench\")\n",
    "    logger.handlers = [logging.StreamHandler(io.StringIO())]\n",
    "    logger.setLevel(logging.INFO)\n",
    "    return logger\n",
    "\n",
    "def setup_struct_logger():\n",
    "    logger = logstructor.getLogger(\"struct_bench\")\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 1: Simple Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_simple(iterations=10000):\n",
    "    # Standard logging\n",
    "    std_logger = setup_standard_logger()\n",
    "    start = time.perf_counter()\n",
    "    for i in range(iterations):\n",
    "        std_logger.info(\"Simple message\")\n",
    "    std_time = time.perf_counter() - start\n",
    "    \n",
    "    # LogStructor\n",
    "    struct_logger = setup_struct_logger()\n",
    "    start = time.perf_counter()\n",
    "    for i in range(iterations):\n",
    "        struct_logger.info(\"Simple message\")\n",
    "    struct_time = time.perf_counter() - start\n",
    "    \n",
    "    overhead = ((struct_time - std_time) / std_time) * 100\n",
    "    \n",
    "    print(f\"Simple Messages ({iterations:,} iterations):\")\n",
    "    print(f\"  Standard: {std_time:.4f}s ({iterations/std_time:,.0f} msg/sec)\")\n",
    "    print(f\"  LogStructor: {struct_time:.4f}s ({iterations/struct_time:,.0f} msg/sec)\")\n",
    "    print(f\"  Overhead: {overhead:+.1f}%\")\n",
    "    \n",
    "    return overhead\n",
    "\n",
    "simple_overhead = benchmark_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 2: Structured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_structured(iterations=10000):\n",
    "    # Standard with f-strings\n",
    "    std_logger = setup_standard_logger()\n",
    "    start = time.perf_counter()\n",
    "    for i in range(iterations):\n",
    "        std_logger.info(f\"User {123} performed action login from 192.168.1.100\")\n",
    "    std_time = time.perf_counter() - start\n",
    "    \n",
    "    # LogStructor with structured fields\n",
    "    struct_logger = setup_struct_logger()\n",
    "    start = time.perf_counter()\n",
    "    for i in range(iterations):\n",
    "        struct_logger.info(\"User performed action\", user_id=123, action=\"login\", ip=\"192.168.1.100\")\n",
    "    struct_time = time.perf_counter() - start\n",
    "    \n",
    "    overhead = ((struct_time - std_time) / std_time) * 100\n",
    "    \n",
    "    print(f\"\\nStructured Data ({iterations:,} iterations):\")\n",
    "    print(f\"  Standard (f-string): {std_time:.4f}s ({iterations/std_time:,.0f} msg/sec)\")\n",
    "    print(f\"  LogStructor (JSON): {struct_time:.4f}s ({iterations/struct_time:,.0f} msg/sec)\")\n",
    "    print(f\"  Overhead: {overhead:+.1f}%\")\n",
    "    \n",
    "    return overhead\n",
    "\n",
    "structured_overhead = benchmark_structured()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 3: Context Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_context(iterations=10000):\n",
    "    # Without context\n",
    "    struct_logger = setup_struct_logger()\n",
    "    start = time.perf_counter()\n",
    "    for i in range(iterations):\n",
    "        struct_logger.info(\"Message\", iteration=i)\n",
    "    no_context_time = time.perf_counter() - start\n",
    "    \n",
    "    # With context\n",
    "    logstructor.bind_context(request_id=\"req-123\", user_id=456)\n",
    "    start = time.perf_counter()\n",
    "    for i in range(iterations):\n",
    "        struct_logger.info(\"Message\", iteration=i)\n",
    "    with_context_time = time.perf_counter() - start\n",
    "    logstructor.clear_context()\n",
    "    \n",
    "    context_overhead = ((with_context_time - no_context_time) / no_context_time) * 100\n",
    "    \n",
    "    print(f\"\\nContext Management ({iterations:,} iterations):\")\n",
    "    print(f\"  Without context: {no_context_time:.4f}s ({iterations/no_context_time:,.0f} msg/sec)\")\n",
    "    print(f\"  With context: {with_context_time:.4f}s ({iterations/with_context_time:,.0f} msg/sec)\")\n",
    "    print(f\"  Context overhead: {context_overhead:+.1f}%\")\n",
    "    \n",
    "    return context_overhead\n",
    "\n",
    "context_overhead = benchmark_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "avg_overhead = statistics.mean([simple_overhead, structured_overhead])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"           PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nðŸ“Š THROUGHPUT OVERHEAD:\")\n",
    "print(f\"   Simple messages:    {simple_overhead:+.1f}%\")\n",
    "print(f\"   Structured data:    {structured_overhead:+.1f}%\")\n",
    "print(f\"   Context management: {context_overhead:+.1f}%\")\n",
    "print(f\"\\n   ðŸ“ˆ Average overhead: {avg_overhead:+.1f}%\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ VERDICT:\")\n",
    "if avg_overhead < 10:\n",
    "    verdict = \"EXCELLENT - Minimal overhead for massive value\"\n",
    "elif avg_overhead < 20:\n",
    "    verdict = \"GOOD - Reasonable overhead for structured logging\"\n",
    "else:\n",
    "    verdict = \"ACCEPTABLE - Higher overhead but still usable\"\n",
    "\n",
    "print(f\"   {verdict}\")\n",
    "\n",
    "print(f\"\\nâœ… RECOMMENDATIONS:\")\n",
    "print(f\"   â€¢ LogStructor adds ~{avg_overhead:.0f}% overhead on average\")\n",
    "print(f\"   â€¢ Perfect for most applications (< 20% overhead)\")\n",
    "print(f\"   â€¢ The structured data benefits far outweigh the cost\")\n",
    "print(f\"   â€¢ Context management adds minimal extra cost\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
