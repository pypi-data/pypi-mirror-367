import gc
import logging
import os
import resource
import tempfile
import time
from pathlib import Path
from typing import Any
from unittest.mock import MagicMock, patch

import numpy as np
import pandas as pd
import pytest

from petsard.exceptions import ConfigError, UnsupportedMethodError
from petsard.loader.benchmarker import BenchmarkerConfig
from petsard.loader.loader import Loader, LoaderConfig, LoaderFileExt
from petsard.metadater import FieldConfig, SchemaConfig


class TestLoaderConfig:
    """Test cases for LoaderConfig class
    LoaderConfig é¡çš„æ¸¬è©¦æ¡ˆä¾‹
    """

    def test_config_requires_filepath_or_method(self):
        """Test that either filepath or method must be specified
        æ¸¬è©¦å¿…é ˆæŒ‡å®š filepath æˆ– method åƒæ•¸
        """
        with pytest.raises(ConfigError):
            LoaderConfig()

    def test_default_method(self):
        """Test default method configuration
        æ¸¬è©¦é»˜èªæ–¹æ³•é…ç½®
        """
        with patch.object(
            BenchmarkerConfig, "_load_benchmark_config"
        ) as mock_load_config:
            mock_load_config.return_value = {
                "adult-income": {
                    "filename": "adult-income.csv",
                    "access": "public",
                    "region_name": "us-west-2",
                    "bucket_name": "petsard-benchmark",
                    "sha256": "1f13ee2bf9d7c66098429281ab91fa1b51cbabd3b805cc365b3c6b44491ea2c0",
                }
            }

            config = LoaderConfig(method="default")
            # æª¢æŸ¥åˆå§‹ filepath è¢«è¨­ç½®ç‚º benchmark URL
            # Check that initial filepath is set to benchmark URL
            assert config.DEFAULT_METHOD_FILEPATH == "benchmark://adult-income"
            # æª¢æŸ¥ filepath å·²è¢«è™•ç†ç‚ºæœ¬åœ°è·¯å¾‘
            # Check that filepath has been processed to local path
            assert str(config.filepath).endswith("benchmark/adult-income.csv")
            # æª¢æŸ¥ benchmarker_config å·²è¢«è¨­ç½®
            # Check that benchmarker_config is set
            assert config.benchmarker_config is not None
            assert config.benchmarker_config.benchmark_name == "adult-income"

    def test_unsupported_method(self):
        """Test unsupported method raises error
        æ¸¬è©¦ä¸æ”¯æ´çš„æ–¹æ³•æœƒå¼•ç™¼éŒ¯èª¤
        """
        with pytest.raises(UnsupportedMethodError):
            LoaderConfig(method="unsupported_method")

    def test_benchmark_path_parsing(self):
        """Test parsing of benchmark path
        æ¸¬è©¦åŸºæº–è³‡æ–™é›†è·¯å¾‘è§£æ
        """
        with patch.object(
            BenchmarkerConfig, "_load_benchmark_config"
        ) as mock_load_config:
            mock_load_config.return_value = {
                "adult-income": {
                    "filename": "adult.csv",
                    "access": "public",
                    "region_name": "us-west-2",
                    "bucket_name": "test-bucket",
                    "sha256": "test-hash",
                }
            }
            config = LoaderConfig(filepath="benchmark://adult-income")
            assert config.benchmarker_config is not None
            assert config.benchmarker_config.benchmark_name == "adult-income"
            assert config.filepath == Path("benchmark").joinpath("adult.csv")
            assert config.benchmarker_config.benchmark_filename == "adult.csv"
            assert config.benchmarker_config.benchmark_access == "public"
            assert config.benchmarker_config.benchmark_region_name == "us-west-2"
            assert config.benchmarker_config.benchmark_bucket_name == "test-bucket"
            assert config.benchmarker_config.benchmark_sha256 == "test-hash"

    def test_unsupported_benchmark(self):
        """Test unsupported benchmark raises error
        æ¸¬è©¦ä¸æ”¯æ´çš„åŸºæº–è³‡æ–™é›†æœƒå¼•ç™¼éŒ¯èª¤
        """
        with patch.object(
            BenchmarkerConfig, "_load_benchmark_config"
        ) as mock_load_config:
            mock_load_config.return_value = {}
            with pytest.raises(UnsupportedMethodError):
                LoaderConfig(filepath="benchmark://nonexistent")

    def test_private_benchmark_unsupported(self):
        """Test private benchmark access raises error
        æ¸¬è©¦ç§æœ‰åŸºæº–è³‡æ–™é›†å­˜å–æœƒå¼•ç™¼éŒ¯èª¤
        """
        with patch.object(
            BenchmarkerConfig, "_load_benchmark_config"
        ) as mock_load_config:
            mock_load_config.return_value = {
                "private-data": {
                    "filename": "private.csv",
                    "access": "private",
                    "region_name": "us-west-2",
                    "bucket_name": "private-bucket",
                    "sha256": "test-hash",
                }
            }
            with pytest.raises(UnsupportedMethodError):
                LoaderConfig(filepath="benchmark://private-data")

    @pytest.mark.parametrize(
        "filepath,expected_ext,expected_code",
        [
            ("path/to/file.csv", ".csv", LoaderFileExt.CSVTYPE),
            ("path/to/file.xlsx", ".xlsx", LoaderFileExt.EXCELTYPE),
            ("path/to/file.xls", ".xls", LoaderFileExt.EXCELTYPE),
            ("path/to/file.CSV", ".csv", LoaderFileExt.CSVTYPE),
            ("path/to/file.XLSX", ".xlsx", LoaderFileExt.EXCELTYPE),
        ],
    )
    def test_file_extension_handling(self, filepath, expected_ext, expected_code):
        """Test file extension parsing and mapping
        æ¸¬è©¦æª”æ¡ˆå‰¯æª”åè§£æå’Œæ˜ å°„
        """
        config = LoaderConfig(filepath=filepath)
        assert config.file_ext == expected_ext
        assert config.file_ext_code == expected_code

    def test_invalid_file_extension(self):
        """Test handling of invalid file extensions
        æ¸¬è©¦è™•ç†ç„¡æ•ˆçš„æª”æ¡ˆå‰¯æª”å
        """
        with pytest.raises(UnsupportedMethodError):
            LoaderConfig(filepath="path/to/file.invalid")

    def test_unsupported_column_type(self):
        """Test handling of unsupported column types
        æ¸¬è©¦è™•ç†ä¸æ”¯æ´çš„æ¬„ä½é¡å‹
        """
        with pytest.raises(UnsupportedMethodError):
            LoaderConfig(
                filepath="path/to/file.csv", column_types={"unsupported_type": ["col1"]}
            )

    def test_get_method(self):
        """Test get() method returns config dictionary
        æ¸¬è©¦ get() æ–¹æ³•è¿”å›é…ç½®å­—å…¸
        """
        config = LoaderConfig(filepath="path/to/file.csv")
        config_dict = config.get()
        assert isinstance(config_dict, dict)
        assert config_dict["filepath"] == "path/to/file.csv"
        assert config_dict["file_ext"] == ".csv"


class TestBenchmarkerConfig:
    """Test cases for BenchmarkerConfig class
    BenchmarkerConfig é¡çš„æ¸¬è©¦æ¡ˆä¾‹
    """

    def test_benchmarker_config_requires_benchmark_name(self):
        """Test that benchmark_name must be specified
        æ¸¬è©¦å¿…é ˆæŒ‡å®š benchmark_name åƒæ•¸
        """
        with pytest.raises(ConfigError):
            BenchmarkerConfig()

    def test_benchmarker_config_initialization(self):
        """Test BenchmarkerConfig initialization
        æ¸¬è©¦ BenchmarkerConfig åˆå§‹åŒ–
        """
        with patch.object(
            BenchmarkerConfig, "_load_benchmark_config"
        ) as mock_load_config:
            mock_load_config.return_value = {
                "adult-income": {
                    "filename": "adult.csv",
                    "access": "public",
                    "region_name": "us-west-2",
                    "bucket_name": "test-bucket",
                    "sha256": "test-hash",
                }
            }

            config = BenchmarkerConfig(benchmark_name="adult-income")
            assert config.benchmark_name == "adult-income"
            assert config.benchmark_filename == "adult.csv"
            assert config.benchmark_access == "public"
            assert config.benchmark_region_name == "us-west-2"
            assert config.benchmark_bucket_name == "test-bucket"
            assert config.benchmark_sha256 == "test-hash"

    def test_benchmarker_config_get_benchmarker_config(self):
        """Test get_benchmarker_config method
        æ¸¬è©¦ get_benchmarker_config æ–¹æ³•
        """
        with patch.object(
            BenchmarkerConfig, "_load_benchmark_config"
        ) as mock_load_config:
            mock_load_config.return_value = {
                "adult-income": {
                    "filename": "adult.csv",
                    "access": "public",
                    "region_name": "us-west-2",
                    "bucket_name": "test-bucket",
                    "sha256": "test-hash",
                }
            }

            config = BenchmarkerConfig(benchmark_name="adult-income")
            benchmarker_config = config.get_benchmarker_config()

            assert isinstance(benchmarker_config, dict)
            assert benchmarker_config["benchmark_filename"] == "adult.csv"
            assert benchmarker_config["benchmark_bucket_name"] == "test-bucket"
            assert benchmarker_config["benchmark_sha256"] == "test-hash"
            assert str(benchmarker_config["filepath"]).endswith("benchmark/adult.csv")

    def test_benchmarker_config_unsupported_benchmark(self):
        """Test unsupported benchmark raises error
        æ¸¬è©¦ä¸æ”¯æ´çš„åŸºæº–è³‡æ–™é›†æœƒå¼•ç™¼éŒ¯èª¤
        """
        with patch.object(
            BenchmarkerConfig, "_load_benchmark_config"
        ) as mock_load_config:
            mock_load_config.return_value = {}
            with pytest.raises(UnsupportedMethodError):
                BenchmarkerConfig(benchmark_name="nonexistent")

    def test_benchmarker_config_private_access_unsupported(self):
        """Test private benchmark access raises error
        æ¸¬è©¦ç§æœ‰åŸºæº–è³‡æ–™é›†å­˜å–æœƒå¼•ç™¼éŒ¯èª¤
        """
        with patch.object(
            BenchmarkerConfig, "_load_benchmark_config"
        ) as mock_load_config:
            mock_load_config.return_value = {
                "private-data": {
                    "filename": "private.csv",
                    "access": "private",
                    "region_name": "us-west-2",
                    "bucket_name": "private-bucket",
                    "sha256": "test-hash",
                }
            }
            with pytest.raises(UnsupportedMethodError):
                BenchmarkerConfig(benchmark_name="private-data")


class TestLoader:
    """Test cases for main Loader functionality
    ä¸»è¦ Loader åŠŸèƒ½çš„æ¸¬è©¦æ¡ˆä¾‹
    """

    @pytest.fixture
    def sample_csv_path(self, tmp_path):
        """Create a temporary CSV file for testing
        å‰µå»ºè‡¨æ™‚ CSV æª”æ¡ˆç”¨æ–¼æ¸¬è©¦
        """
        csv_file = tmp_path / "test.csv"
        pd.DataFrame({"A": [1, 2, 3], "B": ["x", "y", "z"]}).to_csv(
            csv_file, index=False
        )
        return str(csv_file)

    def test_loader_init_no_config(self):
        """Test Loader initialization with no config
        æ¸¬è©¦æ²’æœ‰é…ç½®çš„ Loader åˆå§‹åŒ–
        """
        with pytest.raises(ConfigError):
            Loader()

    @pytest.mark.parametrize(
        "filepath,expected_ext",
        [
            ("path/to/file.csv", ".csv"),
            ("path.with.dots/file.csv", ".csv"),
            ("path/to/file.name.with.dots.csv", ".csv"),
            ("./relative/path/file.csv", ".csv"),
            ("../parent/path/file.csv", ".csv"),
            ("/absolute/path/file.csv", ".csv"),
            ("file.CSV", ".csv"),  # æ¸¬è©¦å¤§å°å¯« / Test case sensitivity
            ("path/to/file.XLSX", ".xlsx"),
        ],
    )
    def test_handle_filepath_with_complex_name(self, filepath, expected_ext):
        """Test handling of complex file paths
        æ¸¬è©¦è™•ç†è¤‡é›œçš„æª”æ¡ˆè·¯å¾‘
        > issue 375
        """
        loader = Loader(filepath=filepath)
        assert loader.config.file_ext == expected_ext
        assert loader.config.filepath == filepath

    def test_loader_init_with_filepath(self, sample_csv_path):
        """Test Loader initialization with filepath
        æ¸¬è©¦ä½¿ç”¨æª”æ¡ˆè·¯å¾‘åˆå§‹åŒ– Loader
        """
        loader = Loader(filepath=sample_csv_path)
        assert loader.config.filepath == sample_csv_path
        assert loader.config.file_ext == ".csv"

    def test_loader_init_with_column_types(self, sample_csv_path):
        """Test Loader initialization with column types
        æ¸¬è©¦ä½¿ç”¨æ¬„ä½é¡å‹åˆå§‹åŒ– Loader
        """
        column_types = {"category": ["B"]}
        loader = Loader(filepath=sample_csv_path, column_types=column_types)
        assert loader.config.column_types == column_types

    def test_benchmark_loader(self):
        """Test loading benchmark dataset
        æ¸¬è©¦è¼‰å…¥åŸºæº–è³‡æ–™é›†
        """
        with (
            patch("petsard.loader.loader.BenchmarkerRequests") as mock_benchmarker,
            patch.object(
                BenchmarkerConfig, "_load_benchmark_config"
            ) as mock_load_config,
        ):
            mock_load_config.return_value = {
                "adult-income": {
                    "filename": "adult.csv",
                    "access": "public",
                    "region_name": "us-west-2",
                    "bucket_name": "test-bucket",
                    "sha256": "test-hash",
                }
            }

            loader = Loader(filepath="benchmark://adult-income")
            # Benchmarker should not be called during init
            # åˆå§‹åŒ–æœŸé–“ä¸æ‡‰èª¿ç”¨ Benchmarker
            mock_benchmarker.assert_not_called()

            assert loader.config.benchmarker_config is not None
            assert loader.config.benchmarker_config.benchmark_name == "adult-income"

    def test_load_csv(self, sample_csv_path):
        """Test loading CSV file
        æ¸¬è©¦è¼‰å…¥ CSV æª”æ¡ˆ
        """
        loader = Loader(filepath=sample_csv_path)

        with (
            patch("pandas.read_csv") as mock_read_csv,
            patch(
                "petsard.metadater.metadater.Metadater.create_schema"
            ) as mock_create_schema,
            patch(
                "petsard.metadater.schema.schema_functions.apply_schema_transformations"
            ) as mock_apply_transformations,
        ):
            # Setup mock returns
            # è¨­ç½®æ¨¡æ“¬å›å‚³å€¼
            mock_df = pd.DataFrame({"A": [1, 2, 3], "B": ["x", "y", "z"]})
            mock_read_csv.return_value = mock_df.fillna(pd.NA)

            mock_schema_instance = MagicMock()
            mock_create_schema.return_value = mock_schema_instance
            mock_apply_transformations.return_value = mock_df

            # Call load method
            # èª¿ç”¨ load æ–¹æ³•
            data, schema = loader.load()

            # Assertions
            # æ–·è¨€
            mock_read_csv.assert_called_once_with(
                sample_csv_path,
                header="infer",
                names=None,
            )
            mock_create_schema.assert_called_once()
            mock_apply_transformations.assert_called_once()
            assert data is not None
            assert schema is not None

    def test_load_excel(self):
        """Test loading Excel file
        æ¸¬è©¦è¼‰å…¥ Excel æª”æ¡ˆ
        """
        excel_path = "path/to/file.xlsx"
        loader = Loader(filepath=excel_path)

        with (
            patch("pandas.read_excel") as mock_read_excel,
            patch(
                "petsard.metadater.metadater.Metadater.create_schema"
            ) as mock_create_schema,
            patch(
                "petsard.metadater.schema.schema_functions.apply_schema_transformations"
            ) as mock_apply_transformations,
            patch("os.path.exists") as mock_exists,
        ):
            # Setup mock returns
            # è¨­ç½®æ¨¡æ“¬å›å‚³å€¼
            mock_exists.return_value = True
            mock_df = pd.DataFrame({"A": [1, 2, 3], "B": ["x", "y", "z"]})
            mock_read_excel.return_value = mock_df.fillna(pd.NA)

            mock_schema_instance = MagicMock()
            mock_create_schema.return_value = mock_schema_instance
            mock_apply_transformations.return_value = mock_df

            # Call load method
            # èª¿ç”¨ load æ–¹æ³•
            data, schema = loader.load()

            # Assertions
            # æ–·è¨€
            mock_read_excel.assert_called_once_with(
                excel_path,
                header="infer",
                names=None,
            )
            mock_create_schema.assert_called_once()
            mock_apply_transformations.assert_called_once()
            assert data is not None
            assert schema is not None

    def test_benchmark_data_load(self):
        """Test loading benchmark data
        æ¸¬è©¦è¼‰å…¥åŸºæº–è³‡æ–™
        """
        with (
            patch.object(
                BenchmarkerConfig, "_load_benchmark_config"
            ) as mock_load_config,
            patch("petsard.loader.loader.BenchmarkerRequests") as mock_benchmarker,
            patch("pandas.read_csv") as mock_read_csv,
            patch(
                "petsard.metadater.metadater.Metadater.create_schema"
            ) as mock_create_schema,
            patch(
                "petsard.metadater.schema.schema_functions.apply_schema_transformations"
            ) as mock_apply_transformations,
        ):
            # Setup mock returns
            # è¨­ç½®æ¨¡æ“¬å›å‚³å€¼
            mock_load_config.return_value = {
                "adult-income": {
                    "filename": "adult.csv",
                    "access": "public",
                    "region_name": "us-west-2",
                    "bucket_name": "test-bucket",
                    "sha256": "test-hash",
                }
            }
            mock_df = pd.DataFrame({"A": [1, 2, 3], "B": ["x", "y", "z"]})
            mock_read_csv.return_value = mock_df.fillna(pd.NA)

            mock_schema_instance = MagicMock()
            mock_create_schema.return_value = mock_schema_instance
            mock_apply_transformations.return_value = mock_df
            mock_benchmarker_instance = MagicMock()
            mock_benchmarker.return_value = mock_benchmarker_instance

            # Create and load benchmark data
            # å‰µå»ºå’Œè¼‰å…¥åŸºæº–è³‡æ–™
            loader = Loader(filepath="benchmark://adult-income")
            data, schema = loader.load()

            # Assertions
            # æ–·è¨€
            mock_benchmarker.assert_called_once()
            mock_benchmarker_instance.download.assert_called_once()
            mock_read_csv.assert_called_once()
            mock_create_schema.assert_called_once()
            mock_apply_transformations.assert_called_once()
            assert data is not None
            assert schema is not None

    def test_custom_na_values(self, sample_csv_path):
        """Test loading with custom NA values
        æ¸¬è©¦ä½¿ç”¨è‡ªå®šç¾© NA å€¼è¼‰å…¥è³‡æ–™
        """
        na_values = ["x"]
        loader = Loader(filepath=sample_csv_path, na_values=na_values)

        with (
            patch("pandas.read_csv") as mock_read_csv,
            patch(
                "petsard.metadater.metadater.Metadater.create_schema"
            ) as mock_create_schema,
            patch(
                "petsard.metadater.schema.schema_functions.apply_schema_transformations"
            ) as mock_apply_transformations,
        ):
            # Setup mock returns
            # è¨­ç½®æ¨¡æ“¬å›å‚³å€¼
            mock_df = pd.DataFrame({"A": [1, 2, 3], "B": [None, "y", "z"]})
            mock_read_csv.return_value = mock_df.fillna(pd.NA)

            mock_schema_instance = MagicMock()
            mock_create_schema.return_value = mock_schema_instance
            mock_apply_transformations.return_value = mock_df

            # Call load method
            # èª¿ç”¨ load æ–¹æ³•
            data, schema = loader.load()

            # Assertions
            # æ–·è¨€
            mock_read_csv.assert_called_once_with(
                sample_csv_path,
                header="infer",
                names=None,
                na_values=na_values,
            )
            mock_create_schema.assert_called_once()
            mock_apply_transformations.assert_called_once()
            assert data is not None
            assert schema is not None

    def test_custom_header_names(self, sample_csv_path):
        """Test loading with custom header names
        æ¸¬è©¦ä½¿ç”¨è‡ªå®šç¾©æ¬„ä½åç¨±è¼‰å…¥è³‡æ–™
        """
        header_names = ["Col1", "Col2"]
        loader = Loader(filepath=sample_csv_path, header_names=header_names)

        with (
            patch("pandas.read_csv") as mock_read_csv,
            patch(
                "petsard.metadater.metadater.Metadater.create_schema"
            ) as mock_create_schema,
            patch(
                "petsard.metadater.schema.schema_functions.apply_schema_transformations"
            ) as mock_apply_transformations,
        ):
            # Setup mock returns
            # è¨­ç½®æ¨¡æ“¬å›å‚³å€¼
            mock_df = pd.DataFrame({"Col1": [1, 2, 3], "Col2": ["x", "y", "z"]})
            mock_read_csv.return_value = mock_df.fillna(pd.NA)

            mock_schema_instance = MagicMock()
            mock_create_schema.return_value = mock_schema_instance
            mock_apply_transformations.return_value = mock_df

            # Call load method
            # èª¿ç”¨ load æ–¹æ³•
            data, schema = loader.load()

            # Assertions
            # æ–·è¨€
            mock_read_csv.assert_called_once_with(
                sample_csv_path,
                header=0,
                names=header_names,
            )
            mock_create_schema.assert_called_once()
            mock_apply_transformations.assert_called_once()
            assert data is not None
            assert schema is not None


class TestLoaderMetadataFeature:
    """Test cases for new schema parameter functionality
    æ–° schema åƒæ•¸åŠŸèƒ½çš„æ¸¬è©¦æ¡ˆä¾‹
    """

    @pytest.fixture
    def sample_csv_with_schema_needs(self, tmp_path):
        """Create a CSV file that needs schema transformations
        å‰µå»ºéœ€è¦ schema è½‰æ›çš„ CSV æª”æ¡ˆ
        """
        csv_file = tmp_path / "schema_test.csv"
        test_data = {
            "age": [25, 30, "unknown", 45, "N/A"],  # Integer with custom NA values
            "salary": [
                50000.123,
                60000.456,
                70000.789,
                80000.999,
                90000.111,
            ],  # Float needing precision
            "score": ["85", "90", "78", "92", "88"],  # String that should be int
            "active": ["true", "false", "yes", "no", "1"],  # Boolean conversion
            "category": ["A", "B", "C", "A", "B"],  # Category data
        }
        pd.DataFrame(test_data).to_csv(csv_file, index=False)
        return str(csv_file)

    def test_schema_parameter_validation(self):
        """Test schema parameter validation in LoaderConfig
        æ¸¬è©¦ LoaderConfig ä¸­çš„ schema åƒæ•¸é©—è­‰
        """
        # Valid schema configuration using SchemaConfig
        fields = {
            "age": FieldConfig(type="int", na_values=["unknown", "N/A"]),
            "salary": FieldConfig(type="float", precision=2),
            "score": FieldConfig(type="int"),
        }
        valid_schema_config = SchemaConfig(
            schema_id="test_schema", name="Test Schema", fields=fields
        )

        # Should not raise any exception
        # Test using Loader instead of LoaderConfig directly
        loader = Loader(filepath="test.csv", schema=valid_schema_config)
        assert loader.config.schema == valid_schema_config

    def test_schema_parameter_validation_invalid_structure(self):
        """Test schema parameter validation with invalid structure
        æ¸¬è©¦ç„¡æ•ˆçµæ§‹çš„ schema åƒæ•¸é©—è­‰
        """
        # SchemaConfig currently accepts any value for fields parameter
        # This test verifies that LoaderConfig can handle SchemaConfig with invalid fields
        invalid_schema = SchemaConfig(schema_id="test", name="test", fields="invalid")

        # LoaderConfig should accept the SchemaConfig even with invalid fields
        # Test using Loader instead of LoaderConfig directly
        loader = Loader(filepath="test.csv", schema=invalid_schema)
        assert loader.config.schema == invalid_schema

    def test_schema_parameter_validation_invalid_keys(self):
        """Test schema parameter validation with invalid keys
        æ¸¬è©¦ç„¡æ•ˆéµå€¼çš„ schema åƒæ•¸é©—è­‰
        """
        # FieldConfig validation is now handled by the dataclass itself
        # Invalid parameters should be caught during FieldConfig creation
        with pytest.raises((TypeError, ValueError)):
            invalid_field = FieldConfig(type="int", invalid_key="value")
            schema_config = SchemaConfig(
                schema_id="test", name="test", fields={"age": invalid_field}
            )
            LoaderConfig(filepath="test.csv", schema=schema_config)

    def test_schema_parameter_validation_invalid_values(self):
        """Test schema parameter validation with invalid values
        æ¸¬è©¦ç„¡æ•ˆå€¼çš„ schema åƒæ•¸é©—è­‰
        """
        # FieldConfig validation is now handled by the dataclass itself
        # Invalid values should be caught during FieldConfig creation
        with pytest.raises((TypeError, ValueError)):
            # Invalid: precision is negative
            invalid_field = FieldConfig(type="float", precision=-1)
            schema_config = SchemaConfig(
                schema_id="test", name="test", fields={"salary": invalid_field}
            )
            LoaderConfig(filepath="test.csv", schema=schema_config)

    def test_schema_transformations_applied(self, sample_csv_with_schema_needs):
        """Test that schema transformations are applied during load
        æ¸¬è©¦åœ¨è¼‰å…¥éç¨‹ä¸­æ‡‰ç”¨ schema è½‰æ›
        """
        fields = {
            "age": FieldConfig(type="int", na_values=["unknown", "N/A"]),
            "salary": FieldConfig(type="float", precision=2),
            "score": FieldConfig(type="int"),
            "active": FieldConfig(type="boolean"),
        }
        schema_config = SchemaConfig(
            schema_id="test_schema", name="Test Schema", fields=fields
        )

        loader = Loader(filepath=sample_csv_with_schema_needs, schema=schema_config)

        with (
            patch("pandas.read_csv") as mock_read_csv,
            patch(
                "petsard.metadater.metadater.Metadater.create_schema"
            ) as mock_create_schema,
            patch(
                "petsard.metadater.schema.schema_functions.apply_schema_transformations"
            ) as mock_apply_transformations,
        ):
            # Setup mock returns
            original_df = pd.DataFrame(
                {
                    "age": [25, 30, "unknown", 45, "N/A"],
                    "salary": [50000.123, 60000.456, 70000.789, 80000.999, 90000.111],
                    "score": ["85", "90", "78", "92", "88"],
                    "active": ["true", "false", "yes", "no", "1"],
                    "category": ["A", "B", "C", "A", "B"],
                }
            )
            mock_read_csv.return_value = original_df.fillna(pd.NA)

            mock_schema_instance = MagicMock()
            mock_create_schema.return_value = mock_schema_instance
            mock_apply_transformations.return_value = original_df

            # Call load method
            data, schema = loader.load()

            # Verify that schema transformations were applied
            mock_apply_transformations.assert_called_once()

            # Verify that create_schema was called with the correct schema config
            call_args = mock_create_schema.call_args
            passed_schema_config = call_args[1]["config"]
            assert "age" in passed_schema_config.fields
            assert "salary" in passed_schema_config.fields
            assert "score" in passed_schema_config.fields
            assert "active" in passed_schema_config.fields

    def test_schema_field_not_in_data_warning(self, sample_csv_with_schema_needs):
        """Test warning when schema field is not found in data
        æ¸¬è©¦ç•¶ schema æ¬„ä½åœ¨è³‡æ–™ä¸­æ‰¾ä¸åˆ°æ™‚çš„è­¦å‘Š
        """
        fields = {
            "nonexistent_field": FieldConfig(type="int"),
            "age": FieldConfig(type="int"),
        }
        schema_config = SchemaConfig(
            schema_id="test_schema", name="Test Schema", fields=fields
        )

        loader = Loader(filepath=sample_csv_with_schema_needs, schema=schema_config)

        with (
            patch("pandas.read_csv") as mock_read_csv,
            patch(
                "petsard.metadater.metadater.Metadater.create_schema"
            ) as mock_create_schema,
            patch(
                "petsard.metadater.schema.schema_functions.apply_schema_transformations"
            ) as mock_apply_transformations,
        ):
            # Setup mock returns
            original_df = pd.DataFrame(
                {
                    "age": [25, 30, 35, 45, 50],
                    "other_field": ["A", "B", "C", "D", "E"],
                }
            )
            mock_read_csv.return_value = original_df.fillna(pd.NA)

            mock_schema_instance = MagicMock()
            mock_create_schema.return_value = mock_schema_instance
            mock_apply_transformations.return_value = original_df

            # Call load method - should not raise exception but log warning
            data, schema = loader.load()

            # Verify that schema transformations were applied
            mock_apply_transformations.assert_called_once()

            # Verify that create_schema was called with schema containing both fields
            call_args = mock_create_schema.call_args
            passed_schema_config = call_args[1]["config"]
            assert "nonexistent_field" in passed_schema_config.fields
            assert "age" in passed_schema_config.fields

    def test_schema_transformation_error_handling(self, sample_csv_with_schema_needs):
        """Test error handling during schema transformations
        æ¸¬è©¦ schema è½‰æ›éç¨‹ä¸­çš„éŒ¯èª¤è™•ç†
        """
        fields = {
            "age": FieldConfig(type="int"),
        }
        schema_config = SchemaConfig(
            schema_id="test_schema", name="Test Schema", fields=fields
        )

        loader = Loader(filepath=sample_csv_with_schema_needs, schema=schema_config)

        with (
            patch("pandas.read_csv") as mock_read_csv,
            patch(
                "petsard.metadater.metadater.Metadater.create_schema"
            ) as mock_create_schema,
            patch(
                "petsard.metadater.schema.schema_functions.apply_schema_transformations"
            ) as mock_apply_transformations,
            patch(
                "petsard.metadater.field.field_functions.apply_field_transformations"
            ) as mock_field_transform,
        ):
            # Setup mock returns
            original_df = pd.DataFrame(
                {
                    "age": [25, 30, 35, 45, 50],
                }
            )
            mock_read_csv.return_value = original_df.fillna(pd.NA)

            # Make field transformation raise an exception
            mock_field_transform.side_effect = Exception("Transformation failed")

            mock_schema_instance = MagicMock()
            mock_create_schema.return_value = mock_schema_instance
            mock_apply_transformations.return_value = original_df

            # Call load method - should not raise exception but continue with other processing
            data, schema = loader.load()

            # Verify that the load completed despite transformation error
            assert data is not None
            assert schema is not None

    def test_schema_precedence_over_column_types(self, sample_csv_with_schema_needs):
        """Test that schema parameter conflicts with column_types raise ConfigError
        æ¸¬è©¦ schema åƒæ•¸èˆ‡ column_types è¡çªæ™‚æœƒæ‹‹å‡º ConfigError
        """
        fields = {
            "age": FieldConfig(type="int", na_values=["unknown"]),
        }
        schema_config = SchemaConfig(
            schema_id="test_schema", name="Test Schema", fields=fields
        )
        column_types = {
            "category": ["age"],  # This should conflict with schema
        }

        # Should raise ConfigError due to field conflict
        with pytest.raises(
            ConfigError, match="Conflict detected.*age.*schema and column_types"
        ):
            Loader(
                filepath=sample_csv_with_schema_needs,
                schema=schema_config,
                column_types=column_types,
            )


class TestLoaderAmbiguousDataFeatures:
    """Test cases for ambiguous data type processing features
    å®¹æ˜“èª¤åˆ¤ã€å‹åˆ¥åˆ¤æ–·æ¨¡ç³Šè³‡æ–™è™•ç†åŠŸèƒ½çš„æ¸¬è©¦æ¡ˆä¾‹
    """

    @pytest.fixture
    def ambiguous_sample_csv(self, tmp_path):
        """Create a sample CSV file with ambiguous data types for testing
        å‰µå»ºå«æœ‰å‹åˆ¥åˆ¤æ–·æ¨¡ç³Šè³‡æ–™çš„æ¸¬è©¦ç”¨ CSV æª”æ¡ˆ
        """
        csv_file = tmp_path / "ambiguous_test.csv"
        # Ambiguous data with leading zeros, mixed types, and null values
        test_data = {
            "id_code": ["001", "002", "010", "099"],  # Leading zeros - å‰å°é›¶ä»£è™Ÿ
            "age": [25, 30, "", 45],  # Integers with null - å«ç©ºå€¼æ•´æ•¸
            "amount": [
                50000.5,
                60000.7,
                "",
                75000.3,
            ],  # Floats with null - å«ç©ºå€¼æµ®é»æ•¸
            "score": [85, 90, 78, 92],  # Pure integers - ç´”æ•´æ•¸
            "category": ["Aç´š", "Bç´š", "Cç´š", "Aç´š"],  # Categories - åˆ†é¡è³‡æ–™
        }
        pd.DataFrame(test_data).to_csv(csv_file, index=False)
        return str(csv_file)

    def test_backward_compatibility(self, ambiguous_sample_csv):
        """Test that Loader maintains backward compatibility
        æ¸¬è©¦ Loader ä¿æŒå‘å¾Œç›¸å®¹æ€§
        """
        # Test with default settings - Loader should focus on basic file reading
        loader = Loader(filepath=ambiguous_sample_csv)

        with (
            patch("pandas.read_csv") as mock_read_csv,
            patch(
                "petsard.metadater.metadater.Metadater.create_schema"
            ) as mock_create_schema,
            patch(
                "petsard.metadater.schema.schema_functions.apply_schema_transformations"
            ) as mock_apply_transformations,
        ):
            # Setup mock returns
            mock_df = pd.DataFrame({"A": [1, 2, 3], "B": ["x", "y", "z"]})
            mock_read_csv.return_value = mock_df.fillna(pd.NA)

            mock_schema_instance = MagicMock()
            mock_create_schema.return_value = mock_schema_instance
            mock_apply_transformations.return_value = mock_df

            # Call load method
            data, schema = loader.load()

            # Verify normal behavior (no dtype parameter when no column_types specified)
            mock_read_csv.assert_called_once_with(
                ambiguous_sample_csv,
                header="infer",
                names=None,
                # No dtype parameter should be passed when no column_types specified
            )
            assert data is not None
            assert schema is not None


class TestLoaderFileExt:
    """Test cases for LoaderFileExt class
    LoaderFileExt é¡çš„æ¸¬è©¦æ¡ˆä¾‹
    """

    @pytest.mark.parametrize(
        "file_ext,expected_code",
        [
            (".csv", LoaderFileExt.CSVTYPE),
            (".CSV", LoaderFileExt.CSVTYPE),
            (".xlsx", LoaderFileExt.EXCELTYPE),
            (".XLSX", LoaderFileExt.EXCELTYPE),
            (".xls", LoaderFileExt.EXCELTYPE),
            (".xlsm", LoaderFileExt.EXCELTYPE),
            (".xlsb", LoaderFileExt.EXCELTYPE),
            (".ods", LoaderFileExt.EXCELTYPE),
            (".odt", LoaderFileExt.EXCELTYPE),
        ],
    )
    def test_get_file_ext_code(self, file_ext, expected_code):
        """Test getting file extension code
        æ¸¬è©¦ç²å–æª”æ¡ˆå‰¯æª”åé¡å‹
        """
        assert LoaderFileExt.get(file_ext) == expected_code

    def test_unsupported_file_ext(self):
        """Test handling of unsupported file extensions
        æ¸¬è©¦è™•ç†ä¸æ”¯æ´çš„æª”æ¡ˆå‰¯æª”å
        """
        with pytest.raises(KeyError):
            LoaderFileExt.get(".unsupported")


# ============================================================================
# å£“åŠ›æ¸¬è©¦ Stress Tests
# ============================================================================


class MemoryMonitor:
    """è¨˜æ†¶é«”ä½¿ç”¨ç›£æ§å™¨"""

    def __init__(self):
        self.initial_memory = self.get_memory_usage()
        self.peak_memory = self.initial_memory

    def get_memory_usage(self) -> float:
        """å–å¾—ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨é‡ (MB)"""
        try:
            # ä½¿ç”¨ resource æ¨¡çµ„ç²å–è¨˜æ†¶é«”ä½¿ç”¨é‡ (Unix/Linux/macOS)
            # Use resource module to get memory usage (Unix/Linux/macOS)
            return resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024
        except (AttributeError, OSError):
            # Windows æˆ–å…¶ä»–ç³»çµ±çš„å‚™ç”¨æ–¹æ¡ˆ
            # Fallback for Windows or other systems
            return 0.0

    def record(self, label: str = ""):
        """è¨˜éŒ„ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨é‡"""
        current = self.get_memory_usage()
        self.peak_memory = max(self.peak_memory, current)
        return current

    def get_peak_usage(self) -> float:
        """å–å¾—å³°å€¼è¨˜æ†¶é«”ä½¿ç”¨é‡"""
        return self.peak_memory

    def get_memory_increase(self) -> float:
        """å–å¾—è¨˜æ†¶é«”å¢é•·é‡"""
        return self.get_memory_usage() - self.initial_memory


class LargeFileGenerator:
    """å¤§å‹æ¸¬è©¦æª”æ¡ˆç”Ÿæˆå™¨"""

    def __init__(self, target_size_gb: float = 1.0):
        self.target_size_gb = target_size_gb
        self.target_size_bytes = int(target_size_gb * 1024 * 1024 * 1024)

    def generate_test_csv(
        self, filepath: str, scenario: str = "mixed_types"
    ) -> dict[str, Any]:
        """ç”Ÿæˆæ¸¬è©¦ CSV æª”æ¡ˆ"""
        logging.info(f"ç”Ÿæˆæ¸¬è©¦æª”æ¡ˆ: {filepath}, æƒ…å¢ƒ: {scenario}")

        estimated_rows = self.target_size_bytes // 100
        chunk_size = 100000

        file_info = {
            "filepath": filepath,
            "scenario": scenario,
            "actual_rows": 0,
            "columns": ["id", "amount", "code", "score"],
            "file_size_bytes": 0,
        }

        with open(filepath, "w", encoding="utf-8") as f:
            f.write("id,amount,code,score\n")

            rows_written = 0
            while rows_written < estimated_rows:
                chunk_data = []
                for i in range(min(chunk_size, estimated_rows - rows_written)):
                    row_idx = rows_written + i
                    progress = row_idx / estimated_rows

                    # 99.9% æ­£å¸¸è³‡æ–™ï¼Œ0.1% ä¾‹å¤–åœ¨æœ€å¾Œ
                    if progress >= 0.999:
                        # ä¾‹å¤–è³‡æ–™
                        row_data = [
                            f"EXCEPTION_{row_idx}",
                            "",
                            str(row_idx),
                            f"{row_idx}.99",
                        ]
                    else:
                        # æ­£å¸¸è³‡æ–™
                        row_data = [
                            str(row_idx + 1),
                            f"{np.random.uniform(1000, 999999):.2f}",
                            f"CODE_{row_idx:06d}",
                            str(np.random.randint(0, 100)),
                        ]

                    chunk_data.append(",".join(row_data))

                f.write("\n".join(chunk_data) + "\n")
                rows_written += len(chunk_data)

                current_size = os.path.getsize(filepath)
                if current_size >= self.target_size_bytes:
                    break

        file_info["actual_rows"] = rows_written
        file_info["file_size_bytes"] = os.path.getsize(filepath)

        logging.info(
            f"æª”æ¡ˆç”Ÿæˆå®Œæˆ: {file_info['file_size_bytes'] / 1024 / 1024:.1f} MB, {file_info['actual_rows']} è¡Œ"
        )
        return file_info


@pytest.mark.stress
class TestLoaderStress:
    """Loader å£“åŠ›æ¸¬è©¦"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """å‰µå»ºè‡¨æ™‚ç›®éŒ„"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield temp_dir

    def _run_stress_test(self, temp_dir, size_gb, test_name, timeout_seconds):
        """åŸ·è¡Œå£“åŠ›æ¸¬è©¦çš„é€šç”¨æ–¹æ³•"""
        file_generator = LargeFileGenerator(target_size_gb=size_gb)
        csv_path = os.path.join(temp_dir, f"stress_test_{size_gb}gb.csv")

        # ç”Ÿæˆæ¸¬è©¦æª”æ¡ˆ
        file_info = file_generator.generate_test_csv(csv_path, "mixed_types")

        memory_monitor = MemoryMonitor()
        memory_monitor.record("æ¸¬è©¦é–‹å§‹")

        success = False
        error_msg = None
        start_time = time.time()

        try:
            # è¨­ç½®è¶…æ™‚
            import signal

            def timeout_handler(signum, frame):
                raise TimeoutError(f"æ¸¬è©¦è¶…æ™‚ ({timeout_seconds} ç§’)")

            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(timeout_seconds)

            try:
                loader = Loader(filepath=csv_path)

                memory_monitor.record("Loader åˆå§‹åŒ–å®Œæˆ")

                data, schema = loader.load()
                memory_monitor.record("è³‡æ–™è¼‰å…¥å®Œæˆ")

                assert data is not None
                assert schema is not None
                assert len(data) > 0

                success = True

            finally:
                signal.alarm(0)  # å–æ¶ˆè¶…æ™‚

        except TimeoutError as e:
            error_msg = str(e)
            logging.error(f"æ¸¬è©¦è¶…æ™‚: {error_msg}")
        except Exception as e:
            error_msg = str(e)
            logging.error(f"æ¸¬è©¦å¤±æ•—: {error_msg}")

        finally:
            load_time = time.time() - start_time

            # æ¸…ç†è¨˜æ†¶é«”
            if "data" in locals():
                del data
            if "schema" in locals():
                del schema
            gc.collect()

            # è¨˜éŒ„æ¸¬è©¦çµæœ
            throughput = (
                (file_info["file_size_bytes"] / 1024 / 1024) / load_time
                if success
                else 0
            )
            logging.info(
                f"{test_name}: {'æˆåŠŸ' if success else 'å¤±æ•—'}, "
                f"è¼‰å…¥æ™‚é–“: {load_time:.2f}ç§’, "
                f"è™•ç†é€Ÿåº¦: {throughput:.1f} MB/ç§’, "
                f"å³°å€¼è¨˜æ†¶é«”: {memory_monitor.get_peak_usage():.1f} MB"
            )

        return success, error_msg

    @pytest.mark.stress
    def test_medium_file_1gb(self, temp_dir):
        """æ¸¬è©¦ä¸­æª”æ¡ˆï¼š1GB (120ç§’è¶…æ™‚)"""
        success, error_msg = self._run_stress_test(temp_dir, 1.0, "ä¸­æª”æ¡ˆ1GBæ¸¬è©¦", 120)
        assert success, f"æ¸¬è©¦å¤±æ•—: {error_msg}"

    @pytest.mark.stress
    def test_xlarge_file_5gb(self, temp_dir):
        """æ¸¬è©¦è¶…å¤§æª”æ¡ˆï¼š5GB (600ç§’è¶…æ™‚)"""
        success, error_msg = self._run_stress_test(
            temp_dir, 5.0, "è¶…å¤§æª”æ¡ˆ5GBæ¸¬è©¦", 600
        )
        assert success, f"æ¸¬è©¦å¤±æ•—: {error_msg}"


@pytest.mark.stress
class TestLoaderTypeInference:
    """å‹åˆ¥æ¨æ–·é‚Šç·£æƒ…æ³æ¸¬è©¦ - 99.9% åœ¨å‰ï¼Œ0.1% ä¾‹å¤–åœ¨å¾Œ"""

    @pytest.fixture(scope="class")
    def temp_dir(self):
        """å‰µå»ºè‡¨æ™‚ç›®éŒ„"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield temp_dir

    def _create_type_test_file(self, temp_dir, test_type):
        """å‰µå»ºå‹åˆ¥æ¸¬è©¦æª”æ¡ˆ"""
        csv_path = os.path.join(temp_dir, f"{test_type}_test.csv")

        with open(csv_path, "w", encoding="utf-8") as f:
            f.write("test_column\n")

            # ç”Ÿæˆ 10000 è¡Œæ¸¬è©¦è³‡æ–™
            total_rows = 10000
            exception_start = int(total_rows * 0.999)  # 99.9% å¾Œé–‹å§‹ä¾‹å¤–

            for i in range(total_rows):
                if i >= exception_start:
                    # æœ€å¾Œ 0.1% æ˜¯ä¾‹å¤–
                    if test_type == "int_to_string":
                        f.write(f"EXCEPTION_{i}\n")
                    elif test_type == "float_to_null":
                        f.write("\n")  # ç©ºå€¼æœƒè¢« pandas éæ¿¾æ‰
                    elif test_type == "string_to_numeric":
                        f.write(f"{i}\n")
                else:
                    # å‰ 99.9% æ˜¯æ­£å¸¸è³‡æ–™
                    if test_type == "int_to_string":
                        f.write(f"{i + 1}\n")
                    elif test_type == "float_to_null":
                        f.write(f"{i * 1.5}\n")  # ç§»é™¤ .2f æ ¼å¼åŒ–ï¼Œé¿å…ç²¾åº¦å•é¡Œ
                    elif test_type == "string_to_numeric":
                        f.write(f"STR_{i:04d}\n")

        return csv_path

    @pytest.mark.stress
    def test_int_with_string_exception(self, temp_dir):
        """æ¸¬è©¦ï¼š99.9% æ•´æ•¸ï¼Œ0.1% å­—ä¸²ä¾‹å¤–"""
        csv_path = self._create_type_test_file(temp_dir, "int_to_string")

        loader = Loader(filepath=csv_path)

        data, schema = loader.load()
        assert data is not None
        assert len(data) == 10000
        logging.info(f"æ•´æ•¸è½‰å­—ä¸²ä¾‹å¤–æ¸¬è©¦å®Œæˆï¼Œè³‡æ–™å½¢ç‹€: {data.shape}")

    @pytest.mark.stress
    def test_float_with_null_exception(self, temp_dir):
        """æ¸¬è©¦ï¼š99.9% æµ®é»æ•¸ï¼Œ0.1% ç©ºå€¼ä¾‹å¤–"""
        csv_path = self._create_type_test_file(temp_dir, "float_to_null")

        loader = Loader(filepath=csv_path)

        data, schema = loader.load()
        assert data is not None
        # ç©ºå€¼æœƒè¢« pandas éæ¿¾æ‰ï¼Œæ‰€ä»¥å¯¦éš›è¡Œæ•¸æœƒå°‘æ–¼ 10000
        assert len(data) > 9900  # è‡³å°‘æœ‰ 99% çš„è³‡æ–™
        logging.info(f"æµ®é»æ•¸è½‰ç©ºå€¼ä¾‹å¤–æ¸¬è©¦å®Œæˆï¼Œè³‡æ–™å½¢ç‹€: {data.shape}")

    @pytest.mark.stress
    def test_string_with_numeric_exception(self, temp_dir):
        """æ¸¬è©¦ï¼š99.9% å­—ä¸²ï¼Œ0.1% æ•¸å€¼ä¾‹å¤–"""
        csv_path = self._create_type_test_file(temp_dir, "string_to_numeric")

        loader = Loader(filepath=csv_path)

        data, schema = loader.load()
        assert data is not None
        assert len(data) == 10000
        logging.info(f"å­—ä¸²è½‰æ•¸å€¼ä¾‹å¤–æ¸¬è©¦å®Œæˆï¼Œè³‡æ–™å½¢ç‹€: {data.shape}")


def run_stress_demo():
    """åŸ·è¡Œå£“åŠ›æ¸¬è©¦ç¤ºç¯„"""
    print("ğŸš€ PETsARD Loader å£“åŠ›æ¸¬è©¦ç¤ºç¯„")
    print("=" * 50)

    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
    )

    with tempfile.TemporaryDirectory() as temp_dir:
        print(f"ä½¿ç”¨è‡¨æ™‚ç›®éŒ„: {temp_dir}")

        # æ¸¬è©¦å°æª”æ¡ˆç”Ÿæˆå’Œè¼‰å…¥
        generator = LargeFileGenerator(target_size_gb=0.01)  # 10MB
        csv_path = os.path.join(temp_dir, "demo_test.csv")

        print("\nç”Ÿæˆæ¸¬è©¦æª”æ¡ˆ...")
        file_info = generator.generate_test_csv(csv_path, "mixed_types")

        print(f"æª”æ¡ˆå¤§å°: {file_info['file_size_bytes'] / 1024 / 1024:.1f} MB")
        print(f"è³‡æ–™è¡Œæ•¸: {file_info['actual_rows']:,}")

        print("\næ¸¬è©¦ Loader è¼‰å…¥...")
        memory_monitor = MemoryMonitor()
        memory_monitor.record("é–‹å§‹")

        start_time = time.time()
        loader = Loader(filepath=csv_path)
        data, schema = loader.load()
        load_time = time.time() - start_time

        memory_monitor.record("å®Œæˆ")

        print("âœ“ è¼‰å…¥æˆåŠŸ")
        print(f"è³‡æ–™å½¢ç‹€: {data.shape}")
        print(f"è¼‰å…¥æ™‚é–“: {load_time:.3f} ç§’")
        print(f"è¨˜æ†¶é«”ä½¿ç”¨: {memory_monitor.get_memory_increase():.1f} MB")
        print(
            f"è™•ç†é€Ÿåº¦: {(file_info['file_size_bytes'] / 1024 / 1024) / load_time:.1f} MB/ç§’"
        )

    print("\n" + "=" * 50)
    print("ğŸ‰ å£“åŠ›æ¸¬è©¦ç¤ºç¯„å®Œæˆ!")
    print("åŸ·è¡Œå®Œæ•´æ¸¬è©¦: pytest tests/loader/ -m stress -v")


class TestLoaderSchemaParameters:
    """Test cases for schema parameter functionality in Loader
    Loader ä¸­ schema åƒæ•¸åŠŸèƒ½çš„æ¸¬è©¦æ¡ˆä¾‹
    """

    def setup_method(self):
        """Setup test data"""
        self.test_data = pd.DataFrame(
            {
                "id": [1, 2, 3, 4, 5],
                "name": ["Alice", "Bob", "Charlie", "David", "Eve"],
                "age": [25, 30, 35, 28, 32],
                "salary": [50000.5, 60000.0, 70000.25, 55000.75, 65000.0],
                "department": ["IT", "HR", "IT", "Finance", "IT"],
                "is_active": [True, False, True, True, False],
            }
        )

        # Create temporary CSV file
        self.temp_file = tempfile.NamedTemporaryFile(
            mode="w", suffix=".csv", delete=False
        )
        self.test_data.to_csv(self.temp_file.name, index=False)
        self.temp_file.close()

    def teardown_method(self):
        """Cleanup test data"""
        if os.path.exists(self.temp_file.name):
            os.unlink(self.temp_file.name)

    def test_compute_stats_parameter(self):
        """Test compute_stats parameter"""
        fields = {"age": FieldConfig(type="int")}
        schema_config = SchemaConfig(
            schema_id="test_schema",
            name="Test Schema",
            fields=fields,
            compute_stats=False,
        )

        loader = Loader(filepath=self.temp_file.name, schema=schema_config)
        # Should not raise error
        assert loader.config.schema.compute_stats is False

    def test_optimize_dtypes_parameter(self):
        """Test optimize_dtypes parameter"""
        fields = {"age": FieldConfig(type="int")}
        schema_config = SchemaConfig(
            schema_id="test_schema",
            name="Test Schema",
            fields=fields,
            optimize_dtypes=False,
        )

        loader = Loader(filepath=self.temp_file.name, schema=schema_config)
        assert loader.config.schema.optimize_dtypes is False

    def test_sample_size_parameter(self):
        """Test sample_size parameter"""
        fields = {"age": FieldConfig(type="int")}
        schema_config = SchemaConfig(
            schema_id="test_schema", name="Test Schema", fields=fields, sample_size=1000
        )

        loader = Loader(filepath=self.temp_file.name, schema=schema_config)
        assert loader.config.schema.sample_size == 1000

    def test_sample_size_null(self):
        """Test sample_size as null"""
        fields = {"age": FieldConfig(type="int")}
        schema_config = SchemaConfig(
            schema_id="test_schema", name="Test Schema", fields=fields, sample_size=None
        )

        loader = Loader(filepath=self.temp_file.name, schema=schema_config)
        assert loader.config.schema.sample_size is None

    def test_leading_zeros_parameter(self):
        """Test leading_zeros parameter"""
        valid_values = ["never", "num-auto", "leading_5"]

        for value in valid_values:
            fields = {"id": FieldConfig(type="int")}
            schema_config = SchemaConfig(
                schema_id="test_schema",
                name="Test Schema",
                fields=fields,
                leading_zeros=value,
            )

            loader = Loader(filepath=self.temp_file.name, schema=schema_config)
            assert loader.config.schema.leading_zeros == value

    def test_leading_zeros_invalid(self):
        """Test invalid leading_zeros parameter"""
        # SchemaConfig validation should catch invalid leading_zeros values
        with pytest.raises((TypeError, ValueError)):
            fields = {"id": FieldConfig(type="int")}
            schema_config = SchemaConfig(
                schema_id="test_schema",
                name="Test Schema",
                fields=fields,
                leading_zeros="invalid_value",
            )
            Loader(filepath=self.temp_file.name, schema=schema_config)

    def test_nullable_int_parameter(self):
        """Test nullable_int parameter"""
        valid_values = ["force", "never"]

        for value in valid_values:
            fields = {"age": FieldConfig(type="int")}
            schema_config = SchemaConfig(
                schema_id="test_schema",
                name="Test Schema",
                fields=fields,
                nullable_int=value,
            )

            loader = Loader(filepath=self.temp_file.name, schema=schema_config)
            assert loader.config.schema.nullable_int == value

    def test_nullable_int_invalid(self):
        """Test invalid nullable_int parameter"""
        # SchemaConfig validation should catch invalid nullable_int values
        with pytest.raises((TypeError, ValueError)):
            fields = {"age": FieldConfig(type="int")}
            schema_config = SchemaConfig(
                schema_id="test_schema",
                name="Test Schema",
                fields=fields,
                nullable_int="invalid_value",
            )
            Loader(filepath=self.temp_file.name, schema=schema_config)

    def test_infer_logical_types_parameter(self):
        """Test infer_logical_types parameter"""
        fields = {"name": FieldConfig(type="str")}
        schema_config = SchemaConfig(
            schema_id="test_schema",
            name="Test Schema",
            fields=fields,
            infer_logical_types=True,
        )

        loader = Loader(filepath=self.temp_file.name, schema=schema_config)
        assert loader.config.schema.infer_logical_types is True

    def test_descriptive_parameters(self):
        """Test descriptive parameters"""
        fields = {"age": FieldConfig(type="int")}
        schema_config = SchemaConfig(
            schema_id="test_schema_v1",
            name="Test Schema",
            description="Schema for testing",
            fields=fields,
        )

        loader = Loader(filepath=self.temp_file.name, schema=schema_config)
        assert loader.config.schema.schema_id == "test_schema_v1"
        assert loader.config.schema.name == "Test Schema"
        assert loader.config.schema.description == "Schema for testing"


class TestLoaderSchemaFieldParameters:
    """Test field-level schema parameters in Loader
    Loader ä¸­æ¬„ä½å±¤ç´š schema åƒæ•¸çš„æ¸¬è©¦æ¡ˆä¾‹
    """

    def setup_method(self):
        """Setup test data"""
        self.test_data = pd.DataFrame(
            {
                "email": ["alice@example.com", "bob@test.com", "charlie@demo.org"],
                "phone": ["123-456-7890", "987-654-3210", "555-123-4567"],
                "user_id": ["00001", "00002", "00003"],
                "score": [85.5, 92.0, 78.5],
            }
        )

        self.temp_file = tempfile.NamedTemporaryFile(
            mode="w", suffix=".csv", delete=False
        )
        self.test_data.to_csv(self.temp_file.name, index=False)
        self.temp_file.close()

    def teardown_method(self):
        """Cleanup test data"""
        if os.path.exists(self.temp_file.name):
            os.unlink(self.temp_file.name)

    def test_logical_type_parameter(self):
        """Test logical_type parameter"""
        valid_values = ["never", "infer", "email", "phone", "url"]

        for value in valid_values:
            fields = {"email": FieldConfig(type="str", logical_type=value)}
            schema_config = SchemaConfig(
                schema_id="test_schema",
                name="Test Schema",
                fields=fields,
            )

            loader = Loader(filepath=self.temp_file.name, schema=schema_config)
            assert loader.config.schema.fields["email"].logical_type == value

    def test_leading_zeros_field_level(self):
        """Test leading_zeros at field level"""
        fields = {"user_id": FieldConfig(type="str", leading_zeros="leading_5")}
        schema_config = SchemaConfig(
            schema_id="test_schema",
            name="Test Schema",
            fields=fields,
            leading_zeros="never",  # Global setting
        )

        loader = Loader(filepath=self.temp_file.name, schema=schema_config)
        assert loader.config.schema.leading_zeros == "never"
        assert loader.config.schema.fields["user_id"].leading_zeros == "leading_5"

    def test_leading_zeros_field_invalid(self):
        """Test invalid leading_zeros at field level"""
        # This should be caught during FieldConfig creation
        with pytest.raises((TypeError, ValueError)):
            FieldConfig(type="str", leading_zeros="invalid_value")


class TestLoaderSchemaParameterConflicts:
    """Test parameter conflicts and validation in Loader
    Loader ä¸­åƒæ•¸è¡çªå’Œé©—è­‰çš„æ¸¬è©¦æ¡ˆä¾‹
    """

    def setup_method(self):
        """Setup test data"""
        self.test_data = pd.DataFrame(
            {"email": ["alice@example.com", "bob@test.com"], "name": ["Alice", "Bob"]}
        )

        self.temp_file = tempfile.NamedTemporaryFile(
            mode="w", suffix=".csv", delete=False
        )
        self.test_data.to_csv(self.temp_file.name, index=False)
        self.temp_file.close()

    def teardown_method(self):
        """Cleanup test data"""
        if os.path.exists(self.temp_file.name):
            os.unlink(self.temp_file.name)

    def test_infer_logical_types_conflict(self):
        """Test conflict between infer_logical_types and field logical_type"""
        # This should raise an error during SchemaConfig creation
        with pytest.raises(
            ValueError,
            match="Cannot set infer_logical_types=True when field .* has logical_type specified",
        ):
            fields = {"email": FieldConfig(type="str", logical_type="email")}
            SchemaConfig(
                schema_id="test_schema",
                name="Test Schema",
                fields=fields,
                infer_logical_types=True,
            )


class TestLoaderSchemaEdgeCases:
    """Test edge cases and error handling for schema parameters in Loader
    Loader ä¸­ schema åƒæ•¸çš„é‚Šç·£æƒ…æ³å’ŒéŒ¯èª¤è™•ç†æ¸¬è©¦æ¡ˆä¾‹
    """

    def setup_method(self):
        """Setup test data"""
        self.test_data = pd.DataFrame({"col1": [1, 2, 3], "col2": ["a", "b", "c"]})

        self.temp_file = tempfile.NamedTemporaryFile(
            mode="w", suffix=".csv", delete=False
        )
        self.test_data.to_csv(self.temp_file.name, index=False)
        self.temp_file.close()

    def teardown_method(self):
        """Cleanup test data"""
        if os.path.exists(self.temp_file.name):
            os.unlink(self.temp_file.name)

    def test_empty_schema(self):
        """Test empty schema"""
        # Test with no schema_config - should use defaults
        loader = Loader(filepath=self.temp_file.name)
        # Should not raise error
        assert loader.config.schema is None

    def test_schema_with_only_global_params(self):
        """Test schema with only global parameters"""
        schema_config = SchemaConfig(
            schema_id="test_schema",
            name="Test Schema",
            fields={},
            compute_stats=False,
            optimize_dtypes=True,
            sample_size=100,
        )

        loader = Loader(filepath=self.temp_file.name, schema=schema_config)
        assert loader.config.schema.compute_stats is False
        assert loader.config.schema.optimize_dtypes is True
        assert loader.config.schema.sample_size == 100

    def test_invalid_global_parameter(self):
        """Test invalid global parameter"""
        # Invalid parameters should be caught during SchemaConfig creation
        with pytest.raises((TypeError, ValueError)):
            SchemaConfig(
                schema_id="test_schema",
                name="Test Schema",
                fields={"col1": FieldConfig(type="int")},
                invalid_param="value",
            )

    def test_invalid_field_parameter(self):
        """Test invalid field parameter"""
        # Invalid parameters should be caught during FieldConfig creation
        with pytest.raises((TypeError, ValueError)):
            FieldConfig(type="int", invalid_param="value")

    def test_mixed_legacy_and_schema(self):
        """Test mixing legacy parameters with schema"""
        fields = {"col1": FieldConfig(type="int")}
        schema_config = SchemaConfig(
            schema_id="test_schema",
            name="Test Schema",
            fields=fields,
            compute_stats=False,
        )

        # This should raise ConfigError due to field conflict
        with pytest.raises(
            ConfigError, match="Conflict detected.*col1.*schema and column_types"
        ):
            Loader(
                filepath=self.temp_file.name,
                column_types={"category": ["col1"]},  # This conflicts with schema
                schema=schema_config,
            )


if __name__ == "__main__":
    run_stress_demo()
