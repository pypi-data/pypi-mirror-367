{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Downloading the drvd-bench dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/tianhongzhou/drvd-bench?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.54G/6.54G [05:54<00:00, 19.8MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/tiger/.cache/kagglehub/datasets/tianhongzhou/drvd-bench/versions/4\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "# It appears that in the Kaggle dataset the image paths include an extra subfolder with the same name. \n",
    "# Since we're not allowed to modify the data during the rebuttal phase, please download the dataset and then manually delete that extra folder layer.\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"tianhongzhou/drvd-bench\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.system(f\"mv /home/tiger/.cache/kagglehub/datasets/tianhongzhou/drvd-bench/versions/4 {current_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 导入成功\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# function of drvd-bench\n",
    "from drvd_bench import (\n",
    "    get_drvd_data,\n",
    "    map_result,\n",
    "    compute_choice_metric,\n",
    "    compute_report_generation_metric\n",
    ")\n",
    "\n",
    "print(\"✅ Import successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Model inference and metric calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 visual_evidence_qa.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 配置就绪\n"
     ]
    }
   ],
   "source": [
    "# Relevant Parameters\n",
    "QWEN_API_KEY   = \"YOUR_QWEN_API_KEY\"  # API key for qwen2.5vl\n",
    "MODEL     = \"qwen2.5-vl-7b-instruct\"\n",
    "BASE_URL  = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "JSONL_PATH   = Path(\"./4/visual_evidence_qa.jsonl\")     # Input data\n",
    "IMAGE_ROOT   = Path(\"./4\")       # Image root directory\n",
    "DATA_TYPE    = \"single\"                      # \"single\" | \"joint\"\n",
    "NUM_SAMPLES  = 100                            # Use the first n samples for testing\n",
    "\n",
    "RAW_OUT_PATH    = Path(\"visual_evidence_qa_result.jsonl\")  # Raw model output\n",
    "\n",
    "print(\"✅ Configuration ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ client 初始化完成\n"
     ]
    }
   ],
   "source": [
    "# API call related logic\n",
    "client = OpenAI(api_key=QWEN_API_KEY, base_url=BASE_URL)\n",
    "print(\"✅ client initialization completed\")\n",
    "\n",
    "import base64\n",
    "import mimetypes\n",
    "import time\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def compress_image(\n",
    "    path: str | Path,\n",
    "    max_dim: int = 1024,\n",
    "    quality: int = 85,\n",
    "    size_limit_mb: int = 10,\n",
    ") -> bytes:\n",
    "    \"\"\"Recursively compress the image so that the Base64 size ≤ size_limit_mb MiB.\"\"\"\n",
    "    img = Image.open(path)\n",
    "    if img.mode in (\"RGBA\", \"P\"):\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "    w, h = img.size\n",
    "    if max(w, h) > max_dim:\n",
    "        ratio = max_dim / max(w, h)\n",
    "        img = img.resize((int(w * ratio), int(h * ratio)), Image.LANCZOS)\n",
    "\n",
    "    buf = BytesIO()\n",
    "    img.save(buf, format=\"JPEG\", quality=quality)\n",
    "    data = buf.getvalue()\n",
    "\n",
    "    # Base64 expands about 1.37 times\n",
    "    if len(data) * 1.37 > size_limit_mb * 1024 * 1024:\n",
    "        # Continue lowering resolution / quality\n",
    "        return compress_image(\n",
    "            path, int(max_dim * 0.9), int(quality * 0.9), size_limit_mb\n",
    "        )\n",
    "    return data\n",
    "\n",
    "\n",
    "def encode_image(\n",
    "    path: str | Path,\n",
    "    max_dim: int = 1024,\n",
    "    quality: int = 85,\n",
    "    size_limit_mb: int = 10,\n",
    ") -> str:\n",
    "    \"\"\"Return a data URL that can be directly used in OpenAI messages.\"\"\"\n",
    "    try:\n",
    "        img_bytes = compress_image(path, max_dim, quality, size_limit_mb)\n",
    "    except Exception:\n",
    "        with open(path, \"rb\") as f:\n",
    "            img_bytes = f.read()\n",
    "\n",
    "    b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "    mime, _ = mimetypes.guess_type(str(path))\n",
    "    if not mime:\n",
    "        mime = \"image/jpeg\"\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "MAX_RETRIES  = 5\n",
    "RETRY_DELAY  = 1      # seconds\n",
    "DEFAULT_SYS_PROMPT = \"You are a helpful medical image analysis assistant.\"\n",
    "\n",
    "def api_infer(\n",
    "    prompt: str,\n",
    "    image_path: str | Path,\n",
    "    client: OpenAI,\n",
    "    *,\n",
    "    system_prompt: str = DEFAULT_SYS_PROMPT,\n",
    "    max_dim: int = 1024,\n",
    "    quality: int = 85,\n",
    "    size_limit_mb: int = 10,\n",
    "    max_tokens: Optional[int] = 300,\n",
    "    temperature: Optional[float] = 0.0,\n",
    "    model_name: str = \"qwen2.5-vl-72b-instruct\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Full implementation, equivalent to api_infer in qwen2.5vl_example.py.\n",
    "    - Automatically converts image_path to data URL\n",
    "    - Retries up to 5 times\n",
    "    \"\"\"\n",
    "    data_url = encode_image(image_path, max_dim, quality, size_limit_mb)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            params = {\"model\": model_name, \"messages\": messages}\n",
    "            if max_tokens is not None:\n",
    "                params[\"max_tokens\"] = max_tokens\n",
    "            if temperature is not None:\n",
    "                params[\"temperature\"] = temperature\n",
    "            resp = client.chat.completions.create(**params)\n",
    "            return resp.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"[Warning] attempt {attempt}/{MAX_RETRIES} failed: {e}\")\n",
    "            if attempt < MAX_RETRIES:\n",
    "                time.sleep(RETRY_DELAY)\n",
    "\n",
    "    # If still failed, raise the last exception\n",
    "    raise last_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading DrVD items: 100it [01:29,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已完成101 条：/opt/tiger/try_new_codes/visual_evidence_qa_result.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform inference and save results\n",
    "RAW_OUT_PATH.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "for idx, (img_path, prompt, record) in enumerate(\n",
    "    get_drvd_data(JSONL_PATH, IMAGE_ROOT, data_type=DATA_TYPE, verbose=True)\n",
    "):\n",
    "    if idx >= NUM_SAMPLES:\n",
    "        break\n",
    "    try:\n",
    "        answer = api_infer(prompt, img_path, client)\n",
    "    except Exception as e:\n",
    "        answer = f\"[ERROR] {e}\"\n",
    "    record[\"model_response\"] = answer\n",
    "\n",
    "    with RAW_OUT_PATH.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "print(f\"✅ Completed {idx+1} entries: {RAW_OUT_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality: CT\n",
      "  modality_recognition: 100.00% (100/100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metric calculation\n",
    "compute_choice_metric(RAW_OUT_PATH, mode=\"single\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 independent_qa.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 配置就绪\n"
     ]
    }
   ],
   "source": [
    "# Relevant Parameters\n",
    "JSONL_PATH   = Path(\"./4/independent_qa.jsonl\")     # Input data\n",
    "IMAGE_ROOT   = Path(\"./4\")       # Image root directory\n",
    "DATA_TYPE    = \"single\"                      # \"single\" | \"joint\"\n",
    "NUM_SAMPLES  = 100                            # Use the first n samples for testing\n",
    "\n",
    "RAW_OUT_PATH    = Path(\"independent_qa_result.jsonl\")  # Raw model output\n",
    "\n",
    "print(\"✅ Configuration ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading DrVD items: 99it [01:10,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] attempt 1/5 failed: Error code: 429 - {'error': {'message': 'You exceeded your current requests list.', 'type': 'limit_requests', 'param': None, 'code': 'limit_requests'}, 'request_id': '40174e0b-2244-919d-8894-52b9b1fda364'}\n",
      "[Warning] attempt 2/5 failed: Error code: 429 - {'error': {'message': 'You exceeded your current requests list.', 'type': 'limit_requests', 'param': None, 'code': 'limit_requests'}, 'request_id': '72bbbe7d-0745-968d-ae76-2652145de04f'}\n",
      "[Warning] attempt 3/5 failed: Error code: 429 - {'error': {'message': 'You exceeded your current requests list.', 'type': 'limit_requests', 'param': None, 'code': 'limit_requests'}, 'request_id': '2bad0287-76ce-95d1-a21c-9872d4ab78e7'}\n",
      "[Warning] attempt 4/5 failed: Error code: 429 - {'error': {'message': 'You exceeded your current requests list.', 'type': 'limit_requests', 'param': None, 'code': 'limit_requests'}, 'request_id': '6ad96773-43dd-9982-9d88-99f78ec009bc'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading DrVD items: 100it [01:22,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] attempt 5/5 failed: Error code: 429 - {'error': {'message': 'You exceeded your current requests list.', 'type': 'limit_requests', 'param': None, 'code': 'limit_requests'}, 'request_id': '178c985c-1fd5-976e-aff7-0aca50fbe7ea'}\n",
      "✅ 已完成101 条：/opt/tiger/try_new_codes/independent_qa_result.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform inference and save results\n",
    "RAW_OUT_PATH.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "for idx, (img_path, prompt, record) in enumerate(\n",
    "    get_drvd_data(JSONL_PATH, IMAGE_ROOT, data_type=DATA_TYPE, verbose=True)\n",
    "):\n",
    "    if idx >= NUM_SAMPLES:\n",
    "        break\n",
    "    try:\n",
    "        answer = api_infer(prompt, img_path, client)\n",
    "    except Exception as e:\n",
    "        answer = f\"[ERROR] {e}\"\n",
    "    record[\"model_response\"] = answer\n",
    "\n",
    "    with RAW_OUT_PATH.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "print(f\"✅ Completed {idx+1} entries: {RAW_OUT_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality: CT\n",
      "  modality: 90.00% (18/20)\n",
      "  bodypart: 85.00% (17/20)\n",
      "  organ: 40.00% (8/20)\n",
      "  lesion: 45.00% (9/20)\n",
      "  diagnosis: 35.00% (7/20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metric calculation\n",
    "compute_choice_metric(RAW_OUT_PATH, mode=\"single\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 joint_qa.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 配置就绪\n"
     ]
    }
   ],
   "source": [
    "# Relevant Parameters\n",
    "JSONL_PATH   = Path(\"./4/joint_qa.jsonl\")     # Input data\n",
    "IMAGE_ROOT   = Path(\"./4\")       # Image root directory\n",
    "DATA_TYPE    = \"joint\"                      # \"single\" | \"joint\"\n",
    "NUM_SAMPLES  = 20                            # Use the first n samples for testing\n",
    "\n",
    "RAW_OUT_PATH    = Path(\"joint_qa_result.jsonl\")  # Raw model output\n",
    "\n",
    "print(\"✅ Configuration ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading DrVD items: 20it [00:15,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已完成21 条：/opt/tiger/try_new_codes/joint_qa_result.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform inference and save results\n",
    "RAW_OUT_PATH.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "for idx, (img_path, prompt, record) in enumerate(\n",
    "    get_drvd_data(JSONL_PATH, IMAGE_ROOT, data_type=DATA_TYPE, verbose=True)\n",
    "):\n",
    "    if idx >= NUM_SAMPLES:\n",
    "        break\n",
    "    try:\n",
    "        answer = api_infer(prompt, img_path, client)\n",
    "    except Exception as e:\n",
    "        answer = f\"[ERROR] {e}\"\n",
    "    record[\"model_response\"] = answer\n",
    "\n",
    "    with RAW_OUT_PATH.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "print(f\"✅ Completed {idx+1} entries: {RAW_OUT_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Hierarchical Accuracy Report by Modality:\n",
      "\n",
      "Modality: CT\n",
      "      modality: 90.00% (18/20)\n",
      "         organ: 65.00% (13/20)\n",
      "        lesion: 45.00% (9/20)\n",
      "     diagnosis: 35.00% (7/20)\n"
     ]
    }
   ],
   "source": [
    "# Metric calculation\n",
    "compute_choice_metric(RAW_OUT_PATH, mode=\"joint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 report_generation.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 配置就绪\n"
     ]
    }
   ],
   "source": [
    "# Relevant Parameters\n",
    "JSONL_PATH   = Path(\"./4/report_generation.jsonl\")     # Input data\n",
    "IMAGE_ROOT   = Path(\"./4\")       # Image root directory\n",
    "DATA_TYPE    = \"single\"                      # \"single\" | \"joint\"\n",
    "NUM_SAMPLES  = 10                            # Use the first n samples for testing\n",
    "\n",
    "RAW_OUT_PATH    = Path(\"report_generation_result.jsonl\")  # Raw model output\n",
    "\n",
    "print(\"✅ Configuration ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading DrVD items: 10it [01:32,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已完成11 条：/opt/tiger/try_new_codes/report_generation_result.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform inference and save results\n",
    "RAW_OUT_PATH.write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "for idx, (img_path, prompt, record) in enumerate(\n",
    "    get_drvd_data(JSONL_PATH, IMAGE_ROOT, data_type=DATA_TYPE, verbose=True)\n",
    "):\n",
    "    if idx >= NUM_SAMPLES:\n",
    "        break\n",
    "    try:\n",
    "        answer = api_infer(prompt, img_path, client)\n",
    "    except Exception as e:\n",
    "        answer = f\"[ERROR] {e}\"\n",
    "    record[\"model_response\"] = answer\n",
    "\n",
    "    with RAW_OUT_PATH.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "print(f\"✅ Completed {idx+1} entries: {RAW_OUT_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.05it/s]\n",
      "Scoring:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a8b7a6cb554e24974cf03bef2e6de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='tokenizer_config.json', max=28.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bceb9f030d4b1c85895a4a92dfd16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='config.json', max=385.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82cf5cdd9064070b1db23ffe098279a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='vocab.txt', layout=Layout(width='20px')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502b7c7d048f40bd8428f86e0b91c1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='pytorch_model.bin', max=440474434.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 1/1 [01:36<00:00, 96.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT: BERTScore F1 = 0.8992, BLEU = 0.0271\n",
      "✅ 指标计算完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Metric calculation\n",
    "DEEPSEEK_API_KEY   = \"YOUR_DEEPSEEK_API_KEY\"  # deepseek's API\n",
    "# Calculate report generation metric\n",
    "compute_report_generation_metric(api_key=DEEPSEEK_API_KEY, json_path=RAW_OUT_PATH)\n",
    "print(\"✅ Metric calculation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model result mapping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to address the issue where models with poor instruction-following ability cannot compute metrics; not needed for models with good instruction-following\n",
    "_ = map_result(\n",
    "    api_key=YOUR_DEEPSEEK_API_KEY,\n",
    "    input_path=RAW_OUT_PATH,\n",
    "    output_path=MAPPED_OUT_PATH,\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    "    show_preview=3       # Only print the first 3 examples in the terminal\n",
    ")\n",
    "print(f\"✅ Mapped results written to {MAPPED_OUT_PATH.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "fileId": "6d7593be-0596-440a-99f7-624280be10d1",
  "filePath": "/opt/tiger/try_new_codes/qwen2.5vl_7b_demo.ipynb",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
